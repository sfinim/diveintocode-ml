{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/timanishi/.pyenv/versions/3.7.8/lib/python3.7/site-packages/chainer/_environment_check.py:91: UserWarning: \n",
      "--------------------------------------------------------------------------------\n",
      "Multiple installations of CuPy package has been detected.\n",
      "You should select only one package from from ['cupy-cuda102', 'cupy-cuda101', 'cupy-cuda100', 'cupy-cuda92', 'cupy-cuda91', 'cupy-cuda90', 'cupy-cuda80', 'cupy'].\n",
      "Follow these steps to resolve this issue:\n",
      "  1. `pip list` to list CuPy packages installed\n",
      "  2. `pip uninstall <package name>` to uninstall all CuPy packages\n",
      "  3. `pip install <package name>` to install the proper one\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  '''.format(name=name, pkgs=pkgs))\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import cupy as np\n",
    "import chainer.cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ディープニューラルネットワークスクラッチ\n",
    "前回は3層のニューラルネットワークを作成しましたが、今回はこれを任意の層数に拡張しやすいものに書き換えていきます。その上で、活性化関数や初期値、最適化手法について発展的なものを扱えるようにしていきます。\n",
    "\n",
    "このようなスクラッチを行うことで、今後各種フレームワークを利用していくにあたり、内部の動きが想像できることを目指します。\n",
    "\n",
    "名前は新しくScratchDeepNeuralNetrowkClassifierクラスとしてください。\n",
    "\n",
    "#### 層などのクラス化\n",
    "クラスにまとめて行くことで、構成を変更しやすい実装にしていきます。\n",
    "\n",
    "手を加える箇所\n",
    "\n",
    "- 層の数\n",
    "- 層の種類（今後畳み込み層など他のタイプの層が登場する）\n",
    "- 活性化関数の種類\n",
    "- 重みやバイアスの初期化方法\n",
    "- 最適化手法\n",
    "\n",
    "そのために、全結合層、各種活性化関数、重みやバイアスの初期化、最適化手法それぞれのクラスを作成します。\n",
    "\n",
    "実装方法は自由ですが、簡単な例を紹介します。サンプルコード1のように全結合層と活性化関数のインスタンスを作成し、サンプルコード2,3のようにして使用します。それぞれのクラスについてはこのあと解説します。\n",
    "\n",
    "《サンプルコード1》\n",
    "\n",
    "ScratchDeepNeuralNetrowkClassifierのfitメソッド内\n",
    "```\n",
    "# self.sigma : ガウス分布の標準偏差\n",
    "# self.lr : 学習率\n",
    "# self.n_nodes1 : 1層目のノード数\n",
    "# self.n_nodes2 : 2層目のノード数\n",
    "# self.n_output : 出力層のノード数\n",
    "optimizer = SGD(self.lr)\n",
    "self.FC1 = FC(self.n_features, self.n_nodes1, SimpleInitializer(self.sigma), optimizer)\n",
    "self.activation1 = Tanh()\n",
    "self.FC2 = FC(self.n_nodes1, self.n_nodes2, SimpleInitializer(self.sigma), optimizer)\n",
    "self.activation2 = Tanh()\n",
    "self.FC3 = FC(self.n_nodes2, self.n_output, SimpleInitializer(self.sigma), optimizer)\n",
    "self.activation3 = Softmax()\n",
    "```\n",
    "\n",
    "《サンプルコード2》\n",
    "\n",
    "イテレーションごとのフォワード\n",
    "```\n",
    "A1 = self.FC1.forward(X)\n",
    "Z1 = self.activation1.forward(A1)\n",
    "A2 = self.FC2.forward(Z1)\n",
    "Z2 = self.activation2.forward(A2)\n",
    "A3 = self.FC3.forward(Z2)\n",
    "Z3 = self.activation3.forward(A3)\n",
    "```\n",
    "\n",
    "《サンプルコード3》\n",
    "\n",
    "イテレーションごとのバックワード\n",
    "```\n",
    "dA3 = self.activation3.backward(Z3, Y) # 交差エントロピー誤差とソフトマックスを合わせている\n",
    "dZ2 = self.FC3.backward(dA3)\n",
    "dA2 = self.activation2.backward(dZ2)\n",
    "dZ1 = self.FC2.backward(dA2)\n",
    "dA1 = self.activation1.backward(dZ1)\n",
    "dZ0 = self.FC1.backward(dA1) # dZ0は使用しない\n",
    "```\n",
    "\n",
    "### 【問題1】全結合層のクラス化\n",
    "全結合層のクラス化を行なってください。\n",
    "\n",
    "以下に雛形を載せました。コンストラクタで重みやバイアスの初期化をして、あとはフォワードとバックワードのメソッドを用意します。重みW、バイアスB、およびフォワード時の入力Xをインスタンス変数として保持しておくことで、煩雑な入出力は不要になります。\n",
    "\n",
    "なお、インスタンスも引数として渡すことができます。そのため、初期化方法のインスタンスinitializerをコンストラクタで受け取れば、それにより初期化が行われます。渡すインスタンスを変えれば、初期化方法が変えられます。\n",
    "\n",
    "また、引数として自身のインスタンスselfを渡すこともできます。これを利用してself.optimizer.update(self)という風に層の重みの更新が可能です。更新に必要な値は複数ありますが、全て全結合層が持つインスタンス変数にすることができます。\n",
    "\n",
    "初期化方法と最適化手法のクラスについては後述します。\n",
    "\n",
    "《雛形》\n",
    "```\n",
    "class FC:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        pass\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"        \n",
    "        pass\n",
    "        return A\n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        pass\n",
    "        # 更新\n",
    "        self = self.optimizer.update(self)\n",
    "        return dZ\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.W = initializer.W(n_nodes1, n_nodes2)\n",
    "        self.b = initializer.B(n_nodes2)\n",
    "        self.X = None\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"        \n",
    "        self.X = X\n",
    "        out = np.dot(X, self.W) + self.b\n",
    "        \n",
    "        return out\n",
    "\n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        # 更新\n",
    "        batch_size = dA.shape[0]\n",
    "        dX = np.dot(dA, self.W.T)\n",
    "        self.dW = np.dot(self.X.T, dA) / batch_size\n",
    "        self.db = np.sum(dA, axis=0) / batch_size\n",
    "        self = self.optimizer.update(self)\n",
    "        \n",
    "        return dX\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- FCクラスの__init__,forward,backwardメソッドを更新"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題2】初期化方法のクラス化\n",
    "初期化を行うコードをクラス化してください。\n",
    "\n",
    "前述のように、全結合層のコンストラクタに初期化方法のインスタンスを渡せるようにします。以下の雛形に必要なコードを書き加えていってください。標準偏差の値（sigma）はコンストラクタで受け取るようにすることで、全結合層のクラス内にこの値（sigma）を渡さなくてすむようになります。\n",
    "\n",
    "これまで扱ってきた初期化方法はSimpleInitializerクラスと名付けることにします。\n",
    "\n",
    "《雛形》\n",
    "```\n",
    "class SimpleInitializer:\n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      ガウス分布の標準偏差\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W :\n",
    "        \"\"\"\n",
    "        pass\n",
    "        return W\n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B :\n",
    "        \"\"\"\n",
    "        pass\n",
    "        return B\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleInitializer:\n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      ガウス分布の標準偏差\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W :\n",
    "        \"\"\"\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B :\n",
    "        \"\"\"\n",
    "        B = np.zeros(n_nodes2)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SimpleInitializerクラスのW, Bメソッドを更新"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題3】最適化手法のクラス化\n",
    "最適化手法のクラス化を行なってください。\n",
    "\n",
    "最適化手法に関しても初期化方法同様に全結合層にインスタンスとして渡します。バックワードのときにself.optimizer.update(self)のように更新できるようにします。以下の雛形に必要なコードを書き加えていってください。\n",
    "\n",
    "これまで扱ってきた最適化手法はSGDクラス（Stochastic Gradient Descent、確率的勾配降下法）として作成します。\n",
    "\n",
    "雛形\n",
    "```\n",
    "class SGD:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "        layer.W -= self.lr * layer.dW\n",
    "        layer.b -= self.lr * layer.db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題4】活性化関数のクラス化\n",
    "活性化関数のクラス化を行なってください。\n",
    "\n",
    "ソフトマックス関数のバックプロパゲーションには交差エントロピー誤差の計算も含む実装を行うことで計算が簡略化されます。\n",
    "\n",
    "#### 発展的要素\n",
    "活性化関数や重みの初期値、最適化手法に関してこれまで見てきた以外のものを実装していきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid():\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        out = 1 / (1 + np.exp(-X))\n",
    "        self.out = out\n",
    "        \n",
    "        return out\n",
    "        \n",
    "    def backward(self, dout):\n",
    "        dX = dout*(1.0 - self.out)*self.out\n",
    "        \n",
    "        return dX\n",
    "\n",
    "\n",
    "class Tanh():\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        out = np.tanh(X)\n",
    "        self.out = out\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dX = dout*(1 - self.out**2)\n",
    "        \n",
    "        return dX\n",
    "\n",
    "    \n",
    "class Softmax():\n",
    "    def __init__(self):\n",
    "        self.loss = None\n",
    "        self.y = None\n",
    "        self.t = None\n",
    "    \n",
    "    def _softmax(self, X):\n",
    "        X = X - np.max(X, axis=-1, keepdims=True)\n",
    "        y = np.exp(X) / np.sum(np.exp(X), axis=-1, keepdims=True)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    def _cross_entropy_error(self, y, t):\n",
    "        batch_size = y.shape[0]\n",
    "        \n",
    "        return -np.sum(t * np.log(y + 1e-7)) / batch_size\n",
    "    \n",
    "    def forward(self, X, t):\n",
    "        self.t = t\n",
    "        self.y = self._softmax(X)\n",
    "        self.loss = self._cross_entropy_error(self.y, self.t)\n",
    "        \n",
    "        return self.loss\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        dX = (self.y - self.t) / batch_size\n",
    "        \n",
    "        return dX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題5】ReLUクラスの作成\n",
    "現在一般的に使われている活性化関数であるReLU（Rectified Linear Unit）をReLUクラスとして実装してください。\n",
    "\n",
    "ReLUは以下の数式です。\n",
    "$$\n",
    "f(x)=ReLU(x)=\\begin{cases}x \\quad x \\geqq 0 \\\\\n",
    "                0 \\quad x < 0 \\\\\n",
    "                \\end{cases}\n",
    "$$\n",
    "$x$ : ある特徴量。スカラー\n",
    "\n",
    "実装上はnp.maximumを使い配列に対してまとめて計算が可能です。\n",
    "\n",
    "[numpy.maximum — NumPy v1.15 Manual](https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.maximum.html)\n",
    "\n",
    "一方、バックプロパゲーションのための $x$ に関する $f(x)$ の微分は以下のようになります。\n",
    "$$\n",
    "\\frac{\\partial f(x)}{\\partial x}=\\begin{cases}1\\space if \\quad x > 0 \\\\\n",
    "                0\\space if \\quad x \\leqq 0 \\\\\n",
    "                \\end{cases}\n",
    "$$\n",
    "\n",
    "数学的には微分可能ではないですが、 $x=0$ のとき $0$ とすることで対応しています。\n",
    "\n",
    "フォワード時の $x$ の正負により、勾配を逆伝播するかどうかが決まるということになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.mask = (x < 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題6】重みの初期値\n",
    "ここまでは重みやバイアスの初期値は単純にガウス分布で、標準偏差をハイパーパラメータとして扱ってきました。しかし、どのような値にすると良いかが知られています。シグモイド関数やハイパボリックタンジェント関数のときは Xavierの初期値 （またはGlorotの初期値）、ReLUのときは Heの初期値 が使われます。\n",
    "\n",
    "XavierInitializerクラスと、HeInitializerクラスを作成してください。\n",
    "\n",
    "#### Xavierの初期値\n",
    "Xavierの初期値における標準偏差 $\\sigma$ は次の式で求められます。\n",
    "$$\n",
    "\\sigma=\\frac{1}{\\sqrt{n}}\n",
    "$$\n",
    "$n$ : 前の層のノード数\n",
    "\n",
    "《論文》\n",
    "\n",
    "[Glorot, X., & Bengio, Y. (n.d.). Understanding the difficulty of training deep feedforward neural networks.](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf)\n",
    "\n",
    "#### Heの初期値\n",
    "Heの初期値における標準偏差 $\\sigma$ は次の式で求められます。\n",
    "$$\n",
    "\\sigma=\\sqrt{\\frac{2}{n}}\n",
    "$$\n",
    "$n$ : 前の層のノード数\n",
    "\n",
    "《論文》\n",
    "\n",
    "[He, K., Zhang, X., Ren, S., & Sun, J. (2015). Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification.](https://arxiv.org/pdf/1502.01852.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XavierInitializer:\n",
    "    def __init__(self):\n",
    "        self.sigma = None\n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        self.sigma = 1 / np.sqrt(n_nodes1)\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "    def B(self, n_nodes2):\n",
    "        B = np.zeros(n_nodes2)\n",
    "        return B\n",
    "\n",
    "\n",
    "class HeInitializer:\n",
    "    def __init__(self):\n",
    "        self.sigma = None\n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        self.sigma = np.sqrt(2 / n_nodes1)\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "    def B(self, n_nodes2):\n",
    "        B = np.zeros(n_nodes2)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題7】最適化手法\n",
    "学習率は学習過程で変化させていく方法が一般的です。基本的な手法である AdaGrad のクラスを作成してください。\n",
    "\n",
    "まず、これまで使ってきたSGDを確認します。\n",
    "$$\n",
    "W_i'=W_i-\\alpha E(\\frac{\\partial L}{\\partial W_i}) \\\\\n",
    "B_i'=B_i-\\alpha E(\\frac{\\partial L}{\\partial B_i})\n",
    "$$\n",
    "$\\alpha$ : 学習率（層ごとに変えることも可能だが、基本的には全て同じとする）\n",
    "\n",
    "$\\frac{\\partial L}{\\partial W_i}$ : $W_i$ に関する損失 $L$ の勾配\n",
    "\n",
    "$\\frac{\\partial L}{\\partial B_i}$ : $B_i$ に関する損失 $L$ の勾配\n",
    "\n",
    "$E()$ : ミニバッチ方向にベクトルの平均を計算\n",
    "\n",
    "続いて、AdaGradです。バイアスの数式は省略しますが、重みと同様のことをします。\n",
    "\n",
    "更新された分だけその重みに対する学習率を徐々に下げていきます。イテレーションごとの勾配の二乗和 $H$ を保存しておき、その分だけ学習率を小さくします。\n",
    "\n",
    "学習率は重み一つひとつに対して異なることになります。\n",
    "\n",
    "$$\n",
    "H_i'=H_i+E(\\frac{\\partial L}{\\partial W_i})×E(\\frac{\\partial L}{\\partial W_i}) \\\\\n",
    "W_i'=W_i-\\alpha\\frac{1}{\\sqrt{H_i'}}E(\\frac{\\partial L}{\\partial W_i})\n",
    "$$\n",
    "\n",
    "$H_i$ : i層目に関して、前のイテレーションまでの勾配の二乗和（初期値は0）\n",
    "\n",
    "$H_i^{\\prime}$ : 更新した $H_i$\n",
    "\n",
    "《論文》\n",
    "[Duchi JDUCHI, J., & Singer, Y. (2011). Adaptive Subgradient Methods for Online Learning and Stochastic Optimization * Elad Hazan. Journal of Machine Learning Research (Vol. 12).](https://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad:\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        self.h_W = None\n",
    "        self.h_b = None\n",
    "    def update(self, layer):\n",
    "        if (self.h_W is None) and (self.h_b is None):\n",
    "            self.h_W = 0\n",
    "            self.h_b = 0\n",
    "        \n",
    "        self.h_W += (layer.dW ** 2).sum()\n",
    "        self.h_b += (layer.db ** 2).sum()\n",
    "        layer.W -= self.lr * layer.dW / (np.sqrt(self.h_W) + 1e-7)\n",
    "        layer.b -= self.lr * layer.db / (np.sqrt(self.h_b) + 1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題8】クラスの完成\n",
    "任意の構成で学習と推定が行えるScratchDeepNeuralNetrowkClassifierクラスを完成させてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "class ScratchDeepNeuralNetrowkClassifier():\n",
    "    def __init__(self, lr, verbose=True, batch_size=20, max_iter=3):\n",
    "        self.verbose = verbose\n",
    "        self.batch_size = batch_size\n",
    "        self.max_iter = max_iter\n",
    "        self.list_train_loss = []\n",
    "        self.list_test_loss = []\n",
    "        # レイヤの生成\n",
    "        initializer = XavierInitializer()\n",
    "        optimizer = SGD(lr=lr)\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers[\"FC1\"] = FC(784, 100, initializer, optimizer)\n",
    "        self.layers[\"tanh1\"] = Tanh()\n",
    "        self.layers[\"FC2\"] = FC(100, 50, initializer, optimizer)\n",
    "        self.layers[\"tanh2\"] = Tanh()\n",
    "        self.layers[\"FC3\"] = FC(50, 10, initializer, optimizer)\n",
    "        self.lastLayer = Softmax()\n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        flg_test = 0\n",
    "        if (X_val is not None) and (y_val is not None):\n",
    "            flg_test = 1\n",
    "\n",
    "        # 1エポックの繰り返し数\n",
    "        iter_num = int(len(X) / self.batch_size)\n",
    "            \n",
    "        # エポックを複数回繰り返す\n",
    "        for i_ in range(self.max_iter):\n",
    "            # 損失計算用\n",
    "            tmp_list_loss_train = []\n",
    "\n",
    "            # 1エポック\n",
    "            for j_ in range(iter_num):\n",
    "                batch_mask = np.random.choice(X.shape[0], self.batch_size)\n",
    "                X_batch = X[batch_mask]\n",
    "                y_batch = y[batch_mask]\n",
    "                \n",
    "                self._gradient(X_batch, y_batch)\n",
    "                            \n",
    "                tmp_list_loss_train.append(self._loss(X_batch, y_batch))\n",
    "                if self.verbose:\n",
    "                    #verboseをTrueにした際は学習過程などを出力する\n",
    "                    print(loss_train)\n",
    "        \n",
    "            # 損失をインスタンス領域に設定\n",
    "            self.list_train_loss.append(sum(tmp_list_loss_train)/len(tmp_list_loss_train))\n",
    "            if flg_test == 1:\n",
    "                loss_test = self._loss(X_val, y_val)\n",
    "                self.list_test_loss.append(loss_test)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        for layer in self.layers.values():\n",
    "            X = layer.forward(X)\n",
    "            \n",
    "        pred = np.argmax(X, axis=1)\n",
    "        \n",
    "        return pred\n",
    "    \n",
    "    def _loss(self, X, t):\n",
    "        for layer in self.layers.values():\n",
    "            X = layer.forward(X)\n",
    "\n",
    "        return self.lastLayer.forward(X, t)\n",
    "\n",
    "    def _gradient(self, X, t):\n",
    "        self._loss(X, t)\n",
    "        \n",
    "        dout = 1\n",
    "        dout = self.lastLayer.backward(dout)\n",
    "        \n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "                    \n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題9】学習と推定\n",
    "層の数や活性化関数を変えたいくつかのネットワークを作成してください。そして、MNISTのデータを学習・推定し、Accuracyを計算してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# データの読み込み\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# ラベルをone-hot化\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "\n",
    "# 分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.2)\n",
    "y_train = y_train.astype(int)\n",
    "y_val = y_val.astype(int)\n",
    "\n",
    "# cupy用\n",
    "X_train = np.array(X_train)\n",
    "X_val = np.array(X_val)\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = ScratchDeepNeuralNetrowkClassifier(lr=0.1, verbose=False, batch_size=20, max_iter=5)\n",
    "nn.fit(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = np.argmax(y_val, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正答率:0.9236666666666666\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = nn.predict(X_val)\n",
    "# cupy用\n",
    "y_pred = chainer.cuda.to_cpu(y_pred)\n",
    "y_val = chainer.cuda.to_cpu(y_val)\n",
    "\n",
    "accuracy = accuracy_score(y_pred, y_val)\n",
    "print(\"正答率:{}\".format(accuracy))\n",
    "\n",
    "x = numpy.arange(1, len(nn.list_train_loss)+1)\n",
    "plt.plot(x, nn.list_train_loss, label=\"loss\")\n",
    "plt.plot(x, nn.list_test_loss, label=\"val_loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "層の数、大きさを変えて実施してみる。\n",
    "- 7層\n",
    "- 活性化関数：1~3層目；ReLU、4層目；tanh、5,6層目；sigmoid\n",
    "- 最適化関数：AdaGrad\n",
    "- 重みの初期化：He"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from copy import deepcopy\n",
    "\n",
    "class ScratchDeepNeuralNetrowkClassifier():\n",
    "    def __init__(self, lr, verbose=True, batch_size=20, max_iter=3):\n",
    "        self.verbose = verbose\n",
    "        self.batch_size = batch_size\n",
    "        self.max_iter = max_iter\n",
    "        self.list_train_loss = []\n",
    "        self.list_test_loss = []\n",
    "        # レイヤの生成\n",
    "        initializer = HeInitializer()\n",
    "        optimizer = AdaGrad(lr=lr)\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers[\"FC1\"] = FC(784, 500, initializer, deepcopy(optimizer))\n",
    "        self.layers[\"ReLU1\"] = Relu()\n",
    "        self.layers[\"FC2\"] = FC(500, 400, initializer, deepcopy(optimizer))\n",
    "        self.layers[\"ReLU2\"] = Relu()\n",
    "        self.layers[\"FC3\"] = FC(400, 300, initializer, deepcopy(optimizer))\n",
    "        self.layers[\"ReLU3\"] = Relu()\n",
    "        self.layers[\"FC4\"] = FC(300, 200, initializer, deepcopy(optimizer))\n",
    "        self.layers[\"tanh1\"] = Tanh()\n",
    "        self.layers[\"FC5\"] = FC(200, 100, initializer, deepcopy(optimizer))\n",
    "        self.layers[\"sigmoid1\"] = Sigmoid()\n",
    "        self.layers[\"FC6\"] = FC(100, 50, initializer, deepcopy(optimizer))\n",
    "        self.layers[\"sigmoid2\"] = Sigmoid()\n",
    "        self.layers[\"FC7\"] = FC(50, 10, initializer, deepcopy(optimizer))\n",
    "        self.lastLayer = Softmax()\n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        flg_test = 0\n",
    "        if (X_val is not None) and (y_val is not None):\n",
    "            flg_test = 1\n",
    "\n",
    "        # 1エポックの繰り返し数\n",
    "        iter_num = int(len(X) / self.batch_size)\n",
    "                        \n",
    "        # エポックを複数回繰り返す\n",
    "        for i_ in range(self.max_iter):\n",
    "            # 損失計算用\n",
    "            tmp_list_loss_train = []\n",
    "\n",
    "            # 1エポック\n",
    "            for j_ in range(iter_num):\n",
    "                batch_mask = np.random.choice(X.shape[0], self.batch_size)\n",
    "                X_batch = X[batch_mask]\n",
    "                y_batch = y[batch_mask]\n",
    "                \n",
    "                self._gradient(X_batch, y_batch)\n",
    "                            \n",
    "                tmp_list_loss_train.append(self._loss(X_batch, y_batch))\n",
    "                if self.verbose:\n",
    "                    #verboseをTrueにした際は学習過程などを出力する\n",
    "                    print(loss_train)\n",
    "        \n",
    "            # 損失をインスタンス領域に設定\n",
    "            self.list_train_loss.append(sum(tmp_list_loss_train)/len(tmp_list_loss_train))\n",
    "            if flg_test == 1:\n",
    "                loss_test = self._loss(X_val, y_val)\n",
    "                self.list_test_loss.append(loss_test)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        for layer in self.layers.values():\n",
    "            X = layer.forward(X)\n",
    "            \n",
    "        pred = np.argmax(X, axis=1)\n",
    "        \n",
    "        return pred\n",
    "    \n",
    "    def _loss(self, X, t):\n",
    "        for layer in self.layers.values():\n",
    "            X = layer.forward(X)\n",
    "\n",
    "        return self.lastLayer.forward(X, t)\n",
    "\n",
    "    def _gradient(self, X, t):\n",
    "        self._loss(X, t)\n",
    "        \n",
    "        dout = 1\n",
    "        dout = self.lastLayer.backward(dout)\n",
    "        \n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "                    \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正答率:0.9106666666666666\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# データの読み込み\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# ラベルをone-hot化\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "\n",
    "# 分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.2)\n",
    "y_train = y_train.astype(int)\n",
    "y_val = y_val.astype(int)\n",
    "\n",
    "# cupy用\n",
    "X_train = np.array(X_train)\n",
    "X_val = np.array(X_val)\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "nn = ScratchDeepNeuralNetrowkClassifier(lr=0.1, verbose=False, batch_size=20, max_iter=5)\n",
    "nn.fit(X_train, y_train, X_val, y_val)\n",
    "\n",
    "y_val = np.argmax(y_val, axis=1)\n",
    "\n",
    "y_pred = nn.predict(X_val)\n",
    "# cupy用\n",
    "y_pred = chainer.cuda.to_cpu(y_pred)\n",
    "y_val = chainer.cuda.to_cpu(y_val)\n",
    "\n",
    "accuracy = accuracy_score(y_pred, y_val)\n",
    "print(\"正答率:{}\".format(accuracy))\n",
    "\n",
    "x = numpy.arange(1, len(nn.list_train_loss)+1)\n",
    "plt.plot(x, nn.list_train_loss, label=\"loss\")\n",
    "plt.plot(x, nn.list_test_loss, label=\"val_loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "単純に層を増やせば性能のいいモデルが得られるというわけではなさそうだ。\n",
    "性能を上げるためにどのようにモデルを構築すればよいか、ネットで調査してみる。\n",
    "\n",
    "[参考]\n",
    "このノートブックを全実行したときの所要時間だが、CPU,GPUの動作を比較すると以下のとおりであった。\n",
    "- CPU : 6分02秒\n",
    "- GPU(GeForce GTX 1070(8GB)) : 2分38秒\n",
    "\n",
    "GPUの使用率は60%あたりを推移していたが、cupyで取得していた領域は800MBほど。ノートブックはカーネルを落とすか再起動しないとGPUメモリが開放されないので注意する。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
