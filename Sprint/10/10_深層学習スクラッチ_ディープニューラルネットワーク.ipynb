{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/timanishi/.pyenv/versions/3.7.8/lib/python3.7/site-packages/chainer/_environment_check.py:91: UserWarning: \n",
      "--------------------------------------------------------------------------------\n",
      "Multiple installations of CuPy package has been detected.\n",
      "You should select only one package from from ['cupy-cuda102', 'cupy-cuda101', 'cupy-cuda100', 'cupy-cuda92', 'cupy-cuda91', 'cupy-cuda90', 'cupy-cuda80', 'cupy'].\n",
      "Follow these steps to resolve this issue:\n",
      "  1. `pip list` to list CuPy packages installed\n",
      "  2. `pip uninstall <package name>` to uninstall all CuPy packages\n",
      "  3. `pip install <package name>` to install the proper one\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  '''.format(name=name, pkgs=pkgs))\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import cupy as np\n",
    "import chainer.cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ディープニューラルネットワークスクラッチ\n",
    "前回は3層のニューラルネットワークを作成しましたが、今回はこれを任意の層数に拡張しやすいものに書き換えていきます。その上で、活性化関数や初期値、最適化手法について発展的なものを扱えるようにしていきます。\n",
    "\n",
    "このようなスクラッチを行うことで、今後各種フレームワークを利用していくにあたり、内部の動きが想像できることを目指します。\n",
    "\n",
    "名前は新しくScratchDeepNeuralNetrowkClassifierクラスとしてください。\n",
    "\n",
    "#### 層などのクラス化\n",
    "クラスにまとめて行くことで、構成を変更しやすい実装にしていきます。\n",
    "\n",
    "手を加える箇所\n",
    "\n",
    "- 層の数\n",
    "- 層の種類（今後畳み込み層など他のタイプの層が登場する）\n",
    "- 活性化関数の種類\n",
    "- 重みやバイアスの初期化方法\n",
    "- 最適化手法\n",
    "\n",
    "そのために、全結合層、各種活性化関数、重みやバイアスの初期化、最適化手法それぞれのクラスを作成します。\n",
    "\n",
    "実装方法は自由ですが、簡単な例を紹介します。サンプルコード1のように全結合層と活性化関数のインスタンスを作成し、サンプルコード2,3のようにして使用します。それぞれのクラスについてはこのあと解説します。\n",
    "\n",
    "《サンプルコード1》\n",
    "\n",
    "ScratchDeepNeuralNetrowkClassifierのfitメソッド内\n",
    "```\n",
    "# self.sigma : ガウス分布の標準偏差\n",
    "# self.lr : 学習率\n",
    "# self.n_nodes1 : 1層目のノード数\n",
    "# self.n_nodes2 : 2層目のノード数\n",
    "# self.n_output : 出力層のノード数\n",
    "optimizer = SGD(self.lr)\n",
    "self.FC1 = FC(self.n_features, self.n_nodes1, SimpleInitializer(self.sigma), optimizer)\n",
    "self.activation1 = Tanh()\n",
    "self.FC2 = FC(self.n_nodes1, self.n_nodes2, SimpleInitializer(self.sigma), optimizer)\n",
    "self.activation2 = Tanh()\n",
    "self.FC3 = FC(self.n_nodes2, self.n_output, SimpleInitializer(self.sigma), optimizer)\n",
    "self.activation3 = Softmax()\n",
    "```\n",
    "\n",
    "《サンプルコード2》\n",
    "\n",
    "イテレーションごとのフォワード\n",
    "```\n",
    "A1 = self.FC1.forward(X)\n",
    "Z1 = self.activation1.forward(A1)\n",
    "A2 = self.FC2.forward(Z1)\n",
    "Z2 = self.activation2.forward(A2)\n",
    "A3 = self.FC3.forward(Z2)\n",
    "Z3 = self.activation3.forward(A3)\n",
    "```\n",
    "\n",
    "《サンプルコード3》\n",
    "\n",
    "イテレーションごとのバックワード\n",
    "```\n",
    "dA3 = self.activation3.backward(Z3, Y) # 交差エントロピー誤差とソフトマックスを合わせている\n",
    "dZ2 = self.FC3.backward(dA3)\n",
    "dA2 = self.activation2.backward(dZ2)\n",
    "dZ1 = self.FC2.backward(dA2)\n",
    "dA1 = self.activation1.backward(dZ1)\n",
    "dZ0 = self.FC1.backward(dA1) # dZ0は使用しない\n",
    "```\n",
    "\n",
    "### 【問題1】全結合層のクラス化\n",
    "全結合層のクラス化を行なってください。\n",
    "\n",
    "以下に雛形を載せました。コンストラクタで重みやバイアスの初期化をして、あとはフォワードとバックワードのメソッドを用意します。重みW、バイアスB、およびフォワード時の入力Xをインスタンス変数として保持しておくことで、煩雑な入出力は不要になります。\n",
    "\n",
    "なお、インスタンスも引数として渡すことができます。そのため、初期化方法のインスタンスinitializerをコンストラクタで受け取れば、それにより初期化が行われます。渡すインスタンスを変えれば、初期化方法が変えられます。\n",
    "\n",
    "また、引数として自身のインスタンスselfを渡すこともできます。これを利用してself.optimizer.update(self)という風に層の重みの更新が可能です。更新に必要な値は複数ありますが、全て全結合層が持つインスタンス変数にすることができます。\n",
    "\n",
    "初期化方法と最適化手法のクラスについては後述します。\n",
    "\n",
    "《雛形》\n",
    "```\n",
    "class FC:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        pass\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"        \n",
    "        pass\n",
    "        return A\n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        pass\n",
    "        # 更新\n",
    "        self = self.optimizer.update(self)\n",
    "        return dZ\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "class FC:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        self.optimizer = deepcopy(optimizer)\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.W = initializer.W(n_nodes1, n_nodes2)\n",
    "        self.b = initializer.B(n_nodes2)\n",
    "        self.X = None\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"        \n",
    "        self.X = X\n",
    "        out = np.dot(X, self.W) + self.b\n",
    "        \n",
    "        return out\n",
    "\n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        # 更新\n",
    "        batch_size = dA.shape[0]\n",
    "        dX = np.dot(dA, self.W.T)\n",
    "        self.dW = np.dot(self.X.T, dA) / batch_size\n",
    "        self.db = np.sum(dA, axis=0) / batch_size\n",
    "        self = self.optimizer.update(self)\n",
    "        \n",
    "        return dX\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- FCクラスの__init__,forward,backwardメソッドを更新"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題2】初期化方法のクラス化\n",
    "初期化を行うコードをクラス化してください。\n",
    "\n",
    "前述のように、全結合層のコンストラクタに初期化方法のインスタンスを渡せるようにします。以下の雛形に必要なコードを書き加えていってください。標準偏差の値（sigma）はコンストラクタで受け取るようにすることで、全結合層のクラス内にこの値（sigma）を渡さなくてすむようになります。\n",
    "\n",
    "これまで扱ってきた初期化方法はSimpleInitializerクラスと名付けることにします。\n",
    "\n",
    "《雛形》\n",
    "```\n",
    "class SimpleInitializer:\n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      ガウス分布の標準偏差\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W :\n",
    "        \"\"\"\n",
    "        pass\n",
    "        return W\n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B :\n",
    "        \"\"\"\n",
    "        pass\n",
    "        return B\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleInitializer:\n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      ガウス分布の標準偏差\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W :\n",
    "        \"\"\"\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B :\n",
    "        \"\"\"\n",
    "        B = np.zeros(n_nodes2)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SimpleInitializerクラスのW, Bメソッドを更新"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題3】最適化手法のクラス化\n",
    "最適化手法のクラス化を行なってください。\n",
    "\n",
    "最適化手法に関しても初期化方法同様に全結合層にインスタンスとして渡します。バックワードのときにself.optimizer.update(self)のように更新できるようにします。以下の雛形に必要なコードを書き加えていってください。\n",
    "\n",
    "これまで扱ってきた最適化手法はSGDクラス（Stochastic Gradient Descent、確率的勾配降下法）として作成します。\n",
    "\n",
    "雛形\n",
    "```\n",
    "class SGD:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "        layer.W -= self.lr * layer.dW\n",
    "        layer.b -= self.lr * layer.db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題4】活性化関数のクラス化\n",
    "活性化関数のクラス化を行なってください。\n",
    "\n",
    "ソフトマックス関数のバックプロパゲーションには交差エントロピー誤差の計算も含む実装を行うことで計算が簡略化されます。\n",
    "\n",
    "#### 発展的要素\n",
    "活性化関数や重みの初期値、最適化手法に関してこれまで見てきた以外のものを実装していきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid():\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        out = 1 / (1 + np.exp(-X))\n",
    "        self.out = out\n",
    "        \n",
    "        return out\n",
    "        \n",
    "    def backward(self, dout):\n",
    "        dX = dout*(1.0 - self.out)*self.out\n",
    "        \n",
    "        return dX\n",
    "\n",
    "\n",
    "class Tanh():\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        out = np.tanh(X)\n",
    "        self.out = out\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dX = dout*(1 - self.out**2)\n",
    "        \n",
    "        return dX\n",
    "\n",
    "    \n",
    "class Softmax():\n",
    "    def __init__(self):\n",
    "        self.loss = None\n",
    "        self.y = None\n",
    "        self.t = None\n",
    "    \n",
    "    def _softmax(self, X):\n",
    "        X = X - np.max(X, axis=-1, keepdims=True)\n",
    "        y = np.exp(X) / np.sum(np.exp(X), axis=-1, keepdims=True)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    def _cross_entropy_error(self, y, t):\n",
    "        batch_size = y.shape[0]\n",
    "        \n",
    "        return -np.sum(t * np.log(y + 1e-7)) / batch_size\n",
    "    \n",
    "    def forward(self, X, t):\n",
    "        self.t = t\n",
    "        self.y = self._softmax(X)\n",
    "        self.loss = self._cross_entropy_error(self.y, self.t)\n",
    "        \n",
    "        return self.loss\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        dX = (self.y - self.t) / batch_size\n",
    "        \n",
    "        return dX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題5】ReLUクラスの作成\n",
    "現在一般的に使われている活性化関数であるReLU（Rectified Linear Unit）をReLUクラスとして実装してください。\n",
    "\n",
    "ReLUは以下の数式です。\n",
    "$$\n",
    "f(x)=ReLU(x)=\\begin{cases}x \\quad x \\geqq 0 \\\\\n",
    "                0 \\quad x < 0 \\\\\n",
    "                \\end{cases}\n",
    "$$\n",
    "$x$ : ある特徴量。スカラー\n",
    "\n",
    "実装上はnp.maximumを使い配列に対してまとめて計算が可能です。\n",
    "\n",
    "[numpy.maximum — NumPy v1.15 Manual](https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.maximum.html)\n",
    "\n",
    "一方、バックプロパゲーションのための $x$ に関する $f(x)$ の微分は以下のようになります。\n",
    "$$\n",
    "\\frac{\\partial f(x)}{\\partial x}=\\begin{cases}1\\space if \\quad x > 0 \\\\\n",
    "                0\\space if \\quad x \\leqq 0 \\\\\n",
    "                \\end{cases}\n",
    "$$\n",
    "\n",
    "数学的には微分可能ではないですが、 $x=0$ のとき $0$ とすることで対応しています。\n",
    "\n",
    "フォワード時の $x$ の正負により、勾配を逆伝播するかどうかが決まるということになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.mask = (x < 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題6】重みの初期値\n",
    "ここまでは重みやバイアスの初期値は単純にガウス分布で、標準偏差をハイパーパラメータとして扱ってきました。しかし、どのような値にすると良いかが知られています。シグモイド関数やハイパボリックタンジェント関数のときは Xavierの初期値 （またはGlorotの初期値）、ReLUのときは Heの初期値 が使われます。\n",
    "\n",
    "XavierInitializerクラスと、HeInitializerクラスを作成してください。\n",
    "\n",
    "#### Xavierの初期値\n",
    "Xavierの初期値における標準偏差 $\\sigma$ は次の式で求められます。\n",
    "$$\n",
    "\\sigma=\\frac{1}{\\sqrt{n}}\n",
    "$$\n",
    "$n$ : 前の層のノード数\n",
    "\n",
    "《論文》\n",
    "\n",
    "[Glorot, X., & Bengio, Y. (n.d.). Understanding the difficulty of training deep feedforward neural networks.](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf)\n",
    "\n",
    "#### Heの初期値\n",
    "Heの初期値における標準偏差 $\\sigma$ は次の式で求められます。\n",
    "$$\n",
    "\\sigma=\\sqrt{\\frac{2}{n}}\n",
    "$$\n",
    "$n$ : 前の層のノード数\n",
    "\n",
    "《論文》\n",
    "\n",
    "[He, K., Zhang, X., Ren, S., & Sun, J. (2015). Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification.](https://arxiv.org/pdf/1502.01852.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XavierInitializer:\n",
    "    def __init__(self):\n",
    "        self.sigma = None\n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        self.sigma = 1 / np.sqrt(n_nodes1)\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "    def B(self, n_nodes2):\n",
    "        B = np.zeros(n_nodes2)\n",
    "        return B\n",
    "\n",
    "\n",
    "class HeInitializer:\n",
    "    def __init__(self):\n",
    "        self.sigma = None\n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        self.sigma = np.sqrt(2 / n_nodes1)\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "    def B(self, n_nodes2):\n",
    "        B = np.zeros(n_nodes2)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題7】最適化手法\n",
    "学習率は学習過程で変化させていく方法が一般的です。基本的な手法である AdaGrad のクラスを作成してください。\n",
    "\n",
    "まず、これまで使ってきたSGDを確認します。\n",
    "$$\n",
    "W_i'=W_i-\\alpha E(\\frac{\\partial L}{\\partial W_i}) \\\\\n",
    "B_i'=B_i-\\alpha E(\\frac{\\partial L}{\\partial B_i})\n",
    "$$\n",
    "$\\alpha$ : 学習率（層ごとに変えることも可能だが、基本的には全て同じとする）\n",
    "\n",
    "$\\frac{\\partial L}{\\partial W_i}$ : $W_i$ に関する損失 $L$ の勾配\n",
    "\n",
    "$\\frac{\\partial L}{\\partial B_i}$ : $B_i$ に関する損失 $L$ の勾配\n",
    "\n",
    "$E()$ : ミニバッチ方向にベクトルの平均を計算\n",
    "\n",
    "続いて、AdaGradです。バイアスの数式は省略しますが、重みと同様のことをします。\n",
    "\n",
    "更新された分だけその重みに対する学習率を徐々に下げていきます。イテレーションごとの勾配の二乗和 $H$ を保存しておき、その分だけ学習率を小さくします。\n",
    "\n",
    "学習率は重み一つひとつに対して異なることになります。\n",
    "\n",
    "$$\n",
    "H_i'=H_i+E(\\frac{\\partial L}{\\partial W_i})×E(\\frac{\\partial L}{\\partial W_i}) \\\\\n",
    "W_i'=W_i-\\alpha\\frac{1}{\\sqrt{H_i'}}E(\\frac{\\partial L}{\\partial W_i})\n",
    "$$\n",
    "\n",
    "$H_i$ : i層目に関して、前のイテレーションまでの勾配の二乗和（初期値は0）\n",
    "\n",
    "$H_i^{\\prime}$ : 更新した $H_i$\n",
    "\n",
    "《論文》\n",
    "[Duchi JDUCHI, J., & Singer, Y. (2011). Adaptive Subgradient Methods for Online Learning and Stochastic Optimization * Elad Hazan. Journal of Machine Learning Research (Vol. 12).](https://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad:\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        self.h_W = None\n",
    "        self.h_b = None\n",
    "    def update(self, layer):\n",
    "        if (self.h_W is None) and (self.h_b is None):\n",
    "            self.h_W = 0\n",
    "            self.h_b = 0\n",
    "        \n",
    "        self.h_W += (layer.dW ** 2).sum()\n",
    "        self.h_b += (layer.db ** 2).sum()\n",
    "        layer.W -= self.lr * layer.dW / (np.sqrt(self.h_W) + 1e-7)\n",
    "        layer.b -= self.lr * layer.db / (np.sqrt(self.h_b) + 1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題8】クラスの完成\n",
    "任意の構成で学習と推定が行えるScratchDeepNeuralNetrowkClassifierクラスを完成させてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "class ScratchDeepNeuralNetrowkClassifier():\n",
    "    def __init__(self, lr, verbose=True, batch_size=20, max_iter=3):\n",
    "        self.verbose = verbose\n",
    "        self.batch_size = batch_size\n",
    "        self.max_iter = max_iter\n",
    "        self.list_train_loss = []\n",
    "        self.list_test_loss = []\n",
    "        # レイヤの生成\n",
    "        initializer = XavierInitializer()\n",
    "        optimizer = SGD(lr=lr)\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers[\"FC1\"] = FC(784, 100, initializer, optimizer)\n",
    "        self.layers[\"tanh1\"] = Tanh()\n",
    "        self.layers[\"FC2\"] = FC(100, 50, initializer, optimizer)\n",
    "        self.layers[\"tanh2\"] = Tanh()\n",
    "        self.layers[\"FC3\"] = FC(50, 10, initializer, optimizer)\n",
    "        self.lastLayer = Softmax()\n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        flg_test = 0\n",
    "        if (X_val is not None) and (y_val is not None):\n",
    "            flg_test = 1\n",
    "\n",
    "        # 1エポックの繰り返し数\n",
    "        iter_num = int(len(X) / self.batch_size)\n",
    "            \n",
    "        # エポックを複数回繰り返す\n",
    "        for i_ in range(self.max_iter):\n",
    "            # 損失計算用\n",
    "            tmp_list_loss_train = []\n",
    "\n",
    "            # 1エポック\n",
    "            for j_ in range(iter_num):\n",
    "                batch_mask = np.random.choice(X.shape[0], self.batch_size)\n",
    "                X_batch = X[batch_mask]\n",
    "                y_batch = y[batch_mask]\n",
    "                \n",
    "                self._gradient(X_batch, y_batch)\n",
    "                            \n",
    "                tmp_list_loss_train.append(self._loss(X_batch, y_batch))\n",
    "                if self.verbose:\n",
    "                    #verboseをTrueにした際は学習過程などを出力する\n",
    "                    print(loss_train)\n",
    "        \n",
    "            # 損失をインスタンス領域に設定\n",
    "            self.list_train_loss.append(sum(tmp_list_loss_train)/len(tmp_list_loss_train))\n",
    "            if flg_test == 1:\n",
    "                loss_test = self._loss(X_val, y_val)\n",
    "                self.list_test_loss.append(loss_test)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        for layer in self.layers.values():\n",
    "            X = layer.forward(X)\n",
    "            \n",
    "        pred = np.argmax(X, axis=1)\n",
    "        \n",
    "        return pred\n",
    "    \n",
    "    def _loss(self, X, t):\n",
    "        for layer in self.layers.values():\n",
    "            X = layer.forward(X)\n",
    "\n",
    "        return self.lastLayer.forward(X, t)\n",
    "\n",
    "    def _gradient(self, X, t):\n",
    "        self._loss(X, t)\n",
    "        \n",
    "        dout = 1\n",
    "        dout = self.lastLayer.backward(dout)\n",
    "        \n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "                    \n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題9】学習と推定\n",
    "層の数や活性化関数を変えたいくつかのネットワークを作成してください。そして、MNISTのデータを学習・推定し、Accuracyを計算してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# データの読み込み\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# ラベルをone-hot化\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "\n",
    "# 分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.2)\n",
    "y_train = y_train.astype(int)\n",
    "y_val = y_val.astype(int)\n",
    "\n",
    "# cupy用\n",
    "X_train = np.array(X_train)\n",
    "X_val = np.array(X_val)\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = ScratchDeepNeuralNetrowkClassifier(lr=0.1, verbose=False, batch_size=20, max_iter=5)\n",
    "nn.fit(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = np.argmax(y_val, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正答率:0.9201666666666667\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = nn.predict(X_val)\n",
    "# cupy用\n",
    "y_pred = chainer.cuda.to_cpu(y_pred)\n",
    "y_val = chainer.cuda.to_cpu(y_val)\n",
    "\n",
    "accuracy = accuracy_score(y_pred, y_val)\n",
    "print(\"正答率:{}\".format(accuracy))\n",
    "\n",
    "x = numpy.arange(1, len(nn.list_train_loss)+1)\n",
    "plt.plot(x, nn.list_train_loss, label=\"loss\")\n",
    "plt.plot(x, nn.list_test_loss, label=\"val_loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "層の数、大きさを変えて実施してみる。\n",
    "- 7層\n",
    "- 活性化関数：1~3層目；ReLU、4層目；tanh、5,6層目；sigmoid\n",
    "- 最適化関数：AdaGrad\n",
    "- 重みの初期化：He"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from copy import deepcopy\n",
    "\n",
    "class ScratchDeepNeuralNetrowkClassifier():\n",
    "    def __init__(self, lr, verbose=True, batch_size=20, max_iter=3):\n",
    "        self.verbose = verbose\n",
    "        self.batch_size = batch_size\n",
    "        self.max_iter = max_iter\n",
    "        self.list_train_loss = []\n",
    "        self.list_test_loss = []\n",
    "        # レイヤの生成\n",
    "        initializer = HeInitializer()\n",
    "        optimizer = AdaGrad(lr=lr)\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers[\"FC1\"] = FC(784, 500, initializer, optimizer)\n",
    "        self.layers[\"ReLU1\"] = Relu()\n",
    "        self.layers[\"FC2\"] = FC(500, 400, initializer, optimizer)\n",
    "        self.layers[\"ReLU2\"] = Relu()\n",
    "        self.layers[\"FC3\"] = FC(400, 300, initializer, optimizer)\n",
    "        self.layers[\"ReLU3\"] = Relu()\n",
    "        self.layers[\"FC4\"] = FC(300, 200, initializer, optimizer)\n",
    "        self.layers[\"tanh1\"] = Tanh()\n",
    "        self.layers[\"FC5\"] = FC(200, 100, initializer, optimizer)\n",
    "        self.layers[\"sigmoid1\"] = Sigmoid()\n",
    "        self.layers[\"FC6\"] = FC(100, 50, initializer, optimizer)\n",
    "        self.layers[\"sigmoid2\"] = Sigmoid()\n",
    "        self.layers[\"FC7\"] = FC(50, 10, initializer, optimizer)\n",
    "        self.lastLayer = Softmax()\n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        flg_test = 0\n",
    "        if (X_val is not None) and (y_val is not None):\n",
    "            flg_test = 1\n",
    "\n",
    "        # 1エポックの繰り返し数\n",
    "        iter_num = int(len(X) / self.batch_size)\n",
    "                        \n",
    "        # エポックを複数回繰り返す\n",
    "        for i_ in range(self.max_iter):\n",
    "            # 損失計算用\n",
    "            tmp_list_loss_train = []\n",
    "\n",
    "            # 1エポック\n",
    "            for j_ in range(iter_num):\n",
    "                batch_mask = np.random.choice(X.shape[0], self.batch_size)\n",
    "                X_batch = X[batch_mask]\n",
    "                y_batch = y[batch_mask]\n",
    "                \n",
    "                self._gradient(X_batch, y_batch)\n",
    "                            \n",
    "                tmp_list_loss_train.append(self._loss(X_batch, y_batch))\n",
    "                if self.verbose:\n",
    "                    #verboseをTrueにした際は学習過程などを出力する\n",
    "                    print(loss_train)\n",
    "        \n",
    "            # 損失をインスタンス領域に設定\n",
    "            self.list_train_loss.append(sum(tmp_list_loss_train)/len(tmp_list_loss_train))\n",
    "            if flg_test == 1:\n",
    "                loss_test = self._loss(X_val, y_val)\n",
    "                self.list_test_loss.append(loss_test)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        for layer in self.layers.values():\n",
    "            X = layer.forward(X)\n",
    "            \n",
    "        pred = np.argmax(X, axis=1)\n",
    "        \n",
    "        return pred\n",
    "    \n",
    "    def _loss(self, X, t):\n",
    "        for layer in self.layers.values():\n",
    "            X = layer.forward(X)\n",
    "\n",
    "        return self.lastLayer.forward(X, t)\n",
    "\n",
    "    def _gradient(self, X, t):\n",
    "        self._loss(X, t)\n",
    "        \n",
    "        dout = 1\n",
    "        dout = self.lastLayer.backward(dout)\n",
    "        \n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "                    \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正答率:0.9105\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# データの読み込み\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# ラベルをone-hot化\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "\n",
    "# 分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.2)\n",
    "y_train = y_train.astype(int)\n",
    "y_val = y_val.astype(int)\n",
    "\n",
    "# cupy用\n",
    "X_train = np.array(X_train)\n",
    "X_val = np.array(X_val)\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "nn = ScratchDeepNeuralNetrowkClassifier(lr=0.1, verbose=False, batch_size=20, max_iter=5)\n",
    "nn.fit(X_train, y_train, X_val, y_val)\n",
    "\n",
    "y_val = np.argmax(y_val, axis=1)\n",
    "\n",
    "y_pred = nn.predict(X_val)\n",
    "# cupy用\n",
    "y_pred = chainer.cuda.to_cpu(y_pred)\n",
    "y_val = chainer.cuda.to_cpu(y_val)\n",
    "\n",
    "accuracy = accuracy_score(y_pred, y_val)\n",
    "print(\"正答率:{}\".format(accuracy))\n",
    "\n",
    "x = numpy.arange(1, len(nn.list_train_loss)+1)\n",
    "plt.plot(x, nn.list_train_loss, label=\"loss\")\n",
    "plt.plot(x, nn.list_test_loss, label=\"val_loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "単純に層を増やせば性能のいいモデルが得られるというわけではなさそうだ。\n",
    "性能を上げるためにどのようにモデルを構築すればよいか、ネットで調査してみる。\n",
    "\n",
    "[参考]\n",
    "このノートブックを全実行したときの所要時間だが、CPU,GPUの動作を比較すると以下のとおりであった。\n",
    "- CPU : 6分02秒\n",
    "- GPU(GeForce GTX 1070(8GB)) : 2分38秒\n",
    "\n",
    "GPUの使用率は60%あたりを推移していたが、cupyで取得していた領域は800MBほど。ノートブックはカーネルを落とすか再起動しないとGPUメモリが開放されないので注意する。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
