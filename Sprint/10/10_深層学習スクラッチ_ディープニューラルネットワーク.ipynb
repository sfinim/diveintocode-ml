{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/timanishi/.pyenv/versions/3.7.8/lib/python3.7/site-packages/chainer/_environment_check.py:91: UserWarning: \n",
      "--------------------------------------------------------------------------------\n",
      "Multiple installations of CuPy package has been detected.\n",
      "You should select only one package from from ['cupy-cuda102', 'cupy-cuda101', 'cupy-cuda100', 'cupy-cuda92', 'cupy-cuda91', 'cupy-cuda90', 'cupy-cuda80', 'cupy'].\n",
      "Follow these steps to resolve this issue:\n",
      "  1. `pip list` to list CuPy packages installed\n",
      "  2. `pip uninstall <package name>` to uninstall all CuPy packages\n",
      "  3. `pip install <package name>` to install the proper one\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  '''.format(name=name, pkgs=pkgs))\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import cupy as np\n",
    "import chainer.cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ディープニューラルネットワークスクラッチ\n",
    "前回は3層のニューラルネットワークを作成しましたが、今回はこれを任意の層数に拡張しやすいものに書き換えていきます。その上で、活性化関数や初期値、最適化手法について発展的なものを扱えるようにしていきます。\n",
    "\n",
    "このようなスクラッチを行うことで、今後各種フレームワークを利用していくにあたり、内部の動きが想像できることを目指します。\n",
    "\n",
    "名前は新しくScratchDeepNeuralNetrowkClassifierクラスとしてください。\n",
    "\n",
    "#### 層などのクラス化\n",
    "クラスにまとめて行くことで、構成を変更しやすい実装にしていきます。\n",
    "\n",
    "手を加える箇所\n",
    "\n",
    "- 層の数\n",
    "- 層の種類（今後畳み込み層など他のタイプの層が登場する）\n",
    "- 活性化関数の種類\n",
    "- 重みやバイアスの初期化方法\n",
    "- 最適化手法\n",
    "\n",
    "そのために、全結合層、各種活性化関数、重みやバイアスの初期化、最適化手法それぞれのクラスを作成します。\n",
    "\n",
    "実装方法は自由ですが、簡単な例を紹介します。サンプルコード1のように全結合層と活性化関数のインスタンスを作成し、サンプルコード2,3のようにして使用します。それぞれのクラスについてはこのあと解説します。\n",
    "\n",
    "《サンプルコード1》\n",
    "\n",
    "ScratchDeepNeuralNetrowkClassifierのfitメソッド内\n",
    "```\n",
    "# self.sigma : ガウス分布の標準偏差\n",
    "# self.lr : 学習率\n",
    "# self.n_nodes1 : 1層目のノード数\n",
    "# self.n_nodes2 : 2層目のノード数\n",
    "# self.n_output : 出力層のノード数\n",
    "optimizer = SGD(self.lr)\n",
    "self.FC1 = FC(self.n_features, self.n_nodes1, SimpleInitializer(self.sigma), optimizer)\n",
    "self.activation1 = Tanh()\n",
    "self.FC2 = FC(self.n_nodes1, self.n_nodes2, SimpleInitializer(self.sigma), optimizer)\n",
    "self.activation2 = Tanh()\n",
    "self.FC3 = FC(self.n_nodes2, self.n_output, SimpleInitializer(self.sigma), optimizer)\n",
    "self.activation3 = Softmax()\n",
    "```\n",
    "\n",
    "《サンプルコード2》\n",
    "\n",
    "イテレーションごとのフォワード\n",
    "```\n",
    "A1 = self.FC1.forward(X)\n",
    "Z1 = self.activation1.forward(A1)\n",
    "A2 = self.FC2.forward(Z1)\n",
    "Z2 = self.activation2.forward(A2)\n",
    "A3 = self.FC3.forward(Z2)\n",
    "Z3 = self.activation3.forward(A3)\n",
    "```\n",
    "\n",
    "《サンプルコード3》\n",
    "\n",
    "イテレーションごとのバックワード\n",
    "```\n",
    "dA3 = self.activation3.backward(Z3, Y) # 交差エントロピー誤差とソフトマックスを合わせている\n",
    "dZ2 = self.FC3.backward(dA3)\n",
    "dA2 = self.activation2.backward(dZ2)\n",
    "dZ1 = self.FC2.backward(dA2)\n",
    "dA1 = self.activation1.backward(dZ1)\n",
    "dZ0 = self.FC1.backward(dA1) # dZ0は使用しない\n",
    "```\n",
    "\n",
    "### 【問題1】全結合層のクラス化\n",
    "全結合層のクラス化を行なってください。\n",
    "\n",
    "以下に雛形を載せました。コンストラクタで重みやバイアスの初期化をして、あとはフォワードとバックワードのメソッドを用意します。重みW、バイアスB、およびフォワード時の入力Xをインスタンス変数として保持しておくことで、煩雑な入出力は不要になります。\n",
    "\n",
    "なお、インスタンスも引数として渡すことができます。そのため、初期化方法のインスタンスinitializerをコンストラクタで受け取れば、それにより初期化が行われます。渡すインスタンスを変えれば、初期化方法が変えられます。\n",
    "\n",
    "また、引数として自身のインスタンスselfを渡すこともできます。これを利用してself.optimizer.update(self)という風に層の重みの更新が可能です。更新に必要な値は複数ありますが、全て全結合層が持つインスタンス変数にすることができます。\n",
    "\n",
    "初期化方法と最適化手法のクラスについては後述します。\n",
    "\n",
    "《雛形》\n",
    "```\n",
    "class FC:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        pass\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"        \n",
    "        pass\n",
    "        return A\n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        pass\n",
    "        # 更新\n",
    "        self = self.optimizer.update(self)\n",
    "        return dZ\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.W = initializer.W(n_nodes1, n_nodes2)\n",
    "        self.b = initializer.B(n_nodes2)\n",
    "        self.X = None\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"        \n",
    "        self.X = X\n",
    "        out = np.dot(X, self.W) + self.b\n",
    "        \n",
    "        return out\n",
    "\n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        # 更新\n",
    "        batch_size = dA.shape[0]\n",
    "        dX = np.dot(dA, self.W.T)\n",
    "        self.dW = np.dot(self.X.T, dA) / batch_size\n",
    "        self.db = np.sum(dA, axis=0) / batch_size\n",
    "        self = self.optimizer.update(self)\n",
    "        \n",
    "        return dX\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- FCクラスの__init__,forward,backwardメソッドを更新"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題2】初期化方法のクラス化\n",
    "初期化を行うコードをクラス化してください。\n",
    "\n",
    "前述のように、全結合層のコンストラクタに初期化方法のインスタンスを渡せるようにします。以下の雛形に必要なコードを書き加えていってください。標準偏差の値（sigma）はコンストラクタで受け取るようにすることで、全結合層のクラス内にこの値（sigma）を渡さなくてすむようになります。\n",
    "\n",
    "これまで扱ってきた初期化方法はSimpleInitializerクラスと名付けることにします。\n",
    "\n",
    "《雛形》\n",
    "```\n",
    "class SimpleInitializer:\n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      ガウス分布の標準偏差\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W :\n",
    "        \"\"\"\n",
    "        pass\n",
    "        return W\n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B :\n",
    "        \"\"\"\n",
    "        pass\n",
    "        return B\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleInitializer:\n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      ガウス分布の標準偏差\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W :\n",
    "        \"\"\"\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B :\n",
    "        \"\"\"\n",
    "        B = np.zeros(n_nodes2)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SimpleInitializerクラスのW, Bメソッドを更新"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題3】最適化手法のクラス化\n",
    "最適化手法のクラス化を行なってください。\n",
    "\n",
    "最適化手法に関しても初期化方法同様に全結合層にインスタンスとして渡します。バックワードのときにself.optimizer.update(self)のように更新できるようにします。以下の雛形に必要なコードを書き加えていってください。\n",
    "\n",
    "これまで扱ってきた最適化手法はSGDクラス（Stochastic Gradient Descent、確率的勾配降下法）として作成します。\n",
    "\n",
    "雛形\n",
    "```\n",
    "class SGD:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "        layer.W -= self.lr * layer.dW\n",
    "        layer.b -= self.lr * layer.db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題4】活性化関数のクラス化\n",
    "活性化関数のクラス化を行なってください。\n",
    "\n",
    "ソフトマックス関数のバックプロパゲーションには交差エントロピー誤差の計算も含む実装を行うことで計算が簡略化されます。\n",
    "\n",
    "#### 発展的要素\n",
    "活性化関数や重みの初期値、最適化手法に関してこれまで見てきた以外のものを実装していきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid():\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        out = 1 / (1 + np.exp(-X))\n",
    "        self.out = out\n",
    "        \n",
    "        return out\n",
    "        \n",
    "    def backward(self, dout):\n",
    "        dX = dout*(1.0 - self.out)*self.out\n",
    "        \n",
    "        return dX\n",
    "\n",
    "\n",
    "class Tanh():\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        out = np.tanh(X)\n",
    "        self.out = out\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dX = dout*(1 - self.out**2)\n",
    "        \n",
    "        return dX\n",
    "\n",
    "    \n",
    "class Softmax():\n",
    "    def __init__(self):\n",
    "        self.loss = None\n",
    "        self.y = None\n",
    "        self.t = None\n",
    "    \n",
    "    def _softmax(self, X):\n",
    "        X = X - np.max(X, axis=-1, keepdims=True)\n",
    "        y = np.exp(X) / np.sum(np.exp(X), axis=-1, keepdims=True)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    def _cross_entropy_error(self, y, t):\n",
    "        batch_size = y.shape[0]\n",
    "        \n",
    "        return -np.sum(t * np.log(y + 1e-7)) / batch_size\n",
    "    \n",
    "    def forward(self, X, t):\n",
    "        self.t = t\n",
    "        self.y = self._softmax(X)\n",
    "        self.loss = self._cross_entropy_error(self.y, self.t)\n",
    "        \n",
    "        return self.loss\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        dX = (self.y - self.t) / batch_size\n",
    "        \n",
    "        return dX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題5】ReLUクラスの作成\n",
    "現在一般的に使われている活性化関数であるReLU（Rectified Linear Unit）をReLUクラスとして実装してください。\n",
    "\n",
    "ReLUは以下の数式です。\n",
    "$$\n",
    "f(x)=ReLU(x)=\\begin{cases}x \\quad x \\geqq 0 \\\\\n",
    "                0 \\quad x < 0 \\\\\n",
    "                \\end{cases}\n",
    "$$\n",
    "$x$ : ある特徴量。スカラー\n",
    "\n",
    "実装上はnp.maximumを使い配列に対してまとめて計算が可能です。\n",
    "\n",
    "[numpy.maximum — NumPy v1.15 Manual](https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.maximum.html)\n",
    "\n",
    "一方、バックプロパゲーションのための $x$ に関する $f(x)$ の微分は以下のようになります。\n",
    "$$\n",
    "\\frac{\\partial f(x)}{\\partial x}=\\begin{cases}1\\space if \\quad x > 0 \\\\\n",
    "                0\\space if \\quad x \\leqq 0 \\\\\n",
    "                \\end{cases}\n",
    "$$\n",
    "\n",
    "数学的には微分可能ではないですが、 $x=0$ のとき $0$ とすることで対応しています。\n",
    "\n",
    "フォワード時の $x$ の正負により、勾配を逆伝播するかどうかが決まるということになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.mask = (x < 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題6】重みの初期値\n",
    "ここまでは重みやバイアスの初期値は単純にガウス分布で、標準偏差をハイパーパラメータとして扱ってきました。しかし、どのような値にすると良いかが知られています。シグモイド関数やハイパボリックタンジェント関数のときは Xavierの初期値 （またはGlorotの初期値）、ReLUのときは Heの初期値 が使われます。\n",
    "\n",
    "XavierInitializerクラスと、HeInitializerクラスを作成してください。\n",
    "\n",
    "#### Xavierの初期値\n",
    "Xavierの初期値における標準偏差 $\\sigma$ は次の式で求められます。\n",
    "$$\n",
    "\\sigma=\\frac{1}{\\sqrt{n}}\n",
    "$$\n",
    "$n$ : 前の層のノード数\n",
    "\n",
    "《論文》\n",
    "\n",
    "[Glorot, X., & Bengio, Y. (n.d.). Understanding the difficulty of training deep feedforward neural networks.](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf)\n",
    "\n",
    "#### Heの初期値\n",
    "Heの初期値における標準偏差 $\\sigma$ は次の式で求められます。\n",
    "$$\n",
    "\\sigma=\\sqrt{\\frac{2}{n}}\n",
    "$$\n",
    "$n$ : 前の層のノード数\n",
    "\n",
    "《論文》\n",
    "\n",
    "[He, K., Zhang, X., Ren, S., & Sun, J. (2015). Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification.](https://arxiv.org/pdf/1502.01852.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XavierInitializer:\n",
    "    def __init__(self):\n",
    "        self.sigma = None\n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        self.sigma = 1 / np.sqrt(n_nodes1)\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "    def B(self, n_nodes2):\n",
    "        B = np.zeros(n_nodes2)\n",
    "        return B\n",
    "\n",
    "\n",
    "class HeInitializer:\n",
    "    def __init__(self):\n",
    "        self.sigma = None\n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        self.sigma = np.sqrt(2 / n_nodes1)\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "    def B(self, n_nodes2):\n",
    "        B = np.zeros(n_nodes2)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題7】最適化手法\n",
    "学習率は学習過程で変化させていく方法が一般的です。基本的な手法である AdaGrad のクラスを作成してください。\n",
    "\n",
    "まず、これまで使ってきたSGDを確認します。\n",
    "$$\n",
    "W_i'=W_i-\\alpha E(\\frac{\\partial L}{\\partial W_i}) \\\\\n",
    "B_i'=B_i-\\alpha E(\\frac{\\partial L}{\\partial B_i})\n",
    "$$\n",
    "$\\alpha$ : 学習率（層ごとに変えることも可能だが、基本的には全て同じとする）\n",
    "\n",
    "$\\frac{\\partial L}{\\partial W_i}$ : $W_i$ に関する損失 $L$ の勾配\n",
    "\n",
    "$\\frac{\\partial L}{\\partial B_i}$ : $B_i$ に関する損失 $L$ の勾配\n",
    "\n",
    "$E()$ : ミニバッチ方向にベクトルの平均を計算\n",
    "\n",
    "続いて、AdaGradです。バイアスの数式は省略しますが、重みと同様のことをします。\n",
    "\n",
    "更新された分だけその重みに対する学習率を徐々に下げていきます。イテレーションごとの勾配の二乗和 $H$ を保存しておき、その分だけ学習率を小さくします。\n",
    "\n",
    "学習率は重み一つひとつに対して異なることになります。\n",
    "\n",
    "$$\n",
    "H_i'=H_i+E(\\frac{\\partial L}{\\partial W_i})×E(\\frac{\\partial L}{\\partial W_i}) \\\\\n",
    "W_i'=W_i-\\alpha\\frac{1}{\\sqrt{H_i'}}E(\\frac{\\partial L}{\\partial W_i})\n",
    "$$\n",
    "\n",
    "$H_i$ : i層目に関して、前のイテレーションまでの勾配の二乗和（初期値は0）\n",
    "\n",
    "$H_i^{\\prime}$ : 更新した $H_i$\n",
    "\n",
    "《論文》\n",
    "[Duchi JDUCHI, J., & Singer, Y. (2011). Adaptive Subgradient Methods for Online Learning and Stochastic Optimization * Elad Hazan. Journal of Machine Learning Research (Vol. 12).](https://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad:\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        self.h_W = None\n",
    "        self.h_b = None\n",
    "    def update(self, layer):\n",
    "        if (self.h_W is None) and (self.h_b is None):\n",
    "            self.h_W = 0\n",
    "            self.h_b = 0\n",
    "        \n",
    "        self.h_W += (layer.dW ** 2).sum()\n",
    "        self.h_b += (layer.db ** 2).sum()\n",
    "        layer.W -= self.lr * layer.dW / (np.sqrt(self.h_W) + 1e-7)\n",
    "        layer.b -= self.lr * layer.db / (np.sqrt(self.h_b) + 1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題8】クラスの完成\n",
    "任意の構成で学習と推定が行えるScratchDeepNeuralNetrowkClassifierクラスを完成させてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "class ScratchDeepNeuralNetrowkClassifier():\n",
    "    def __init__(self, lr, verbose=True, batch_size=20, max_iter=3):\n",
    "        self.verbose = verbose\n",
    "        self.batch_size = batch_size\n",
    "        self.max_iter = max_iter\n",
    "        self.list_train_loss = []\n",
    "        self.list_test_loss = []\n",
    "        # レイヤの生成\n",
    "        initializer = XavierInitializer()\n",
    "        optimizer = SGD(lr=lr)\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers[\"FC1\"] = FC(784, 100, initializer, optimizer)\n",
    "        self.layers[\"tanh1\"] = Tanh()\n",
    "        self.layers[\"FC2\"] = FC(100, 50, initializer, optimizer)\n",
    "        self.layers[\"tanh2\"] = Tanh()\n",
    "        self.layers[\"FC3\"] = FC(50, 10, initializer, optimizer)\n",
    "        self.lastLayer = Softmax()\n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        flg_test = 0\n",
    "        if (X_val is not None) and (y_val is not None):\n",
    "            flg_test = 1\n",
    "\n",
    "        # 1エポックの繰り返し数\n",
    "        iter_num = int(len(X) / self.batch_size)\n",
    "            \n",
    "        # エポックを複数回繰り返す\n",
    "        for i_ in range(self.max_iter):\n",
    "            # 損失計算用\n",
    "            tmp_list_loss_train = []\n",
    "\n",
    "            # 1エポック\n",
    "            for j_ in range(iter_num):\n",
    "                batch_mask = np.random.choice(X.shape[0], self.batch_size)\n",
    "                X_batch = X[batch_mask]\n",
    "                y_batch = y[batch_mask]\n",
    "                \n",
    "                self._gradient(X_batch, y_batch)\n",
    "                            \n",
    "                tmp_list_loss_train.append(self._loss(X_batch, y_batch))\n",
    "                if self.verbose:\n",
    "                    #verboseをTrueにした際は学習過程などを出力する\n",
    "                    print(loss_train)\n",
    "        \n",
    "            # 損失をインスタンス領域に設定\n",
    "            self.list_train_loss.append(sum(tmp_list_loss_train)/len(tmp_list_loss_train))\n",
    "            if flg_test == 1:\n",
    "                loss_test = self._loss(X_val, y_val)\n",
    "                self.list_test_loss.append(loss_test)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        for layer in self.layers.values():\n",
    "            X = layer.forward(X)\n",
    "            \n",
    "        pred = np.argmax(X, axis=1)\n",
    "        \n",
    "        return pred\n",
    "    \n",
    "    def _loss(self, X, t):\n",
    "        for layer in self.layers.values():\n",
    "            X = layer.forward(X)\n",
    "\n",
    "        return self.lastLayer.forward(X, t)\n",
    "\n",
    "    def _gradient(self, X, t):\n",
    "        self._loss(X, t)\n",
    "        \n",
    "        dout = 1\n",
    "        dout = self.lastLayer.backward(dout)\n",
    "        \n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "                    \n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題9】学習と推定\n",
    "層の数や活性化関数を変えたいくつかのネットワークを作成してください。そして、MNISTのデータを学習・推定し、Accuracyを計算してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# データの読み込み\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# ラベルをone-hot化\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "\n",
    "# 分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.2)\n",
    "y_train = y_train.astype(int)\n",
    "y_val = y_val.astype(int)\n",
    "\n",
    "# cupy用\n",
    "X_train = np.array(X_train)\n",
    "X_val = np.array(X_val)\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = ScratchDeepNeuralNetrowkClassifier(lr=0.1, verbose=False, batch_size=20, max_iter=5)\n",
    "nn.fit(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = np.argmax(y_val, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正答率:0.92275\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = nn.predict(X_val)\n",
    "# cupy用\n",
    "y_pred = chainer.cuda.to_cpu(y_pred)\n",
    "y_val = chainer.cuda.to_cpu(y_val)\n",
    "\n",
    "accuracy = accuracy_score(y_pred, y_val)\n",
    "print(\"正答率:{}\".format(accuracy))\n",
    "\n",
    "x = numpy.arange(1, len(nn.list_train_loss)+1)\n",
    "plt.plot(x, nn.list_train_loss, label=\"loss\")\n",
    "plt.plot(x, nn.list_test_loss, label=\"val_loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "層の数、大きさを変えて実施してみる。\n",
    "- 7層\n",
    "- 活性化関数：1~3層目；ReLU、4層目；tanh、5,6層目；sigmoid\n",
    "- 最適化関数：AdaGrad\n",
    "- 重みの初期化：He"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "class ScratchDeepNeuralNetrowkClassifier():\n",
    "    def __init__(self, lr, verbose=True, batch_size=20, max_iter=3):\n",
    "        self.verbose = verbose\n",
    "        self.batch_size = batch_size\n",
    "        self.max_iter = max_iter\n",
    "        self.list_train_loss = []\n",
    "        self.list_test_loss = []\n",
    "        # レイヤの生成\n",
    "        initializer = HeInitializer()\n",
    "        optimizer = AdaGrad(lr=lr)\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers[\"FC1\"] = FC(784, 500, initializer, optimizer)\n",
    "        self.layers[\"ReLU1\"] = Relu()\n",
    "        self.layers[\"FC2\"] = FC(500, 400, initializer, optimizer)\n",
    "        self.layers[\"ReLU2\"] = Relu()\n",
    "        self.layers[\"FC3\"] = FC(400, 300, initializer, optimizer)\n",
    "        self.layers[\"ReLU3\"] = Relu()\n",
    "        self.layers[\"FC4\"] = FC(300, 200, initializer, optimizer)\n",
    "        self.layers[\"tanh1\"] = Tanh()\n",
    "        self.layers[\"FC5\"] = FC(200, 100, initializer, optimizer)\n",
    "        self.layers[\"sigmoid1\"] = Sigmoid()\n",
    "        self.layers[\"FC6\"] = FC(100, 50, initializer, optimizer)\n",
    "        self.layers[\"sigmoid2\"] = Sigmoid()\n",
    "        self.layers[\"FC7\"] = FC(50, 10, initializer, optimizer)\n",
    "        self.lastLayer = Softmax()\n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        flg_test = 0\n",
    "        if (X_val is not None) and (y_val is not None):\n",
    "            flg_test = 1\n",
    "\n",
    "        # 1エポックの繰り返し数\n",
    "        iter_num = int(len(X) / self.batch_size)\n",
    "                        \n",
    "        # エポックを複数回繰り返す\n",
    "        for i_ in range(self.max_iter):\n",
    "            # 損失計算用\n",
    "            tmp_list_loss_train = []\n",
    "\n",
    "            # 1エポック\n",
    "            for j_ in range(iter_num):\n",
    "                batch_mask = np.random.choice(X.shape[0], self.batch_size)\n",
    "                X_batch = X[batch_mask]\n",
    "                y_batch = y[batch_mask]\n",
    "                \n",
    "                self._gradient(X_batch, y_batch)\n",
    "                            \n",
    "                tmp_list_loss_train.append(self._loss(X_batch, y_batch))\n",
    "                if self.verbose:\n",
    "                    #verboseをTrueにした際は学習過程などを出力する\n",
    "                    print(loss_train)\n",
    "        \n",
    "            # 損失をインスタンス領域に設定\n",
    "            self.list_train_loss.append(sum(tmp_list_loss_train)/len(tmp_list_loss_train))\n",
    "            if flg_test == 1:\n",
    "                loss_test = self._loss(X_val, y_val)\n",
    "                self.list_test_loss.append(loss_test)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        for layer in self.layers.values():\n",
    "            X = layer.forward(X)\n",
    "            \n",
    "        pred = np.argmax(X, axis=1)\n",
    "        \n",
    "        return pred\n",
    "    \n",
    "    def _loss(self, X, t):\n",
    "        for layer in self.layers.values():\n",
    "            X = layer.forward(X)\n",
    "\n",
    "        return self.lastLayer.forward(X, t)\n",
    "\n",
    "    def _gradient(self, X, t):\n",
    "        self._loss(X, t)\n",
    "        \n",
    "        dout = 1\n",
    "        dout = self.lastLayer.backward(dout)\n",
    "        \n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "                    \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正答率:0.8126666666666666\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD5CAYAAAA3Os7hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3RVVd7G8e9OD6QBKYRUeiAJNYTeRGkiiIAIUsU+g3UcdUbHMo5tfK1jGVQ6UgR0EAUE6UpLaKEGBAKBQEKABALp+/3jBEEMJCH33nNz8/uslTVJ7iH34Yw8HPbZZ2+ltUYIIUTV52R2ACGEEJYhhS6EEA5CCl0IIRyEFLoQQjgIKXQhhHAQUuhCCOEgXMo6QCkVBkwHggANTNJaf3DNMQr4AOgPXATGaa233ujn+vv768jIyJuMLYQQ1VNiYuJprXVAaa+VWehAIfC01nqrUsobSFRKLdda77nqmH5A45KP9sCnJf97XZGRkSQkJJTrNyCEEMKglEq53mtlDrlordMuX21rrc8De4GQaw4bBEzXho2An1IquBKZhRBCVFCFxtCVUpFAa2DTNS+FAMeu+jqVP5Y+SqkHlVIJSqmEjIyMiiUVQghxQ+UudKWUF7AAeEJrnX0zb6a1nqS1jtNaxwUElDoEJIQQ4iaVZwwdpZQrRpnP0lovLOWQ40DYVV+HlnxPCCF+p6CggNTUVHJzc82OYtc8PDwIDQ3F1dW13L+mPLNcFPAlsFdr/e51DlsE/FkpNQfjZmiW1jqt3CmEENVGamoq3t7eREZGYtSLuJbWmszMTFJTU6lfv365f115rtA7A6OBJKXU9pLv/Q0IL3njz4AfMKYsHsSYtji+AtmFENVIbm6ulHkZlFLUqVOHit5rLLPQtdbrgRueeW2swfunCr2zEKLakjIv282coyr3pGjG+TxeXrSb/MJis6MIIYRdqXKFvvnwGab+coRn5u+guFg25xBCVJyXl5fZEayiXLNc7MntLYI5ktmUfy/bT7CvJ8/1izI7khBC2IUqd4UO8GiPhozqEM5na35l+oYjZscRQlRRWmueeeYZYmJiiI2NZe7cuQCkpaXRrVs3WrVqRUxMDOvWraOoqIhx48b9dux7771ncvo/qnJX6GDcLHhlYAwns/J4adFuAr096BtT1+xYQogKeuW73ew5cVPPKV5X83o+vHRHdLmOXbhwIdu3b2fHjh2cPn2adu3a0a1bN7766iv69OnD3//+d4qKirh48SLbt2/n+PHj7Nq1C4Bz585ZNLclVMkrdABnJ8VHI1rTKsyPx+dsIzHljNmRhBBVzPr16xkxYgTOzs4EBQXRvXt3tmzZQrt27ZgyZQovv/wySUlJeHt706BBAw4dOsTEiRNZunQpPj4+Zsf/gyp5hX6Zp5szX45tx5BPf2HCtAQWPNKJhgGOebNDCEdU3itpW+vWrRtr167l+++/Z9y4cTz11FOMGTOGHTt2sGzZMj777DPmzZvH5MmTzY76O1X2Cv2y2jXdmDY+HhcnxdjJm0k/L48TCyHKp2vXrsydO5eioiIyMjJYu3Yt8fHxpKSkEBQUxAMPPMD999/P1q1bOX36NMXFxQwZMoTXXnuNrVtvuOWDKar0Ffpl4XVqMHlcO+6ZtJHxU7Yw96GOeLk7xG9NCGFFgwcPZsOGDbRs2RKlFG+//TZ169Zl2rRp/Pvf/8bV1RUvLy+mT5/O8ePHGT9+PMXFxjMwb7zxhsnp/0gZD3naXlxcnLb0Bher9qdz/7QEOjfy58uxcbg6V/l/gAjhcPbu3UuzZs3MjlEllHaulFKJWuu40o53qMbr2TSQNwbHsjY5g+cWJGHWX1ZCCGEGhxuXuLtdGCeyLvH+igOE+HnwVO+mZkcSQgibcLhCB3i8V2PSzuXy4cqD1PX1ZGT7cLMjCSGE1TlkoSuleG1wDKfO5/LCt0kE+bjTq1mQ2bGEEMKqHGoM/Wquzk58PLIN0fV8+fNX29h+zP6e6hJCCEty2EIHqOnuwuRx7Qjwdue+qVs4cjrH7EhCCGE1Dl3oAAHe7kwd3w6tNWOnbOb0hTyzIwkhhFU4fKEDNAjw4stx7TiVncuEqVu4mF9odiQhRBVxo7XTjxw5QkxMjA3T3Fi1KHSANuG1+GhEG5KOZ/Hnr7ZRWCQ7HgkhHItDznK5ntuaB/HqoBhe+HYXL/5vF68PjpW9DYUw05Ln4GSSZX9m3Vjo9+Z1X37uuecICwvjT38ytkF++eWXcXFxYdWqVZw9e5aCggJee+01Bg0aVKG3zc3N5ZFHHiEhIQEXFxfeffddevbsye7duxk/fjz5+fkUFxezYMEC6tWrx913301qaipFRUW8+OKLDB8+vFK/bahmhQ4wqkMEaVmX+HjVr9Tz9WRir8ZmRxJC2NDw4cN54oknfiv0efPmsWzZMh577DF8fHw4ffo0HTp0YODAgRW64Pv4449RSpGUlMS+ffvo3bs3ycnJfPbZZzz++OPce++95OfnU1RUxA8//EC9evX4/vvvAcjKyrLI763aFTrAX3o3Je1cLv+3PJm6vh4MiwszO5IQ1dMNrqStpXXr1qSnp3PixAkyMjKoVasWdevW5cknn2Tt2rU4OTlx/PhxTp06Rd265d84Z/369UycOBGAqKgoIiIiSE5OpmPHjvzrX/8iNTWVu+66i8aNGxMbG8vTTz/Ns88+y4ABA+jatatFfm/VZgz9akop3hzSgi6N/Hl+YRJrkjPMjiSEsKFhw4Yxf/585s6dy/Dhw5k1axYZGRkkJiayfft2goKCyM21zFLcI0eOZNGiRXh6etK/f39WrlxJkyZN2Lp1K7Gxsbzwwgu8+uqrFnmvalnoAG4uTnw6qg1Ngrx5ZGYiu45b5p88Qgj7N3z4cObMmcP8+fMZNmwYWVlZBAYG4urqyqpVq0hJSanwz+zatSuzZs0CIDk5maNHj9K0aVMOHTpEgwYNeOyxxxg0aBA7d+7kxIkT1KhRg1GjRvHMM89YbG31alvoAN4erkwZ345aNdwYN2ULx85cNDuSEMIGoqOjOX/+PCEhIQQHB3PvvfeSkJBAbGws06dPJyoqqsI/89FHH6W4uJjY2FiGDx/O1KlTcXd3Z968ecTExNCqVSt27drFmDFjSEpKIj4+nlatWvHKK6/wwgsvWOT35VDrod+sg+nnGfLpBup4ubHg4U7UqulmdiQhHJash15+1Xo99JvVKNCbL8bGkXr2EhOmbSG3oMjsSEIIUWFS6CXaRdbmg+Gt2HbsHI/N3kZRsWyOIYQwJCUl0apVq999tG/f3uxYf1Atpy1eT7/YYP4xoDmvfLeHV77bzSsDo+XBIyGsQGtdpf5sxcbGsn37dpu+580Mh0uhX2N85/qkZeUyae0h6vl58nD3hmZHEsKheHh4kJmZSZ06dapUqduS1prMzEw8PDwq9Ouk0EvxXN8o0rJyeXPJPoJ9PRjUKsTsSEI4jNDQUFJTU8nIkOc/bsTDw4PQ0NAK/ZoyC10pNRkYAKRrrf+wrJhSyheYCYSX/Lx3tNZTKpTCzjg5Kd4Z1oKM87n85esd+Hu507mRv9mxhHAIrq6u1K9f3+wYDqk8N0WnAn1v8PqfgD1a65ZAD+D/lFJVft6fu4sz/x0dRwN/Lx6ekcjetGyzIwkhxA2VWeha67XAmRsdAngrYzDMq+RYh1hw3NfTePCoprsL46Zs5vi5S2ZHEkKI67LEtMX/AM2AE0AS8LjWutTFxpVSDyqlEpRSCVVl/KyenydT72vHxbwixk3eTNbFArMjCSFEqSxR6H2A7UA9oBXwH6WUT2kHaq0naa3jtNZxAQEBFnhr24iq68N/x7QlJfMiD8xIkAePhBB2yRKFPh5YqA0HgcNAxRdCsHOdGvrzzt0t2Xz4DE9/vYNiefBICGFnLFHoR4FeAEqpIKApcMgCP9fuDGxZj7/1j+L7nWm8/sNes+MIIcTvlGfa4myM2Sv+SqlU4CXAFUBr/RnwT2CqUioJUMCzWuvTVktssge6NuDEuVy+WH+YYD9PJnSR6VdCCPtQZqFrrUeU8foJoLfFEtk5pRQvDmjOyaxcXvt+D3V9PLi9RbDZsYQQQhbnuhnOTor372lF2/BaPDl3O5sOZZodSQghpNBvloerM1+MjSOsticPTE8g+dR5syMJIao5KfRK8KvhxtTx8bi7OjNu8mZOZllmD0IhhLgZUuiVFFa7BlPHtyPrUgHjpmwmO1cePBJCmEMK3QKi6/ny2ei2HEy/wCMzE8kvLPVBWSGEsCopdAvp2jiAt4a04OeDmfx1vjx4JISwPVkP3YKGtA3lZHYu/162n2A/T57t63APzAoh7JgUuoU92qMhx89d4tPVv1LP14PRHSPNjiSEqCak0C1MKcWrA6NJz87lH4t2E+jjQZ/oumbHEkJUAzKGbgUuzk58NKINLUP9eGz2NhJTbrScvBBCWEbVK3St4fhWs1OUydPNmS/HxhHs68GEaQn8mnHB7EhCCAdX9Qp9+yz4/BZY965R7nasjpc70+6Lx8VJMXbyZtLPy4NHQgjrqXqFHjMEYu6Cn16BhQ9CgX2XZESdmnw5th2ZF/K5b+oWLuQ5xO58Qgg7VPUK3dUThnwJt7wASfNgan84f9LsVDfUMsyPT+5tw9608zw6aysFRfLgkRDC8qpeoQMoBd2egeEzIX0fTOoJJ7aZneqGekYF8vrgGNYmZ/C3hUloOx8uEkJUPVWz0C9rdgdMWAZOzjC5H+z+xuxENzS8XTiP92rM14mpvLfigNlxhBAOpmoXOkDdWHhgFQS3hK/HwarXodh+hzSeuLUxd8eF8uFPB5i9+ajZcYQQDqTqFzqAVwCMXQSt7oU1b8HXYyE/x+xUpVJK8a/BsXRvEsAL3+5i5b5TZkcSQjgIxyh0ABd3GPQx9H4N9i2GyX0gK9XsVKVydXbik3vb0DzYhz/N2saOY+fMjiSEcACOU+hg3CztNBFGzIWzKcbN0mObzU5VqpruLkwe1w5/bzfum7qFI6ft818UQoiqw7EK/bImvWHCcnCrCVNvh+2zzU5UqgBvd6aNj6dYa8ZN2UzmhTyzIwkhqjDHLHSAwCh4YCWEtYdvH4bl/4DiIrNT/UGDAC++GNuOtKxc7puWwMV8efBICHFzHLfQAWrUhtHfQNwE+PkDmDMScrPNTvUHbSNq8dGI1iSlnmPiV9solAePhBA3wbELHcDZFQa8C/3fgQPL4cvecOaw2an+oHd0XV4ZFMNP+9J58X+75cEjIUSFOX6hXxb/AIxeCOfTjMW9Dq8zO9EfjO4QwaM9GjJ781E+XnXQ7DhCiCqm+hQ6QIMexrh6TX+YcSckTDE70R8806cpg1uH8M6PycxPtM9pl0II+1S9Ch2gTkO4f4VR7oufgB/+CkX2cyNSKcVbQ1rQpZE/zy3YydrkDLMjCSGqiOpX6AAevjByHnT8M2z+L8waCpfOmp3qN24uTnw6qg2Ng7x5ZGYiu45nmR1JCFEFVM9CB2NBrz7/goH/gSPr4fNecNp+Fszy9nBl6vh2+NVwY/zULRw7c9HsSEIIO1d9C/2yNqNh7HeQm2WU+sGfzE70myAfD6aOb0deQRFjp2zmbE6+2ZGEEHaszEJXSk1WSqUrpXbd4JgeSqntSqndSqk1lo1oAxEdjZulvqHG8MvGz+xme7vGQd58MbYdqWcvcf/0BHIL7O/hKCGEfSjPFfpUoO/1XlRK+QGfAAO11tHAMMtEs7FaETDhR2jSD5Y+C989DoX2cUUcX7827w9vxdajZ3l8zjaKiu3jLxshhH0ps9C11muBMzc4ZCSwUGt9tOT4dAtlsz13L2MXpK5Pw9ZpxtTGnEyzUwHQPzaYF29vzrLdp/jn4j3y4JEQ4g8sMYbeBKillFqtlEpUSo253oFKqQeVUglKqYSMDDudjufkBL3+AXd9AakJ8HkPOLXH7FQA3NelPg90rc/UX44wae0hs+MIIeyMJQrdBWgL3A70AV5USjUp7UCt9SStdZzWOi4gIMACb21FLYbB+CXGsMuXt8H+JWYnAuD5fs0Y0CKYN5bs43/bj5sdRwhhRyxR6KnAMq11jtb6NLAWaGmBn2u+0Lbw4Cqo0whmj4D175l+s9TJSfF/d7ekff3a/OXrHfxy8LSpeYQQ9sMShf4/oItSykUpVQNoD+y1wM+1Dz71jCv16MGw4mX45iEoyDU1kruLM5PGxFHfvyYPzUhkb5r9rSAphLC98kxbnA1sAJoqpVKVUhOUUg8rpR4G0FrvBZYCO4HNwBda6+tOcayS3GrA0MnQ8wXYOdfYNOO8uXuB+nq6MnV8PDXdXRg/ZQsnzl0yNY8QwnzKrNkScXFxOiEhwZT3rpQ9i4yrdM9acM9XUK+VqXH2ncxm2KcbCPbz4OuHO+Hr6WpqHiGEdSmlErXWcaW9Jk+KVlTzgXDfMkDB5L6w+xtT40TV9eG/Y9py+HQOD05PIK9QHjwSorqSQr8ZwS2Mm6V1Y+HrcbD6TSg2b5ehTg39eWdYSzYdPsPT83ZQLA8eCVEtSaHfLK9AGLcYWo6E1W/A/PGQb94CWoNahfB8vygW70zjjSWOc09aCFF+LmYHqNJc3OHOTyCwmbEJ9dnDcM9s8A0xJc6D3Rpw4twlPl93mGBfT+7rUt+UHEIIc8gVemUpBZ0fg5FzIfMQfN4Tjm0xKYriH3dE0yc6iH9+v4cfktJMySGEMIcUuqU06QP3LwdXT2Na4445psRwdlJ8cE9r2obX4om529l8+EbL8AghHIkUuiUFNoP7V0JYvDG1cflLptws9XB15vMxcYTW8uT+aVs4cOq8zTMIIWxPCt3SataB0d9A2/Hw8/swZyTk2b5Qa9V0Y9r4eNxdnRk7eTP7T0qpC+HopNCtwdkVBrwH/d+BAz/Cl73h7BGbxwirXYMp49qRV1jMgI/W8f6KZPILzZteKYSwLil0a1EK4h+AUQsg+zhM6glHfrZ5jJgQX358shv9YoJ5f8UBBv5nPTtTz9k8hxDC+qTQra1hT2NcvUYdmD4QEqfZPEIdL3c+HNGaz8fEcSYnnzs//pk3luyV7eyEcDBS6Lbg3wjuXwH1u8N3j8GS56Co0OYxbmsexPKnujOsbRj/XXOI/h+sY8sRmQUjhKOQQrcVTz8YOQ86PAqbPoWvhsEl2w99+Hq68tbQFsyYEE9eYTF3/3cDLy/aTU6e7f+CEUJYlhS6LTm7QN834I4P4fA6+KIXnD5oSpSujQP48clujO0YydRfjtDn/bWsPyCbZQhRlUmhm6HtWBjzP7h0Fr64BX5daUqMmu4uvDwwmnkPdcTV2YlRX27i2fk7ybpUYEoeIUTlSKGbJbIzPLAKfEJg5lDYNMm07e3i69dmyeNdeah7A75OPEbv99awYo+5G3gIISpOCt1MtSJgwo/GsgFLnoHFTxibUpvAw9WZ5/s145tHO+Pn6cb90xN4bPY2zuSYk0cIUXFS6GZz94bhs6DLk5A4FWYMhpxM0+K0DPPju4ldeOLWxizZlcZt765h8c4TmLWzlRCi/KTQ7YGTE9z6MgyeBKlbjBUb081b09zNxYknbm3CdxO7EFLLkz9/tY2HZiSSnm3u5thCiBuTQrcnLYfD+B+gMBe+uA32LzU1TlRdHxY+0onn+kWxOjmDW99dw9cJx+RqXQg7JYVub0LjjJuldRrA7Hvg5w9Mu1kK4OLsxMPdG7L08a40revNM/N3MnbKFlLPmrc7kxCidFLo9sg3BMYvheg7jZ2Qvn0ECswd7mgQ4MXcBzvyysBoEo6coc97a5mx4YjsXyqEHZFCt1duNWDoFOj5d9gxG6bdAefNnUro5KQY2ymSZU90o3V4LV78327u+Xwjh0/nmJpLCGGQQrdnSkH3v8KwaXAyCT6/BdJ2mJ2KsNo1mDEhnreHtGBvWjZ931/LpLW/UiRX60KYSgq9Koi+EyYsAzRM7gt7/md2IpRS3N0ujBVPdadrY39e/2Efd336C8myO5IQppFCryqCWxo3S4OiYd4YWP2WqTdLLwvy8eDzMXF8cE8rjp25yO0fruODFQdkIw0hTCCFXpV4B8HYxdByBKx+HeaPh3zzZ5sopRjUKoTlT3ajb0ww761IZuB/1pOUmmV2NCGqFSn0qsbVA+78FG57FXZ/C1P6QdZxs1MBxkYaH41ozaTRbY2NND75mbeW7pONNISwESn0qkgp6Pw4jJgDmQeNJ0tTE8xO9Zve0XVZ/mR3hrQJ4dPVv9L/w3UkyEYaQlidFHpV1rQvTFgOLh4wpT/snGd2ot/41nDl7aEtmX5fPHkFxQwr2UjjYr5spCGEtZRZ6EqpyUqpdKXUrjKOa6eUKlRKDbVcPFGmoObGzdLQdrDwAVjxChTbzw3Jbk0CWPZkN0Z3iPhtI42fD8pGGkJYQ3mu0KcCfW90gFLKGXgL+NECmURF1awDo7+BNmNh/bswdxTk2c/0QS93F14dFMPcBzvgrBT3frGJ5xbsJDtXNtIQwpLKLHSt9VqgrAHQicACIN0SocRNcHGDOz6Afm9D8hL4sg+cTTE71e+0b1CHpU9046FuDZiXcIze767lp72ykYYQllLpMXSlVAgwGPi0HMc+qJRKUEolZGRkVPatxbWUgvYPwagFkJ1q3CxN+cXsVL/j4erM8/2NjTR8PF2YMC2BJ+bIRhpCWIIlboq+DzyrtS5z4FZrPUlrHae1jgsICLDAW4tSNbwF7l8JnrVg2kDYOt3sRH9weSONx3o1ZvFOYyON73emydK8QlSCJQo9DpijlDoCDAU+UUrdaYGfKyrDvxHcvwLqd4VFE2HqADi60exUv+Pu4sxTtxkbadTz8+RPX23l4ZmykYYQN6vSha61rq+1jtRaRwLzgUe11t9WOpmoPM9aMPJr6PsmZOyHyX2MLe7saM46QLNgH755tBPP9o1i1X5jI435ialytS5EBZVn2uJsYAPQVCmVqpSaoJR6WCn1sPXjiUpzdoEOj8Dj242nS09shy96way7jc/thIuzE4/0aMiSx7vSJMibv3y9g3FTtnD83CWzowlRZSizroLi4uJ0QoJ9XSlWC3nnYdN/4ZePIPccRA2AHs9D3Rizk/2muFgzfcMR3lq6HycFz/Vvxr3x4Tg5KbOjCWE6pVSi1jqu1Nek0Kup3CzY+Cls+BjysqH5nUaxB0aZnew3x85c5LmFO/n5YCbt69fmrSEtiPSvaXYsIUwlhS6u79JZo9Q3fgr5ORA7FLo/Z9xUtQNaa+YlHOO1xXspKC7m6duacl+X+jjL1bqopqTQRdlyMuGXD2HzJCjMhRb3GLsl1a5vdjIATmbl8vdvkvhpXzqtwvx4e2gLmgR5mx1LCJuTQhfldyEd1r8PCV9CcSG0GgndngG/cLOTobVm0Y4TvLxoNzl5RUy8pREP92iIq7OsMSeqDyl0UXHZaca6MIlTjZ2R2oyBbn8Bn3pmJ+P0hTxeWrSb73em0TzYh7eHtiAmxNfsWELYhBS6uHlZqbD2Hdg2A5QzxI2HLk8ZuyeZbNnuk7zw7S7O5OTzULcGPNarMR6uzmbHEsKqpNBF5Z1NgbVvw/bZ4OwG8fdD5yegpr+psbIuFvDP7/cwPzGVhgE1eXtoS9pG1DI1kxDWJIUuLCfzV1jzNiTNAxdPYzGwThOhRm1TY61JzuD5BTtJy85lfKf6/KVPE2q4uZiaSQhrkEIXlpeRDGvehF0Lwc0LOj4KHR4FTz/TIl3IK+StJfuYsTGF8No1ePOuWDo1MvdfEEJYmhS6sJ5Te2D1G7B3EXj4QseJxlW7h49pkTYeyuS5BTs5knmREfHhPN8/Ch8PV9PyCGFJUujC+tJ2wOo3Yf8PxqJgnR+H+AfBzZwnOy/lF/Hu8v18uf4wgd4evH5XDLdEmX8jV4jKkkIXtnM8EVa9AQeXQw1/6PIktJsArp6mxNl+7Bx/nb+D5FMXGNw6hH8MaE6tmm6mZBHCEqTQhe0d3QSrX4dDq8ErCLo+bex56uph8yh5hUV8vPIgn6z+Fb8arrw6KIb+scE2zyGEJUihC/McWQ+rXoeUn8EnxCj21qONPVBtbM+JbP66YAe7jmfTL6YurwyKJtDb9n/BCFEZUujCXFrD4TWw8l+Quhl8w6H7M9ByBDjb9mZlYVExk9Yd4v0VB/B0deYfA5pzV5sQlJLFvkTVIIUu7IPWcPAnWPUvOLEVatWH7s9Ci7vBybZPeB5Mv8CzC3aSmHKWHk0DeH1wLPX8zBnnF6IipNCFfdEakpcaxX4yCeo0hh7PQfRd4GS7hbaKSjbSeHvpfpydFM/3j2JEO9lIQ9g3KXRhn4qLYd9iYx57+h4IaGYUe7OBNi32o5nGRhq//JpJhwbGRhoRdWQjDWGfpNCFfSsuhj3fGPPYTydDUCz0fB6a9gcbjW1rrZmz5Rivf29spDE8LoxRHSJoLGuuCzsjhS6qhuIiSJpvLClw5hAEt4Kef4fGt9ms2NOyLvHvpftZvDON/KJi2tevzeiOEfRuXhc3F1l3XZhPCl1ULUWFsHMOrHkLzh2F0HbQ82/QoKfNij3zQh7zElKZtSmF1LOX8PdyZ0R8GCPiw+XmqTCVFLqomgrzYfssYz327FQI7wS3/B0iu9gsQlGxZm1yBjM3prByfzoK6NUsiNEdIujSyF9uoAqbk0IXVVthHmydbhT7hZNQvxv0fAHC29s0xrEzF/lq81HmbTlGZk4+EXVqMKp9BEPbhspyAsJmpNCFYyi4BAlTjK3xcjKgYS9jjD20rU1j5BUWsXTXSWZuTGHLkbO4uThxR4t6jOoQTqswP3lISViVFLpwLPk5sPlz+PkDuHQGmvQ1xtiDW9o8yr6T2czcmMI3W4+Tk19ETIgPo9pHMLBVPdlgQ1iFFLpwTHnnYdNn8MtHkJsFUQOMYg+KtnmUC3mFfLPtODM3pLD/1Hm8PVwY0iaUUR0iaBToZfM8wnFJoQvHlpsFGz6BjZ9AXjZED4Yez0NAU5tH0VqTkHKWGRtSWLIrjYIiTccGdRjdMYLbmgfh6ixTH0XlSKGL6uHiGdjwsXHVXnARYocZa8XUaWhKnIzzecxLOMZXm45y/NwlAr3duSc+nBHxYQT7ytRHcXOk0EX1kjcWys0AABBjSURBVJMJv3wAmyZBUb6xqmP3Z6BWpClxioo1q/enM2NjCmuSM3BSilubBTK6QySdGtaRqY+iQqTQRfV0IR3WvwdbvgRdBK1HQde/gF+YaZGOZl5k1uYUvk5I5UxOPvX9a3Jv+3CGtQ3Dt4bseyrKJoUuqrfsNFj3f7B1mvF1m7HQ9SnwqWdapNyCIpbsSmPmxqMkppzF3cWJgS3rMapDBC3D/EzLJexfpQpdKTUZGACka61jSnn9XuBZQAHngUe01jvKCiWFLmzu3DFY9w5smwnK2djrtPMT4G3u5tF7TmQzc1MK3247zsX8IlqE+jKqfQR3tKyHp5tt14kX9q+yhd4NuABMv06hdwL2aq3PKqX6AS9rrct8hE8KXZjm7BFY82/YMRuc3SD+AaPYa9YxNVZ2bgHfbjvOjA0pHEi/gI+HC0PbhjGqQzgNAmTqozBUeshFKRUJLC6t0K85rhawS2sdUtbPlEIXpsv81VgAbOc8cKsJ7R+Cjn+GGrVNjaW1ZvPhM8zYmMLSXScpLNZ0aeTPqA7h3NosCBeZ+lit2bLQ/wJEaa3vv87rDwIPAoSHh7dNSUkp872FsLqM/cZa7LsXgrsPdHgU2o4Dn2Czk5F+Ppd5W4ypjyeycqnr48GI+HDuiQ8jyEc2uK6ObFLoSqmewCdAF611Zlk/U67Qhd05tdvYPWnvd4AyVnWMGQLNB5l+1V5YVMyq/RnM2JjC2uQMnJ0UfaKDGNU+go4N68j6MdWI1QtdKdUC+Abop7VOLk8oKXRht04fgF0LjM02Mg+Akws0vMUo96b9wcPH1HhHTucYqz4mHOPcxQIaBtTk3vYRDGkbiq+nTH10dFYtdKVUOLASGKO1/qW8oaTQhd3T2tjEetd82LUQso6Biwc07m2Ue5M+4GreE5+5BUV8vzONGRtT2H7sHB6uTgxqGcLojhHEhPialktYV2VnucwGegD+wCngJcAVQGv9mVLqC2AIcHlAvPB6b3Y1KXRRpWgNqVuMq/bd30BOOrh5QdTtEDMUGvYEZ/Oujncdz2LmxhT+t/0ElwqKaBnmx+gOEQxoEYyHq0x9dCTyYJEQllRcBEfWGcMyexZB7jnwrGWMtccMgYjO4GROiWZdKmDh1lRmbkzh14wc/Gq4MqxtKPe2jyDSv6YpmYRlSaELYS2F+fDrSmNYZt8PUJADXnWNFR9jhkBonM32Qb2a1poNhzKZtfEoy3YbUx+7NvZndIcIbokKlKmPVZgUuhC2kH8RDiwzhmUOLIeiPPALN4o9ZqixTrsJ5Z6encuckqmPJ7NzCfb1YGR8OMPjwwj0lqmPVY0UuhC2lpsF+743hmV+XWUsDubfFGKHGgVvwpK+hUXFrNibzqxNKaw7cBoXJ0WfmLqMah9Bhwa1ZepjFSGFLoSZcjJhz7fGTJmUnwFtbJcXMxRi7gLfUJtHOnw6h1kbU/g6MZWsSwU0CvRiVPtw7mobio+HTH20Z1LoQtiL7BPGLJldC+B4ovG98I4lDzDdCV4BNo2TW1DEdztOMHNjCjtSs/B0debO1saqj9H1ZOqjPZJCF8IenTlkXLXvWgDpe0A5Qf3uxrBM1ADwtO0yujtTzzFzYwqLdpwgt6CY1uHG1Mf+sTL10Z5IoQth707tMYp91wI4e9hYBbLRrSVPp/YzFg+zkayLBczfmsqsjSkcOp1DrRqu3B0Xxsj24UTUkamPZpNCF6Kq0BpObC25cl8I50+Aaw2j1GOGGCXv4m6jKJpffs1k5sYUftxzimKt6dY4gNEdIugZFYizbJ1nCil0Iaqi4mI4uqHkAaZv4WImuPtCszuMm6n1u4Ozi02inMzKZfbmo8zZcpRT2XmE+Hkysn04d8eFEeBtm79ghEEKXYiqrqgADq+BpAWwbzHkZUMNf4i+05gtE9YenKz/sFBBUTEr9pxi5qYUfj6Yiauzom9MMANb1qNLI3/ZYckGpNCFcCQFuXBwuXHlvn8pFF4CnxDj6dTYoRDcyiYPMP2acYFZG48yP/EY2bmFuLs40bmRP72aBdIrKoi6vvLQkjVIoQvhqPIuwP4lRrkfXAHFBVC7YcnTqUMgMMrqEfILi9l8+Awr9p7ip32nOHbmEgDR9Xzo1SyIW5sFElPPFycZc7cIKXQhqoOLZ4zhmKT5xuJhuhiCYozx9ui7oHZ9q0fQWnMw/QIr9qbz095TbD16lmINgd7u3BIVSK9mQTI0U0lS6EJUN+dPlTydugCObTK+FxJnXLVHD7bZ9npncvJZvT+dn/amsyY5gwt5MjRTWVLoQlRn545eeYDp5E7M2l5PhmYsQwpdCGHISDY2wzZ5e70bDc1cvnLvLEMzpZJCF0L8np1tr3cmJ59V+9JZuU+GZsoihS6EuD47217vekMzMSE+9IoKolc1H5qRQhdClI+dba8nQzN/JIUuhKg4O9xe73pDM10a+XNLNRmakUIXQlTODbfXG2LMd7dxuZc1NHNrsyCi6/k43NCMFLoQwnJK217Pu54xFbJ+V4jsCrUibVrwWmsOpF/gp2uGZoJ8Sh5ocqChGSl0IYR15Jw2nk49tMYYe8/JML7vG2YUfGRXo+T9wm0a6/LQzE/7TrE2+fTvhmZ6NQvilqjAKjs0I4UuhLA+rSFjv1HsR9bBkfXGkr8AfhFXyj2yK/iG2CxWeYZmYkJ8qswm2VLoQgjbKy6GjL1GsR9ea2yQfems8Vqt+iXl3s24krfRUgQ3HpoJoldUoN0PzUihCyHMV1wM6bvh8OUr+J8hL8t4rU6j31/BewXaJFJpQzMerk50bmgMzfRqFkiQj30NzUihCyHsT3GR8bTqkXVGyaf8Avnnjdf8m14p98guUNPf6nGqytCMFLoQwv4VFcLJHVeu4FM2GHPfAQKbX7mCj+hs9QXFLg/NrNh7ipV70+1qaEYKXQhR9RQVwIntcGStUfLHNkHBRUAZ897rl1y9R3Qynma1InsampFCF0JUfYX5cGJryRX8Wji2GQpzAQXBLUqGZ7pCREfw8LVajPzCYjYdzjRurF41NBMb4sstUYFWH5qpVKErpSYDA4B0rXVMKa8r4AOgP3ARGKe13lpWKCl0IUSlFOZBasKVKZLHNhtPsConY1/Vy2Pw4R3A3dsqEa4emvmpZGhGXzU0c2szY2jGw9VyQzOVLfRuwAVg+nUKvT8wEaPQ2wMfaK3blxVKCl0IYVEFl4xVIw+XFHzqFmOPVeUMIW2uPOgU3gHcalolgi2GZio95KKUigQWX6fQ/wus1lrPLvl6P9BDa512o58phS6EsKr8i8a4++Ur+OOJUFwITq4Q0vbKUgVh7a2y9vuNhmbu6xLJ4NahN/Vzb1ToLjcf9zchwLGrvk4t+d4fCl0p9SDwIEB4uG0fBRZCVDNuNYy13Bv2NL7OuwDHNpY86LQO1r8H694BZzcIbXflCj60HbhW/ganm4sTXRsH0LVxAC/d0fx3QzNZFwsq/fNLY4kr9MXAm1rr9SVf/wQ8q7W+4eW3XKELIUyVmw1HN15ZqiBtB+hicHaHsPgr0yRD2oKLu0XfWmt90zdNrX2FfhwIu+rr0JLvCSGE/fLwgSa9jQ+AS+fg6IYrSxWsfgNWvw4unkbBX16qoF5rcHGr1FtbawaMJQp9EfBnpdQcjJuiWWWNnwshhN3x9IOm/YwPgItnjIK//KDTyteM77vWMG6sRnaF+t2MGTXOlqjSyiszhVJqNtAD8FdKpQIvAa4AWuvPgB8wZrgcxJi2ON5aYYUQwmZq1Db2VY263fg6J9NYYOzyUgU/vWJ8380LwjtemSYZ3NKm2/RdTR4sEkKIm3EhA1LWX7mCP51sfN/dx3h69fIYfFCMRQve2mPoQghR/XgFGPurRg82vj5/6soN1sPrIHmp8X0PP2P9mctLFQRGg5OTVSJJoQshhCV4B0HsUOMDIPvElRusR9bD/u+N73vWhq5PQ6c/WzyCFLoQQliDTz1ocbfxAXDumFHsR9aBd12rvKUUuhBC2IJfGLQaYXxYiXUGcoQQQticFLoQQjgIKXQhhHAQUuhCCOEgpNCFEMJBSKELIYSDkEIXQggHIYUuhBAOwrTFuZRSGUDKTf5yf+C0BeNYir3mAvvNJrkqRnJVjCPmitBaB5T2gmmFXhlKqYTrrTZmJnvNBfabTXJVjOSqmOqWS4ZchBDCQUihCyGEg6iqhT7J7ADXYa+5wH6zSa6KkVwVU61yVckxdCGEEH9UVa/QhRBCXEMKXQghHIRdF7pSarJSKl0ptes6ryul1IdKqYNKqZ1KqTZ2kquHUipLKbW95OMfNsgUppRapZTao5TarZR6vJRjbH6+ypnLjPPloZTarJTaUZLrlVKOcVdKzS05X5uUUpF2kmucUirjqvN1v7VzXfXezkqpbUqpxaW8ZvPzVc5cZp6vI0qppJL3TSjldcv+mdRa2+0H0A1oA+y6zuv9gSWAAjoAm+wkVw9gsY3PVTDQpuRzbyAZaG72+SpnLjPOlwK8Sj53BTYBHa455lHgs5LP7wHm2kmuccB/bHm+rnrvp4CvSvv/y4zzVc5cZp6vI4D/DV636J9Ju75C11qvBc7c4JBBwHRt2Aj4KaWC7SCXzWmt07TWW0s+Pw/sBUKuOczm56ucuWyu5BxcKPnSteTj2hkCg4BpJZ/PB3oppZQd5DKFUioUuB344jqH2Px8lTOXPbPon0m7LvRyCAGOXfV1KnZQFiU6lvyzeYlSKtqWb1zyT93WGFd3VzP1fN0gF5hwvkr+mb4dSAeWa62ve7601oVAFlDHDnIBDCn5J/p8pVSYtTOVeB/4K1B8nddNOV/lyAXmnC8w/jL+USmVqJR6sJTXLfpnsqoXur3airHeQkvgI+BbW72xUsoLWAA8obXOttX7lqWMXKacL611kda6FRAKxCulYmzxvmUpR67vgEitdQtgOVeuiq1GKTUASNdaJ1r7vSqinLlsfr6u0kVr3QboB/xJKdXNmm9W1Qv9OHD137ahJd8zldY6+/I/m7XWPwCuSil/a7+vUsoVozRnaa0XlnKIKeerrFxmna+r3v8csAroe81Lv50vpZQL4Atkmp1La52ptc4r+fILoK0N4nQGBiqljgBzgFuUUjOvOcaM81VmLpPO1+X3Pl7yv+nAN0D8NYdY9M9kVS/0RcCYkjvFHYAsrXWa2aGUUnUvjx0qpeIxzrNV/8Mueb8vgb1a63evc5jNz1d5cpl0vgKUUn4ln3sCtwH7rjlsETC25POhwEpdcifLzFzXjLEOxLgvYVVa6+e11qFa60iMG54rtdajrjnM5uerPLnMOF8l71tTKeV9+XOgN3DtzDiL/pl0uem0NqCUmo0xA8JfKZUKvIRxkwit9WfADxh3iQ8CF4HxdpJrKPCIUqoQuATcY+3/sDGuVEYDSSXjrwB/A8KvymXG+SpPLjPOVzAwTSnljPEXyDyt9WKl1KtAgtZ6EcZfRDOUUgcxboLfY+VM5c31mFJqIFBYkmucDXKVyg7OV3lymXW+goBvSq5VXICvtNZLlVIPg3X+TMqj/0II4SCq+pCLEEKIElLoQgjhIKTQhRDCQUihCyGEg5BCF0IIByGFLoQQDkIKXQghHMT/A9CxljerdUBoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# データの読み込み\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# ラベルをone-hot化\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "\n",
    "# 分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.2)\n",
    "y_train = y_train.astype(int)\n",
    "y_val = y_val.astype(int)\n",
    "\n",
    "# cupy用\n",
    "X_train = np.array(X_train)\n",
    "X_val = np.array(X_val)\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "nn = ScratchDeepNeuralNetrowkClassifier(lr=0.1, verbose=False, batch_size=20, max_iter=5)\n",
    "nn.fit(X_train, y_train, X_val, y_val)\n",
    "\n",
    "y_val = np.argmax(y_val, axis=1)\n",
    "\n",
    "y_pred = nn.predict(X_val)\n",
    "# cupy用\n",
    "y_pred = chainer.cuda.to_cpu(y_pred)\n",
    "y_val = chainer.cuda.to_cpu(y_val)\n",
    "\n",
    "accuracy = accuracy_score(y_pred, y_val)\n",
    "print(\"正答率:{}\".format(accuracy))\n",
    "\n",
    "x = numpy.arange(1, len(nn.list_train_loss)+1)\n",
    "plt.plot(x, nn.list_train_loss, label=\"loss\")\n",
    "plt.plot(x, nn.list_test_loss, label=\"val_loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "単純に層を増やせば性能のいいモデルが得られるというわけではなさそうだ。\n",
    "性能を上げるためにどのようにモデルを構築すればよいか、ネットで調査してみる。\n",
    "\n",
    "[参考]\n",
    "このノートブックを全実行したときの所要時間だが、CPU,GPUの動作を比較すると以下のとおりであった。\n",
    "- CPU : 6分02秒\n",
    "- GPU(GeForce GTX 1070(8GB)) : 2分38秒\n",
    "\n",
    "GPUの使用率は60%あたりを推移していたが、cupyで取得していた領域は500MBほど。ノートブックはカーネルを落とすか再起動しないとGPUメモリが開放されないので注意する。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
