{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2次元の畳み込みニューラルネットワークスクラッチ\n",
    "2次元に対応した畳み込みニューラルネットワーク（CNN）のクラスをスクラッチで作成していきます。NumPyなど最低限のライブラリのみを使いアルゴリズムを実装していきます。\n",
    "\n",
    "プーリング層なども作成することで、CNNの基本形を完成させます。クラスの名前はScratch2dCNNClassifierとしてください。\n",
    "\n",
    "#### データセットの用意\n",
    "引き続きMNISTデータセットを使用します。2次元畳み込み層へは、28×28の状態で入力します。\n",
    "\n",
    "今回は白黒画像ですからチャンネルは1つしかありませんが、チャンネル方向の軸は用意しておく必要があります。\n",
    "\n",
    "(n_samples, n_channels, height, width)のNCHWまたは(n_samples, height, width, n_channels)のNHWCどちらかの形にしてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前回、cupyが使えなかったので今回も諦める方向で進める。\n",
    "\n",
    "import numpy as np\n",
    "#import cupy as np\n",
    "#import chainer.cuda\n",
    "from keras.datasets import mnist\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "\n",
    "# データの読み込み\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# (n_samples, n_channels, height, width)\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1], X_train.shape[2])\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1], X_test.shape[2])\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# ラベルをone-hot化\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "\n",
    "# 分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.2)\n",
    "y_train = y_train.astype(int)\n",
    "y_val = y_val.astype(int)\n",
    "\n",
    "# cupy用\n",
    "# X_train = np.array(X_train)\n",
    "# X_val = np.array(X_val)\n",
    "# y_train = np.array(y_train)\n",
    "# y_val = np.array(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題1】2次元畳み込み層の作成\n",
    "1次元畳み込み層のクラスConv1dを発展させ、2次元畳み込み層のクラスConv2dを作成してください。\n",
    "\n",
    "フォワードプロパゲーションの数式は以下のようになります。\n",
    "$$\n",
    "a_{i,j,m}=\\sum_{k=0}^{K-1}\\sum_{s=0}^{F_b-1}\\sum_{t=0}^{F_w-1}x_{(i+s),(j+t),k}w_{s,t,k,m}+b_m\n",
    "$$\n",
    "\n",
    "$a_{i,j,m}$ : 出力される配列のi行j列、mチャンネルの値\n",
    "\n",
    "$i$ : 配列の行方向のインデックス\n",
    "\n",
    "$j$ : 配列の列方向のインデックス\n",
    "\n",
    "$m$ : 出力チャンネルのインデックス\n",
    "\n",
    "$K$ : 入力チャンネル数\n",
    "\n",
    "$F_{h}, F_{w}$ : 高さ方向（h）と幅方向（w）のフィルタのサイズ\n",
    "\n",
    "$x_{(i+s),(j+t),k}$ : 入力の配列の(i+s)行(j+t)列、kチャンネルの値\n",
    "\n",
    "$w_{s,t,k,m}$ : 重みの配列のs行t列目。kチャンネルの入力に対して、mチャンネルへ出力する重み\n",
    "\n",
    "$b_m$ : mチャンネルへの出力のバイアス項\n",
    "\n",
    "全てスカラーです。\n",
    "\n",
    "次に更新式です。1次元畳み込み層や全結合層と同じ形です。\n",
    "$$\n",
    "w'_{s,t,k,m}=w_{s,t,k,m}-\\alpha\\frac{\\partial L}{\\partial w_{s,t,k,m}} \\\\\n",
    "b'_m=b_m-\\alpha\\frac{\\partial L}{\\partial b_m}\n",
    "$$\n",
    "\n",
    "$\\alpha$ : 学習率\n",
    "\n",
    "$\\frac{\\partial L}{\\partial w_{s,t,k,m}}$ : $w_{s,t,k,m}$ に関する損失 $L$ の勾配\n",
    "\n",
    "$\\frac{\\partial L}{\\partial b_{m}}$ : $b_{m}$ に関する損失 $L$ の勾配\n",
    "\n",
    "勾配 $\\frac{\\partial L}{\\partial w_{s,t,k,m}}$ や $\\frac{\\partial L}{\\partial b_{m}}$ を求めるためのバックプロパゲーションの数式が以下である。\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w_{s,t,k,m}}=\\sum_{i=0}^{N_{out,h}-1}\\sum_{j=0}^{N_{out,w}-1}\\frac{\\partial L}{\\partial a_{i,j,m}}x_{(i+s),(j+t),k} \\\\\n",
    "\\frac{\\partial L}{\\partial b_{m}}=\\sum_{i=0}^{N_{out,h}-1}\\sum_{j=0}^{N_{out,w}-1}\\frac{\\partial L}{\\partial a_{i,j,m}}\n",
    "$$\n",
    "\n",
    "$\\frac{\\partial L}{\\partial a_i}$ : 勾配の配列のi行j列、mチャンネルの値\n",
    "\n",
    "$N_{out,h},N_{out,w}$ : 高さ方向（h）と幅方向（w）の出力のサイズ\n",
    "\n",
    "前の層に流す誤差の数式は以下です。\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial x_{i,j,k}}=\\sum_{m=0}^{M-1}\\sum_{s=0}^{F_h-1}\\sum_{t=0}^{F_w-1}\\frac{\\partial L}{\\partial a_{(i-s),(j-t),m)}}w_{s,t,k,m}\n",
    "$$\n",
    "\n",
    "$\\frac{\\partial L}{\\partial x_{i,j,k}}$ : 前の層に流す誤差の配列のi列j行、kチャンネルの値\n",
    "\n",
    "$M$ : 出力チャンネル数\n",
    "\n",
    "ただし、 $i-s<0$ または $i-s>N_{out,h}-1$ または $j-t<0$ または $j-t>N_{out,w}-1$ のとき $\\frac{\\partial L}{\\partial a_{(i-s),(j-t),m}} =0$ です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- filter_infoについて\n",
    "\n",
    "filter_info=(filter_num, channel_in, filter_height, filter_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "        layer.W -= self.lr * layer.dW\n",
    "        layer.b -= self.lr * layer.db\n",
    "        \n",
    "        \n",
    "class AdaGrad:\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        self.h_W = None\n",
    "        self.h_b = None\n",
    "    def update(self, layer):\n",
    "        if (self.h_W is None) and (self.h_b is None):\n",
    "            self.h_W = 0\n",
    "            self.h_b = 0\n",
    "        \n",
    "        self.h_W += (layer.dW ** 2).sum()\n",
    "        self.h_b += (layer.db ** 2).sum()\n",
    "        layer.W -= self.lr * layer.dW / (np.sqrt(self.h_W) + 1e-7)\n",
    "        layer.b -= self.lr * layer.db / (np.sqrt(self.h_b) + 1e-7)\n",
    "        \n",
    "        \n",
    "class XavierInitializer_conv:\n",
    "    def __init__(self):\n",
    "        self.sigma = None\n",
    "    def W(self, filter_info):\n",
    "        filter_num, channel_in, filter_height, filter_width = filter_info\n",
    "        self.sigma = 1 / np.sqrt(filter_num)\n",
    "        W = self.sigma * np.random.randn(filter_num, channel_in, filter_height, filter_width)\n",
    "        return W\n",
    "    def B(self, filter_info):\n",
    "        filter_num, channel_in, filter_height, filter_width = filter_info\n",
    "        B = np.zeros(filter_num)\n",
    "        return B\n",
    "\n",
    "\n",
    "class HeInitializer_conv:\n",
    "    def __init__(self):\n",
    "        self.sigma = None\n",
    "    def W(self, filter_info):\n",
    "        filter_num, channel_in, filter_height, filter_width = filter_info\n",
    "        self.sigma = np.sqrt(2 / filter_num)\n",
    "        W = self.sigma * np.random.randn(filter_num, channel_in, filter_height, filter_width)\n",
    "        return W\n",
    "    def B(self, filter_info):\n",
    "        filter_num, channel_in, filter_height, filter_width = filter_info\n",
    "        B = np.zeros(filter_num)\n",
    "        return B\n",
    "    \n",
    "    \n",
    "class XavierInitializer:\n",
    "    def __init__(self):\n",
    "        self.sigma = None\n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        self.sigma = 1 / np.sqrt(n_nodes1)\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "    def B(self, n_nodes2):\n",
    "        B = np.zeros(n_nodes2)\n",
    "        return B\n",
    "\n",
    "\n",
    "class HeInitializer:\n",
    "    def __init__(self):\n",
    "        self.sigma = None\n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        self.sigma = np.sqrt(2 / n_nodes1)\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "    def B(self, n_nodes2):\n",
    "        B = np.zeros(n_nodes2)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sprint11で作成したConv1dを流用してConv2dを作成する\n",
    "- 変更\n",
    "  - filtersizeをfilter_widthに変更\n",
    "  - filter_heightを追加し、処理も追加する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d:\n",
    "    def __init__(self, filter_info, initializer, optimizer, pad=0, stride=1):\n",
    "        self.optimizer = deepcopy(optimizer)\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.W = initializer.W(filter_info)\n",
    "        self.b = initializer.B(filter_info)\n",
    "        self.X = None\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "        self.pad = pad\n",
    "        self.out_width = None\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, X):\n",
    "        filter_num, channel_in, filter_height, filter_width = self.W.shape\n",
    "        self.out_height = (X.shape[2] + 2*self.pad - filter_height)//self.stride + 1\n",
    "        self.out_width = (X.shape[3] + 2*self.pad - filter_width)//self.stride + 1\n",
    "        X = np.pad(X, [(0,0), (0,0), (self.pad,self.pad), (self.pad,self.pad)], 'constant')\n",
    "        self.X = X\n",
    "        col = np.zeros((X.shape[0], channel_in, filter_height, filter_width, self.out_height, self.out_width))\n",
    "        \n",
    "        for height in range(filter_height):\n",
    "            height_max = height + self.stride*self.out_height\n",
    "            for width in range(filter_width):\n",
    "                width_max = width + self.stride*self.out_width\n",
    "                col[:, :, height, width, :, :] = X[:, :, height:height_max:self.stride, width:width_max:self.stride]\n",
    "        \n",
    "        col = col.transpose(0, 4, 5, 1, 2, 3).reshape(X.shape[0]*self.out_height*self.out_width, -1)\n",
    "        self.col = col\n",
    "        \n",
    "        # colと計算できるように変形\n",
    "        col_W = self.W.reshape(filter_num, -1).T\n",
    "        self.col_W = col_W\n",
    "        out = np.dot(col, col_W) + self.b\n",
    "        \n",
    "        # (サンプル数, フィルターと畳み込んだ要素)の形にする\n",
    "        out = out.reshape(X.shape[0], self.out_height, self.out_width, -1).transpose(0, 3, 1, 2)\n",
    "        \n",
    "        return out\n",
    "\n",
    "    def backward(self, dA):\n",
    "        filter_num, channel_in, filter_height, filter_width = self.W.shape\n",
    "        dA = dA.transpose(0, 2, 3, 1).reshape(-1, filter_num)\n",
    "        self.db = np.sum(dA)\n",
    "        self.dW = np.dot(self.col.T, dA)\n",
    "        self.dW = self.dW.transpose(1, 0).reshape(self.W.shape)\n",
    "        \n",
    "        dcol = np.dot(dA, self.col_W.T)\n",
    "        # フィルターと内積を取った全ての要素を元イメージの形に変換\n",
    "        dcol = dcol.reshape(self.X.shape[0], self.out_height, \n",
    "                            self.out_width, channel_in,\n",
    "                            filter_height, filter_width).transpose(0, 3, 4, 5, 1, 2)\n",
    "        dX = np.zeros((self.X.shape[0], self.X.shape[1], \n",
    "                       self.X.shape[2]+self.stride-1, self.X.shape[3]+self.stride-1))\n",
    "        \n",
    "        for height in range(filter_height):\n",
    "            height_max = height + self.stride*self.out_height\n",
    "            for width in range(filter_width):\n",
    "                width_max = width + self.stride*self.out_width\n",
    "                dX[:, :, height:height_max:self.stride, width:width_max:self.stride] += dcol[:, :, height, width, :, :]\n",
    "\n",
    "        self.optimizer.update(self)\n",
    "\n",
    "        return dX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4, 5, 5)\n",
      "(3, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# テスト\n",
    "filter_info = (4, 1, 24, 24)\n",
    "initializer = HeInitializer_conv()\n",
    "optimizer = AdaGrad(lr=0.01)\n",
    "\n",
    "conv = Conv2d(filter_info, initializer, optimizer)\n",
    "out = conv.forward(X_train[:3])\n",
    "print(out.shape)\n",
    "dout = conv.backward(np.ones((3,4,5,5)))\n",
    "print(dout.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題2】2次元畳み込み後の出力サイズ\n",
    "畳み込みを行うと特徴マップのサイズが変化します。どのように変化するかは以下の数式から求められます。この計算を行う関数を作成してください。\n",
    "$$\n",
    "N_{h,out}=\\frac{N_{h,in}+2P_h-F_h}{S_h}+1 \\\\\n",
    "N_{w,out}=\\frac{N_{w,in}+2P_w-F_w}{S_w}+1\n",
    "$$\n",
    "\n",
    "$N_{out}$ : 出力のサイズ（特徴量の数）\n",
    "\n",
    "$N_{in}$ : 入力のサイズ（特徴量の数）\n",
    "\n",
    "$P$ : ある方向へのパディングの数\n",
    "\n",
    "$F$ : フィルタのサイズ\n",
    "\n",
    "$S$ : ストライドのサイズ\n",
    "\n",
    "$h$ が高さ方向、 $w$ が幅方向である"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_output_size(X, pad, stride, filter_height, filter_width):\n",
    "    out_height = (X.shape[2] + 2*pad - filter_height) // stride + 1\n",
    "    out_width = (X.shape[3] + 2*pad - filter_width) // stride + 1\n",
    "    return out_height, out_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_output_size(X_train, 0, 1, 24, 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Conv2dクラスに反映"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d:\n",
    "    def __init__(self, filter_info, initializer, optimizer, pad=0, stride=1):\n",
    "        self.optimizer = deepcopy(optimizer)\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.W = initializer.W(filter_info)\n",
    "        self.b = initializer.B(filter_info)\n",
    "        self.X = None\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "        self.pad = pad\n",
    "        self.out_width = None\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, X):\n",
    "        filter_num, channel_in, filter_height, filter_width = self.W.shape\n",
    "        self.out_height, self.out_width = calc_output_size(X, self.pad, self.stride, filter_height, filter_width)\n",
    "        X = np.pad(X, [(0,0), (0,0), (self.pad,self.pad), (self.pad,self.pad)], 'constant')\n",
    "        self.X = X\n",
    "        col = np.zeros((X.shape[0], channel_in, filter_height, filter_width, self.out_height, self.out_width))\n",
    "\n",
    "        for height in range(filter_height):\n",
    "            height_max = height + self.stride*self.out_height\n",
    "            for width in range(filter_width):\n",
    "                width_max = width + self.stride*self.out_width\n",
    "                col[:, :, height, width, :, :] = X[:, :, height:height_max:self.stride, width:width_max:self.stride]\n",
    "        \n",
    "        col = col.transpose(0, 4, 5, 1, 2, 3).reshape(X.shape[0]*self.out_height*self.out_width, -1)\n",
    "        self.col = col\n",
    "        \n",
    "        # colと計算できるように変形\n",
    "        col_W = self.W.reshape(filter_num, -1).T\n",
    "        self.col_W = col_W\n",
    "        out = np.dot(col, col_W) + self.b\n",
    "        \n",
    "        # (サンプル数, チャンネル数, フィルター数, フィルターと畳み込んだ要素)の形にする\n",
    "        out = out.reshape(X.shape[0], self.out_height, self.out_width, -1).transpose(0, 3, 1, 2)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dA):\n",
    "        filter_num, channel_in, filter_height, filter_width = self.W.shape\n",
    "        dA = dA.transpose(0, 3, 1, 2).reshape(-1, filter_num)\n",
    "        self.db = np.sum(dA)\n",
    "        self.dW = np.dot(self.col.T, dA)\n",
    "        self.dW = self.dW.transpose(1, 0).reshape(self.W.shape)\n",
    "        \n",
    "        dcol = np.dot(dA, self.col_W.T)\n",
    "        # フィルターと内積を取った全ての要素を元イメージの形に変換\n",
    "        dcol = dcol.reshape(self.X.shape[0], self.out_height, \n",
    "                            self.out_width, channel_in,\n",
    "                            filter_height, filter_width).transpose(0, 3, 4, 5, 1, 2)\n",
    "        dX = np.zeros((self.X.shape[0], self.X.shape[1], \n",
    "                       self.X.shape[2]+self.stride-1, self.X.shape[3]+self.stride-1))\n",
    "        \n",
    "        for height in range(filter_height):\n",
    "            height_max = height + self.stride*self.out_height\n",
    "            for width in range(filter_width):\n",
    "                width_max = width + self.stride*self.out_width\n",
    "                dX[:, :, height:height_max:self.stride, width:width_max:self.stride] += dcol[:, :, height, width, :, :]\n",
    "\n",
    "        self.optimizer.update(self)\n",
    "\n",
    "        return dX[:, :, self.pad:self.X.shape[2] + self.pad, self.pad:self.X.shape[3] + self.pad]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1, 5, 5)\n",
      "(3, 1, 4, 4)\n",
      "(3, 1, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "# テスト\n",
    "filter_info = (1, 1, 2, 2)\n",
    "initializer = HeInitializer_conv()\n",
    "optimizer = AdaGrad(lr=0.01)\n",
    "\n",
    "test_X = np.array([[[[1,2,3,4,1],[2,4,6,8,1],[1,3,5,7,1],[1,1,1,1,1],[1,1,1,1,1]]],\n",
    "                  [[[1,2,3,4,1],[2,4,6,8,1],[1,3,5,7,1],[1,1,1,1,1],[1,1,1,1,1]]],\n",
    "                  [[[1,2,3,4,1],[2,4,6,8,1],[1,3,5,70,1],[1,1,1,1,1],[1,1,1,1,1]]]])\n",
    "\n",
    "print(test_X.shape)\n",
    "conv = Conv2d(filter_info, initializer, optimizer)\n",
    "out = conv.forward(test_X)\n",
    "print(out.shape)\n",
    "dout = conv.backward(np.ones((3,1,4,4)))\n",
    "print(dout.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題3】最大プーリング層の作成\n",
    "最大プーリング層のクラスMaxPool2Dを作成してください。プーリング層は数式で表さない方が分かりやすい部分もありますが、数式で表すとフォワードプロパゲーションは以下のようになります。\n",
    "$$\n",
    "a_{i,j,k}=\\max_{(p,q\\in P_{i,j})}x_{p,q,k}\n",
    "$$\n",
    "\n",
    "$P_{i,j}$ : i行j列への出力する場合の入力配列のインデックスの集合。 $S_{h}×S_{w}$ の範囲内の行（p）と列（q）\n",
    "\n",
    "$S_{h}, S_{w}$ : 高さ方向（h）と幅方向（w）のストライドのサイズ\n",
    "\n",
    "$(p,q)\\in P_{i,j}$ : $P_{i,j}$ に含まれる行（p）と列（q）のインデックス\n",
    "\n",
    "$a_{i,j,m}$ : 出力される配列のi行j列、kチャンネルの値\n",
    "\n",
    "$x_{p,q,k}$ : 入力の配列のp行q列、kチャンネルの値\n",
    "\n",
    "ある範囲の中でチャンネル方向の軸は残したまま最大値を計算することになります。\n",
    "\n",
    "バックプロパゲーションのためには、フォワードプロパゲーションのときの最大値のインデックス $(p,q)$ を保持しておく必要があります。フォワード時に最大値を持っていた箇所にそのままの誤差を流し、そこ以外には0を入れるためです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool2D:\n",
    "    def __init__(self, pool_h, pool_w, stride=1, pad=0):\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.stride = stride\n",
    "        self.x = None\n",
    "        self.arg_max = None\n",
    "        self.pad=pad\n",
    "\n",
    "    def forward(self, X):\n",
    "        n_samples, n_channels, height, width = X.shape\n",
    "        self.out_height = int(1 + (height - self.pool_h) / self.stride)\n",
    "        self.out_width = int(1 + (width - self.pool_w) / self.stride)\n",
    "        X = np.pad(X, [(0,0), (0,0), (self.pad,self.pad), (self.pad,self.pad)], 'constant')\n",
    "\n",
    "        col = np.zeros((n_samples, n_channels, self.pool_h, self.pool_w, self.out_height, self.out_width))\n",
    "        \n",
    "        for height in range(self.pool_h):\n",
    "            height_max = height + self.stride*self.out_height\n",
    "            for width in range(self.pool_w):\n",
    "                width_max = width + self.stride*self.out_width\n",
    "                col[:, :, height, width, :, :] = X[:, :, height:height_max:self.stride, width:width_max:self.stride]\n",
    "        \n",
    "        col = col.transpose(0, 4, 5, 1, 2, 3).reshape(X.shape[0]*self.out_height*self.out_width, -1)\n",
    "\n",
    "        col = col.reshape(-1, self.pool_h*self.pool_w)\n",
    "        arg_max = np.argmax(col, axis=1)\n",
    "        out = np.max(col, axis=1)\n",
    "        out = out.reshape(n_samples, self.out_height, self.out_width, n_channels).transpose(0, 3, 1, 2)\n",
    "\n",
    "        self.X = X\n",
    "        self.arg_max = arg_max\n",
    "\n",
    "        return out \n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout = dout.transpose(0, 2, 3, 1)\n",
    "    \n",
    "        pool_size = self.pool_h * self.pool_w\n",
    "        dmax = np.zeros((dout.size, pool_size))\n",
    "        dmax[np.arange(self.arg_max.size), self.arg_max.flatten()] = dout.flatten()\n",
    "        dmax = dmax.reshape(dout.shape + (pool_size,)) \n",
    "    \n",
    "        dcol = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2], -1)\n",
    "        \n",
    "        dcol = dcol.reshape(self.X.shape[0], self.out_height, \n",
    "                            self.out_width, self.X.shape[1],\n",
    "                            self.pool_h, self.pool_w).transpose(0, 3, 4, 5, 1, 2)\n",
    "        dX = np.zeros((self.X.shape[0], self.X.shape[1], \n",
    "                       self.X.shape[2]+self.stride-1, self.X.shape[3]+self.stride-1))\n",
    "        \n",
    "        for height in range(self.pool_h):\n",
    "            height_max = height + self.stride*self.out_height\n",
    "            for width in range(self.pool_w):\n",
    "                width_max = width + self.stride*self.out_width\n",
    "                dX[:, :, height:height_max:self.stride, width:width_max:self.stride] += dcol[:, :, height, width, :, :]\n",
    "        \n",
    "        return dX[:, :, self.pad:self.X.shape[2] + self.pad, self.pad:self.X.shape[3] + self.pad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1, 4, 4)\n",
      "(3, 1, 3, 3)\n",
      "(3, 1, 4, 4)\n",
      "[[[[  -9.18079427  -14.10973041  -19.03866655   -5.31684448]\n",
      "   [  -8.19900158  -13.47291687  -18.74683215   -2.18728154]\n",
      "   [  -4.567371     -5.25732928   -5.94728756    1.08440761]\n",
      "   [  -2.63695764   -2.63695764   -2.63695764   -2.63695764]]]\n",
      "\n",
      "\n",
      " [[[  -9.18079427  -14.10973041  -19.03866655   -5.31684448]\n",
      "   [  -8.19900158  -13.47291687  -18.74683215   -2.18728154]\n",
      "   [  -4.567371     -5.25732928   -5.94728756    1.08440761]\n",
      "   [  -2.63695764   -2.63695764   -2.63695764   -2.63695764]]]\n",
      "\n",
      "\n",
      " [[[  -9.18079427  -14.10973041  -19.03866655   -5.31684448]\n",
      "   [  -8.19900158  -13.47291687 -122.27635259  -43.05240674]\n",
      "   [  -4.567371     -5.25732928  -66.75530841   40.1587427 ]\n",
      "   [  -2.63695764   -2.63695764   -2.63695764   -2.63695764]]]]\n",
      "[[[[ -8.19900158 -13.47291687  -2.18728154]\n",
      "   [ -4.567371    -5.25732928   1.08440761]\n",
      "   [ -2.63695764  -2.63695764   1.08440761]]]\n",
      "\n",
      "\n",
      " [[[ -8.19900158 -13.47291687  -2.18728154]\n",
      "   [ -4.567371    -5.25732928   1.08440761]\n",
      "   [ -2.63695764  -2.63695764   1.08440761]]]\n",
      "\n",
      "\n",
      " [[[ -8.19900158 -13.47291687  -5.31684448]\n",
      "   [ -4.567371    -5.25732928  40.1587427 ]\n",
      "   [ -2.63695764  -2.63695764  40.1587427 ]]]]\n"
     ]
    }
   ],
   "source": [
    "pooling = MaxPool2D(2, 2, stride=1)\n",
    "print(out.shape)\n",
    "pool_out = pooling.forward(out)\n",
    "print(pool_out.shape)\n",
    "pool_back = pooling.backward(pool_out)\n",
    "print(pool_back.shape)\n",
    "print(out)\n",
    "print(pool_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題4】（アドバンス課題）平均プーリングの作成\n",
    "平均プーリング層のクラスAveragePool2Dを作成してください。\n",
    "\n",
    "範囲内の最大値ではなく、平均値を出力とするプーリング層です。\n",
    "\n",
    "画像認識関係では最大プーリング層が一般的で、平均プーリングはあまり使われません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AveragePool2D:\n",
    "    def __init__(self, pool_h, pool_w, stride=1, pad=0):\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.stride = stride\n",
    "        self.x = None\n",
    "        self.arg_max = None\n",
    "        self.pad=pad\n",
    "\n",
    "    def forward(self, X): \n",
    "        n_samples, n_channels, height, width = X.shape\n",
    "        self.out_height = int(1 + (height - self.pool_h) / self.stride)\n",
    "        self.out_width = int(1 + (width - self.pool_w) / self.stride)\n",
    "        X = np.pad(X, [(0,0), (0,0), (self.pad,self.pad), (self.pad,self.pad)], 'constant')\n",
    "\n",
    "        col = np.zeros((n_samples, n_channels, self.pool_h, self.pool_w, self.out_height, self.out_width))\n",
    "        \n",
    "        for height in range(self.pool_h):\n",
    "            height_max = height + self.stride*self.out_height\n",
    "            for width in range(self.pool_w):\n",
    "                width_max = width + self.stride*self.out_width\n",
    "                col[:, :, height, width, :, :] = X[:, :, height:height_max:self.stride, width:width_max:self.stride]\n",
    "        \n",
    "        col = col.transpose(0, 4, 5, 1, 2, 3).reshape(X.shape[0]*self.out_height*self.out_width, -1)\n",
    "\n",
    "        col = col.reshape(-1, self.pool_h*self.pool_w)\n",
    "        out = np.mean(col, axis=1)\n",
    "        out = out.reshape(n_samples, self.out_height, self.out_width, n_channels).transpose(0, 3, 1, 2)\n",
    "\n",
    "        self.X = X\n",
    "\n",
    "        return out \n",
    "\n",
    "    def backward(self, dout):\n",
    "        \n",
    "        return dout / (self.pool_h*self.pool_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooling = AveragePool2D(2, 2, stride=2)\n",
    "# print(out.shape)\n",
    "pool_out = pooling.forward(out)\n",
    "# print(pool_out.shape)\n",
    "pool_back = pooling.backward(pool_out)\n",
    "# print(pool_back.shape)\n",
    "# print(out)\n",
    "# print(pool_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題5】平滑化\n",
    "平滑化するためのFlattenクラスを作成してください。\n",
    "\n",
    "フォワードのときはチャンネル、高さ、幅の3次元を1次元にreshapeします。その値は記録しておき、バックワードのときに再びreshapeによって形を戻します。\n",
    "\n",
    "この平滑化のクラスを挟むことで出力前の全結合層に適した配列を作ることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten:\n",
    "    def __init__(self):\n",
    "        self.channel = None\n",
    "        self.height = None\n",
    "        self.width = None\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.channel = X.shape[1]\n",
    "        self.height = X.shape[2]\n",
    "        self.width = X.shape[3]\n",
    "        return X.reshape(X.shape[0], -1)\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        return dA.reshape(dA.shape[0], self.channel, self.height, self.width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題6】学習と推定\n",
    "作成したConv2dを使用してMNISTを学習・推定し、Accuracyを計算してください。\n",
    "\n",
    "精度は低くともまずは動くことを目指してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from collections import OrderedDict\n",
    "\n",
    "class FC:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        self.optimizer = deepcopy(optimizer)\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.W = initializer.W(n_nodes1, n_nodes2)\n",
    "        self.b = initializer.B(n_nodes2)\n",
    "        self.X = None\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"        \n",
    "        self.X = X\n",
    "        out = np.dot(X, self.W) + self.b\n",
    "        \n",
    "        return out\n",
    "\n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        # 更新\n",
    "        batch_size = dA.shape[0]\n",
    "        dX = np.dot(dA, self.W.T)\n",
    "        self.dW = np.dot(self.X.T, dA) / batch_size\n",
    "        self.db = np.sum(dA, axis=0) / batch_size\n",
    "        self = self.optimizer.update(self)\n",
    "        \n",
    "        return dX\n",
    "\n",
    "\n",
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.mask = (x < 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "        \n",
    "        return dx\n",
    "\n",
    "    \n",
    "class Softmax():\n",
    "    def __init__(self):\n",
    "        self.loss = None\n",
    "        self.y = None\n",
    "        self.t = None\n",
    "    \n",
    "    def _softmax(self, X):\n",
    "        X = X - np.max(X, axis=-1, keepdims=True)\n",
    "        y = np.exp(X) / np.sum(np.exp(X), axis=-1, keepdims=True)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    def _cross_entropy_error(self, y, t):\n",
    "        batch_size = y.shape[0]\n",
    "\n",
    "        return -np.sum(t * np.log(y + 1e-7)) / batch_size\n",
    "    \n",
    "    def forward(self, X, t):\n",
    "        self.t = t\n",
    "        self.y = self._softmax(X)\n",
    "        self.loss = self._cross_entropy_error(self.y, self.t)\n",
    "        \n",
    "        return self.loss\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        dX = (self.y - self.t) / batch_size\n",
    "        \n",
    "        return dX\n",
    "\n",
    "    \n",
    "class ScratchDeepNeuralNetrowkClassifier():\n",
    "    def __init__(self, lr, verbose=True, batch_size=20, max_iter=3):\n",
    "        self.verbose = verbose\n",
    "        self.batch_size = batch_size\n",
    "        self.max_iter = max_iter\n",
    "        self.list_train_loss = []\n",
    "        self.list_test_loss = []\n",
    "        # レイヤの生成\n",
    "        initializer = XavierInitializer()\n",
    "        initializer_conv = XavierInitializer_conv()\n",
    "        optimizer = AdaGrad(lr=lr)\n",
    "        self.layers = OrderedDict()\n",
    "        filter_info_1 = (6, 1, 3, 3)\n",
    "        filter_info_2 = (12, 6, 3, 3)\n",
    "        pad = 0\n",
    "        self.layers[\"Conv2d_1\"] = Conv2d(filter_info_1, initializer_conv, optimizer, pad=pad, stride=1)\n",
    "        self.layers[\"ReLU1\"] = Relu()\n",
    "        self.layers[\"Pooling1\"] = MaxPool2D(2, 2, stride=2, pad=pad)\n",
    "        self.layers[\"Conv2d_2\"] = Conv2d(filter_info_2, initializer_conv, optimizer, pad=pad, stride=1)\n",
    "        self.layers[\"ReLU2\"] = Relu()\n",
    "        self.layers[\"Pooling2\"] = MaxPool2D(2, 2, stride=1, pad=pad)\n",
    "        self.layers[\"Flatten\"] = Flatten()\n",
    "        self.layers[\"FC1\"] = FC(1200, 500, initializer, optimizer)\n",
    "        self.layers[\"ReLU3\"] = Relu()\n",
    "        self.layers[\"FC2\"] = FC(500, 100, initializer, optimizer)\n",
    "        self.layers[\"ReLU4\"] = Relu()\n",
    "        self.layers[\"FC3\"] = FC(100, 10, initializer, optimizer)\n",
    "        self.lastLayer = Softmax()\n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        flg_test = 0\n",
    "        if (X_val is not None) and (y_val is not None):\n",
    "            flg_test = 1\n",
    "\n",
    "        # 1エポックの繰り返し数\n",
    "        iter_num = int(len(X) / self.batch_size)\n",
    "            \n",
    "        # エポックを複数回繰り返す\n",
    "        for i_ in range(self.max_iter):\n",
    "            # 損失計算用\n",
    "            tmp_list_loss_train = []\n",
    "            tmp_list_loss_val = []\n",
    "\n",
    "            # 1エポック\n",
    "            for j_ in range(iter_num):\n",
    "                batch_mask = np.random.choice(X.shape[0], self.batch_size)\n",
    "                batch_mask_val = np.random.choice(X_val.shape[0], self.batch_size)\n",
    "                X_batch = X[batch_mask]\n",
    "                y_batch = y[batch_mask]\n",
    "                X_val_batch = X_val[batch_mask_val]\n",
    "                y_val_batch = y_val[batch_mask_val]\n",
    "                \n",
    "                self._gradient(X_batch, y_batch)\n",
    "                \n",
    "                loss_train = self._loss(X_batch, y_batch)\n",
    "                tmp_list_loss_train.append(loss_train)\n",
    "                if flg_test == 1:\n",
    "                    loss_test = self._loss(X_val_batch, y_val_batch)\n",
    "                    tmp_list_loss_val.append(loss_test)\n",
    "                    \n",
    "                if self.verbose:\n",
    "                    #verboseをTrueにした際は学習過程などを出力する\n",
    "                    print(\"loss_train:{}\".format(loss_train))\n",
    "                    print(\"loss_test:{}\".format(loss_test))\n",
    "            \n",
    "            # 損失をインスタンス領域に設定\n",
    "            self.list_train_loss.append(sum(tmp_list_loss_train)/len(tmp_list_loss_train))\n",
    "            self.list_test_loss.append(sum(tmp_list_loss_val)/len(tmp_list_loss_val))\n",
    "                \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        for layer in self.layers.values():\n",
    "            X = layer.forward(X)\n",
    "            \n",
    "        pred = np.argmax(X, axis=1)\n",
    "        \n",
    "        return pred\n",
    "    \n",
    "    def _loss(self, X, t):\n",
    "        for layer in self.layers.values():\n",
    "            X = layer.forward(X)\n",
    "        \n",
    "        return self.lastLayer.forward(X, t)\n",
    "\n",
    "    def _gradient(self, X, t):\n",
    "        self._loss(X, t)\n",
    "        \n",
    "        dout = 1\n",
    "        dout = self.lastLayer.backward(dout)\n",
    "        \n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "                    \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = ScratchDeepNeuralNetrowkClassifier(lr=0.1, verbose=False, batch_size=20, max_iter=10)\n",
    "nn.fit(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = np.argmax(y_val, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正答率:0.90825\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = nn.predict(X_val)\n",
    "\n",
    "accuracy = accuracy_score(y_pred, y_val)\n",
    "print(\"正答率:{}\".format(accuracy))\n",
    "\n",
    "x = np.arange(1, len(nn.list_train_loss)+1)\n",
    "plt.plot(x, nn.list_train_loss, label=\"loss\")\n",
    "plt.plot(x, nn.list_test_loss, label=\"val_loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "問題7のAlexNetチックなモデルより良い性能が出せた。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題7】（アドバンス課題）LeNet\n",
    "CNNで画像認識を行う際は、フィルタサイズや層の数などを１から考えるのではなく、有名な構造を利用することが一般的です。現在では実用的に使われることはありませんが、歴史的に重要なのは1998年の LeNet です。この構造を再現してMNISTに対して動かし、Accuracyを計算してください。\n",
    "\n",
    "[Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278–2324, 1998.](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf)\n",
    "\n",
    "<img src=\"https://t.gyazo.com/teams/diveintocode/83358987a273743a589b9388dfdf59ac.png\" width=\"400\">\n",
    "\n",
    "※上記論文から引用\n",
    "\n",
    "サブサンプリングとは現在のプーリングに相当するものです。現代風に以下のように作ってみることにします。活性化関数も当時はシグモイド関数ですが、ReLUとします。\n",
    "\n",
    "1. 畳み込み層　出力チャンネル数6、フィルタサイズ5×5、ストライド1\n",
    "2. ReLU\n",
    "3. 最大プーリング\n",
    "4. 畳み込み層　出力チャンネル数16、フィルタサイズ5×5、ストライド1\n",
    "5. ReLU\n",
    "6. 最大プーリング\n",
    "7. 平滑化\n",
    "8. 全結合層　出力ノード数120\n",
    "9. ReLU\n",
    "10. 全結合層　出力ノード数84\n",
    "11. ReLU\n",
    "12. 全結合層　出力ノード数10\n",
    "13. ソフトマックス関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchDeepNeuralNetrowkClassifier():\n",
    "    def __init__(self, lr, verbose=True, batch_size=20, max_iter=3):\n",
    "        self.verbose = verbose\n",
    "        self.batch_size = batch_size\n",
    "        self.max_iter = max_iter\n",
    "        self.list_train_loss = []\n",
    "        self.list_test_loss = []\n",
    "        # レイヤの生成\n",
    "        initializer = XavierInitializer()\n",
    "        initializer_conv = XavierInitializer_conv()\n",
    "        optimizer = AdaGrad(lr=lr)\n",
    "        self.layers = OrderedDict()\n",
    "        filter_info_1 = (6, 1, 5, 5)\n",
    "        filter_info_2 = (16, 6, 5, 5)\n",
    "        pad = 0\n",
    "        self.layers[\"Conv2d_1\"] = Conv2d(filter_info_1, initializer_conv, optimizer, pad=pad, stride=1)\n",
    "        self.layers[\"ReLU1\"] = Relu()\n",
    "        self.layers[\"Pooling1\"] = MaxPool2D(2, 2, stride=2, pad=pad)\n",
    "        self.layers[\"Conv2d_2\"] = Conv2d(filter_info_2, initializer_conv, optimizer, pad=pad, stride=1)\n",
    "        self.layers[\"ReLU2\"] = Relu()\n",
    "        self.layers[\"Pooling2\"] = MaxPool2D(2, 2, stride=1, pad=pad)\n",
    "        self.layers[\"Flatten\"] = Flatten()\n",
    "        self.layers[\"FC1\"] = FC(784, 120, initializer, optimizer)\n",
    "        self.layers[\"ReLU3\"] = Relu()\n",
    "        self.layers[\"FC2\"] = FC(120, 84, initializer, optimizer)\n",
    "        self.layers[\"ReLU4\"] = Relu()\n",
    "        self.layers[\"FC3\"] = FC(84, 10, initializer, optimizer)\n",
    "        self.lastLayer = Softmax()\n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        flg_test = 0\n",
    "        if (X_val is not None) and (y_val is not None):\n",
    "            flg_test = 1\n",
    "\n",
    "        # 1エポックの繰り返し数\n",
    "        iter_num = int(len(X) / self.batch_size)\n",
    "            \n",
    "        # エポックを複数回繰り返す\n",
    "        for i_ in range(self.max_iter):\n",
    "            # 損失計算用\n",
    "            tmp_list_loss_train = []\n",
    "            tmp_list_loss_val = []\n",
    "\n",
    "            # 1エポック\n",
    "            for j_ in range(iter_num):\n",
    "                batch_mask = np.random.choice(X.shape[0], self.batch_size)\n",
    "                batch_mask_val = np.random.choice(X_val.shape[0], self.batch_size)\n",
    "                X_batch = X[batch_mask]\n",
    "                y_batch = y[batch_mask]\n",
    "                X_val_batch = X_val[batch_mask_val]\n",
    "                y_val_batch = y_val[batch_mask_val]\n",
    "                \n",
    "                self._gradient(X_batch, y_batch)\n",
    "                \n",
    "                loss_train = self._loss(X_batch, y_batch)\n",
    "                tmp_list_loss_train.append(loss_train)\n",
    "                if flg_test == 1:\n",
    "                    loss_test = self._loss(X_val_batch, y_val_batch)\n",
    "                    tmp_list_loss_val.append(loss_test)\n",
    "                    \n",
    "                if self.verbose:\n",
    "                    #verboseをTrueにした際は学習過程などを出力する\n",
    "                    print(\"loss_train:{}\".format(loss_train))\n",
    "                    print(\"loss_test:{}\".format(loss_test))\n",
    "            \n",
    "            # 損失をインスタンス領域に設定\n",
    "            self.list_train_loss.append(sum(tmp_list_loss_train)/len(tmp_list_loss_train))\n",
    "            self.list_test_loss.append(sum(tmp_list_loss_val)/len(tmp_list_loss_val))\n",
    "                \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        for layer in self.layers.values():\n",
    "            X = layer.forward(X)\n",
    "            \n",
    "        pred = np.argmax(X, axis=1)\n",
    "        \n",
    "        return pred\n",
    "    \n",
    "    def _loss(self, X, t):\n",
    "        for layer in self.layers.values():\n",
    "            X = layer.forward(X)\n",
    "        \n",
    "        return self.lastLayer.forward(X, t)\n",
    "\n",
    "    def _gradient(self, X, t):\n",
    "        self._loss(X, t)\n",
    "        \n",
    "        dout = 1\n",
    "        dout = self.lastLayer.backward(dout)\n",
    "        \n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "                    \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = ScratchDeepNeuralNetrowkClassifier(lr=0.1, verbose=False, batch_size=20, max_iter=10)\n",
    "nn.fit(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = np.argmax(y_val, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正答率:0.8858333333333334\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU9b3/8ddntiyThWwkkAAJyCIkSDCAK2pxX0Cwgtu1emu9bd2q1qv31t5aa1tve6tdfrZe69XaVquIiFAX6oJFrVLCvi+GLQlLdkhC9u/vjzNZCRDgJGdm8nk+HvOYzMzJmU+ivOeb7/mezxFjDEoppUKfy+kClFJK2UMDXSmlwoQGulJKhQkNdKWUChMa6EopFSY8Tr1xcnKyyczMdOrtlVIqJK1YsaLUGJPS3WuOBXpmZib5+flOvb1SSoUkEdl1tNd0ykUppcKEBrpSSoUJDXSllAoTjs2hK6X6p8bGRgoLC6mrq3O6lKAWGRlJRkYGXq+3x9+jga6U6lOFhYXExsaSmZmJiDhdTlAyxlBWVkZhYSFZWVk9/j6dclFK9am6ujqSkpI0zI9BREhKSjrhv2I00JVSfU7D/PhO5ncUeoFemA8fPOZ0FUopFXR6FOgicrmIbBGR7SLySDevPy0iqwO3rSJSaX+pAcWr4NOnYd/6XnsLpVR4i4mJcbqEXnHcQBcRN/AMcAUwFrhRRMZ23MYYc78xZoIxZgLwG2B+bxQLwLhZ4PLA2td67S2UUioU9WSEPhnYbowpMMY0AK8CM46x/Y3AX+worlv+JDjtElg3D1paeu1tlFLhzxjDQw89RHZ2Njk5Obz2mjVQ3Lt3L1OnTmXChAlkZ2fzySef0NzczG233da27dNPP+1w9UfqybLFdGBPh8eFwJTuNhSRYUAW8NFRXr8TuBNg6NChJ1RoJ+Ovh63vwq5PIWvqye9HKeWoHy7awMbig7buc+zgOH5wzbgebTt//nxWr17NmjVrKC0tZdKkSUydOpVXXnmFyy67jO9973s0NzdTW1vL6tWrKSoqYv16a7q3srL3ZpZPlt0HRW8A5hljmrt70RjznDEmzxiTl5LSbbOwnhl1BfhiddpFKXVKPv30U2688UbcbjepqalccMEFLF++nEmTJvHiiy/y2GOPsW7dOmJjYxk+fDgFBQXcc889vPfee8TFxTld/hF6MkIvAoZ0eJwReK47NwB3nWpRx+WLhrHTYeNCuPIX4I3s9bdUStmvpyPpvjZ16lSWLl3K22+/zW233cYDDzzArbfeypo1a1i8eDHPPvssc+fO5YUXXnC61E56MkJfDowUkSwR8WGF9sKuG4nIGCAB+NzeEo8i53qoPwhb3+uTt1NKhZ/zzz+f1157jebmZkpKSli6dCmTJ09m165dpKam8o1vfIM77riDlStXUlpaSktLC9dddx1PPPEEK1eudLr8Ixx3hG6MaRKRu4HFgBt4wRizQUQeB/KNMa3hfgPwqjHG9F65HWRNhZg0WDsXxl3bJ2+plAovM2fO5PPPP+eMM85ARPjZz35GWloaL730Ej//+c/xer3ExMTwxz/+kaKiIm6//XZaAosxfvrTnzpc/ZGkr/K3q7y8PHPKF7hY/D1Y9r/w3a0QnWhPYUqpXrVp0yZOP/10p8sICd39rkRkhTEmr7vtQ+9M0Y7Gz4aWRti4wOlKlFLKcaEd6GnjIWWMNe2ilFL9XGgHuog1St/9OVQc9TJ7SinVL4R2oIO12gVg3evO1qGUUg4L/UAfMBSGnmNNuzh0gFcppYJB6Ac6WNMupVtg31qnK1FKKceER6CPnQEurx4cVUr1a+ER6NGJMOqyQAfGbtvIKKXUSTlW7/SdO3eSnZ3dh9UcW3gEOljTLtX7YMdSpytRSilH9KQ5V2gYeRlExFvTLiMucroapVRPvPsI7Ftn7z7TcuCKJ4/68iOPPMKQIUO46y6rj+Bjjz2Gx+NhyZIlVFRU0NjYyBNPPMGMGce67MOR6urq+Na3vkV+fj4ej4ennnqKiy66iA0bNnD77bfT0NBAS0sLb7zxBoMHD2b27NkUFhbS3NzM97//febMmXNKPzaEU6B7I60OjBsWwFW/sDoyKqVUF3PmzOE73/lOW6DPnTuXxYsXc++99xIXF0dpaSlnnXUW06dPP6ELNT/zzDOICOvWrWPz5s1ceumlbN26lWeffZb77ruPm2++mYaGBpqbm3nnnXcYPHgwb7/9NgBVVVW2/GzhE+gA4+fAqj9ZF7/Ivs7papRSx3OMkXRvyc3N5cCBAxQXF1NSUkJCQgJpaWncf//9LF26FJfLRVFREfv37yctLa3H+/3000+55557ABgzZgzDhg1j69atnH322fz4xz+msLCQWbNmMXLkSHJycnjwwQd5+OGHufrqqzn//PNt+dnCZw4dYNi5EJeuq12UUsd0/fXXM2/ePF577TXmzJnDyy+/TElJCStWrGD16tWkpqZSV1dny3vddNNNLFy4kKioKK688ko++ugjRo0axcqVK8nJyeHRRx/l8ccft+W9wivQXS7I+Sps/wBqypyuRikVpObMmcOrr77KvHnzuP7666mqqmLgwIF4vV6WLFnCrl0n3krk/PPP5+WXXwZg69at7N69m9GjR1NQUMDw4cO59957mTFjBmvXrqW4uJjo6GhuueUWHnroIdt6q4dXoAPkzIaWJtgw3+lKlFJBaty4cRw6dIj09HQGDRrEzTffTH5+Pjk5Ofzxj39kzJgxJ7zPb3/727S0tJCTk8OcOXP4wx/+QEREBHPnziU7O5sJEyawfv16br31VtatW8fkyZOZMGECP/zhD3n00Udt+blCux/60fz2HPD54Y73e2f/SqmTpv3Qe65/9UM/mvGzofCfUL7D6UqUUqrPhGeg53wVEO3AqJSyxbp165gwYUKn25QpU5wu6wjhtWyxVXwGZJ4Ha1+DqQ9ZfdOVUkHDGHNCa7ydlpOTw+rVq/v0PU9mOjw8R+hgTbuUbYfiVU5XopTqIDIykrKyspMKrP7CGENZWRmRkZEn9H3hOUIHOH06vP2gtSY9faLT1SilAjIyMigsLKSkpMTpUoJaZGQkGRkZJ/Q94RvoUQNg1OWwfh5c+gS4w/dHVSqUeL1esrKynC4jLIXvlAtYrQBqSmDHx05XopRSvS68A33kJRAZr60AlFL9QngHuicCxs2ETX+Fhhqnq1FKqV4V3oEO1rRLYw1sfsfpSpRSqleFf6APOQvih1hr0pVSKoyFf6C7XJBzPXz5EVTrMimlVPgK/0AHa9rFNGsHRqVUWOsfgT5wjHWdQZ12UUqFsf4R6GCN0otWQNmXTleilFK9ov8EenagA6OuSVdKhan+E+hxgyBrqjXtok2BlFJhqP8EOljTLhU7oLCXrpSklFIO6l+Bfvo14ImEdTrtopQKP/0r0CPjYPQVsP4NaG50uhqllLJV/wp0sKZdasusE42UUiqM9L9AHzENohJ0tYtSKuz0v0D3+GDcLNj8NtQfcroapZSyTY8CXUQuF5EtIrJdRB45yjazRWSjiGwQkVfsLdNm4+dA02Grra5SSoWJ4wa6iLiBZ4ArgLHAjSIytss2I4H/AM41xowDvtMLtdpnyGQYMExXuyilwkpPRuiTge3GmAJjTAPwKjCjyzbfAJ4xxlQAGGMO2FumzURg/Gwo+BgO7XO6GqWUskVPAj0d2NPhcWHguY5GAaNE5DMR+UJELu9uRyJyp4jki0i+41f8zpkNpsVawqiUUmHAroOiHmAkcCFwI/B7ERnQdSNjzHPGmDxjTF5KSopNb32SUkbBoAm62kUpFTZ6EuhFwJAOjzMCz3VUCCw0xjQaY3YAW7ECPriNnwN7V0PJVqcrUUqpU9aTQF8OjBSRLBHxATcAC7tsswBrdI6IJGNNwRTYWGfvyL4OxKUHR5VSYeG4gW6MaQLuBhYDm4C5xpgNIvK4iEwPbLYYKBORjcAS4CFjTFlvFW2b2FQYfqF2YFRKhQUxDgVZXl6eyc8Pgq6Ha16FN/8N/nUxDD3L6WqUUuqYRGSFMSavu9f635miXY25GrzRenBUKRXyNNAjYmD0ldYFpJsanK5GKaVOWsgFenHlYeatKLR3p+PnwOEK2P6BvftVSqk+FHKB/uaqIr77+hr2lNfat9MRF0F0sq52UUqFtJAL9BkTBgNWsNvG7YXsWbDlXairsm+/SinVh0Iu0DMSopmSlciCVUXYukJn/BxoqoNNi+zbp1JK9aGQC3SAWRPTKSitYU2hjaPp9DMhcbiudlFKhayQDPQrcgYR4XHx5kobD46KWA27diyFg8X27VcppfpISAZ6XKSXi8emsmjtXhqbW+zb8fjZgIF18+zbp1JK9ZGQDHSAmRPSKa9p4O9bbGzDmzQC0vN0tYtSKiSFbKBfMDqFRL/P3tUuYI3S962D/Rvt3a9SSvWykA10r9vFNeMH8f6m/Rysa7Rvx+Nmgbh1lK6UCjkhG+gAMydm0NDUwrvr9tq305gUGPEVax69xcb5eaWU6mUhHehnZMQzPNnP/JV2T7vMgao9sPtze/erlFK9KKQDXUSYmZvOsh3lFFbY2ApgzJXg9Vt90pVSKkSEdKADXJtrXa/6rdU2rh33+eH0q2HjAmiqt2+/SinVi0I+0IckRjMpM4H5KwttbgUw2+rrsu1v9u1TKaV6UcgHOsDM3Ay+LKlhfdFB+3aadSH4B+q0i1IqZIRFoF+VMwif28X8VTa2AnB7rItIb10Mhyvt269SSvWSsAj0+Ggv004fyKI1xTTZ3QqguQE2vmXfPpVSqpeERaADzMxNp7S6gU+2ldq308G5kDRSOzAqpUJC2AT6haMHMiDay3w7WwGIWKP0XZ9C5R779quUUr0gbALd53Fx9fhB/G3DPg7Z2Qog53rrfr12YFRKBbewCXSwVrvUN7Xw3vp99u00MQuGTNFpF6VU0AurQJ84dACZSdH2d2DMuR4ObIR96+3dr1JK2SisAl1EuDY3nc8Lythbddi+HY+bBS6PrklXSgW1sAp0sFa7GAMLVtnYCsCfBKddEujA2GzffpVSykZhF+jDkvxMHDqAN1fZ3QrgejhUDLs+s2+fSillo7ALdLD6pG/dX82GYhtbAYy6AnyxOu2ilApaYRnoV+cMwusWFth5cNQXDWOnw8aF0Fhn336VUsomYRnoCX4fF40eyFt2twLIuR7qD8LW9+zbp1JK2SQsAx1g1sR0Sg7V89mXZfbtNGsqxKTpmnSlVFAK20C/aMxA4iI9vLnSxg6MLjfkfNXqkV5bbt9+lVLKBmEb6BEeN1eNH8ziDfupqW+yb8fjZ0NLo3U1I6WUCiJhG+hgTbscbmxm8QYbWwGkjYeUMTrtopQKOmEd6HnDEhiSGGVvKwAR6+Do7s+hYpd9+1VKqVMU1oEuIsyckM5n20vZf9DGpYatHRjXvW7fPpVS6hSFdaCDdZJRi4G3Vts4Sk8YBkPPgX/8BpY9B0319u1bKaVOUtgHelaynwlDBjB/pc0dGK/5JaRmw7sPwW/yYNXL0GzjwVellDpBPQp0EblcRLaIyHYReaSb128TkRIRWR243WF/qSdvZm46m/cdYtNeG1sBpIyG2/4Kt8yH6ER469vwu7NhwwJosfFkJqWU6qHjBrqIuIFngCuAscCNIjK2m01fM8ZMCNyet7nOU3LNGYPxuGxuBQDWAdLTpsGdH8PsPwECr38Nfn8hbPsA7GwOppRSx9GTEfpkYLsxpsAY0wC8Cszo3bLslej3ceHoFBasLqK5pRdCVsTq8/Ltz+HaZ+FwJbx8Hbx4Jez6h/3vp5RS3ehJoKcDHa+QXBh4rqvrRGStiMwTkSHd7UhE7hSRfBHJLykpOYlyT97M3Az2H6zncztbAXTlcsOEG+HufLjqF1BeAC9eAX/+KhSv7r33VUop7DsougjINMaMB94HXupuI2PMc8aYPGNMXkpKik1v3TPTTh9IbKSH+atsbAVwNB4fTLoD7l0FlzwORfnw3AUw92tQsrX3318p1S/1JNCLgI4j7ozAc22MMWXGmNa1e88DZ9pTnn0ivW6uyhnEe+v3UdvQR6tRfNFw7n1w3xq44GHY/gH8dgosuAsqd/dNDUqpfqMngb4cGCkiWSLiA24AFnbcQEQGdXg4HdhkX4n2uTY3ndqGZv62YX/fvnFkPFz0n1awn/Vt64SkX0+Ed/4dDvVxLUqpsHXcQDfGNAF3A4uxgnquMWaDiDwuItMDm90rIhtEZA1wL3BbbxV8KiZnJpI+wOZWACfCnwyX/diaism9GZY/D7+eAB/8EA5XOFOTUipsiK3X3TwBeXl5Jj8/v8/f9+eLN/O7j7/ki/+cxsDYyD5//07KvoSPf2pdfDoiDs69F6Z8EyJinK1LKRW0RGSFMSavu9fC/kzRrmbmWq0AFq4udroUSBoB1z0P3/wUMs+Fj35kjdi/eFbbCSilTli/C/TTBsYwPiPeuWmX7qRlw41/ga9/AANPh/cetubYV/5J2wkopXqs3wU6WK0ANhQfZOv+Q06X0tmQSfC1RXDrWxCbCgvvtlbFrJ+v7QSUUsfVLwP9mjMG43aJ/Q277DL8QrjjQ7jhFXD7YN7t8L9TYetibSeglDqqfhnoyTERTB2ZzFuri2jpjVYAdhCBMVdZ8+uzfg8Nh+CV2fDCZbDzU6erU0oFoX4Z6GD1Sd9bVccXO3qxFYAdXG7rOqZ358PVT1snJP3hKvjTTCha6XR1Sqkg0m8D/dKxqcREeHgzWKddunJ7Ie9frTXslz5h9Yb5/UXw2i1wICjP41JK9bF+G+iRXjdXZKfx7vp9HG5odrqcnvNGwTn3WGedXvif8OXH8NuzYd7XtU+MUv1cvw10gJkT06mub+L9TSF4+n1kHFz4MHxnLZx3P2x511oRM/9O64QlpVS/068D/aysJAbFR/Lmyj7owNhbohPh4h9YwX7OPbBpEfy/PHjzW1b7XqVUv9GvA93lEmZMSGfptlJKq0P8zEx/stWqt7UB2Ib51rVO37oLKnY6XZ1Sqg/060AHmDUxneYWw6I1QdAKwA4xA60GYPetgcl3wtrX4TdnwsJ7tWWvUmGu3wf6qNRYxg2OC65WAHaITYMrnoT7VlurY9b8xWon8NcHoCrMflalFKCBDlitANYWVrH9QLXTpdgvbjBc+XNruePEf4GVf7QagL3zEBzc63R1SikbaaAD0ycMxiXwZl9cns4p8RnWiUn3roQzboT8F+BXZ8C7j+hFNpQKExrowMDYSM4bmcKCVcXB2wrALgOGwvRfwz0rYPz18M/nrGBf/D2oPuB0dUqpU6CBHjArN52iysMs31nudCl9IyETZjwDdy+HcTPhi99awf7+f0FNkLdDUEp1SwM94NJxqUT73OF3cPR4kkbAzN/BXcvh9Gvgs1/DL3Osy+LV9pMPN6XChAZ6QLTPw+XZaby9bi91jSHUCsAuyafBrOfgrmUw+nL49Gn45Xj46Am93qlSIUIDvYNZuRkcqmviw039eC45ZTR89QX49udw2jRY+nMr2Jf8FA5XOl2dUuoYNNA7OHtEEqlxEeG92qWnBp4Os1+Cb34Gwy+Avz8JvxoPf/8Z1B10ujqlVDc00DtwB1oBfLylhPKaBqfLCQ5p2TDnz/Bvn8Cw82DJj61gX/o/UB9kl/BTqp/TQO9iZm46TS2Gv64Nk1YAdhk0Hm58Be78GDImw0c/sqZiPn0a6sPwhCylQpAGehenD4pjTFps8F5v1GmDc+HmuXDHR5A+ET54zFru+Nmvre6OzY1OV6hUv+VxuoBgNGtiOj95ZzMFJdUMT4lxupzglHEm3PIG7PknLPkJvP996yZu6+SlxCxIyILE4e1fJ2SCL9rpypUKWxro3ZgxIZ0n393MglVFPHDpaKfLCW5DJsOtC2DvGti3Dsp3WCP1ih1QtALqqjpvHzvICvmELEjM7PB1FkQlOPIjKBUuNNC7kRoXybmnJfPm6iLuv2QUIuJ0ScFv0BnWravacivcywO3ikDgb/8Aqvd13jYq4chRfevXMamg/x2UOiYN9KO4dkI6D76+hhW7KsjLTHS6nNAVnWjd0s888rWGGuviGx1H9eU7oHC5dYEO09K+rTe6fSTfFvaBwI/LALf+r6yU/is4isuz03h0wXrmryrSQO8tPj+kjrNuXTU3Whfk6DiqL98BZdth2/vQ3OEKUy4PDBjWHvCDJkBGHiSNBJce91f9hwb6UfgjPFw2LpW31+7lB9eMJcLjdrqk/sXttfrMJI048rWWFji0t3PQt369e5nVQRIgIt5aiZORBxmTID0P/El9+3Mo1Yc00I9h5sQMFqwuZsnmA1yePcjpclQrlwvi061b5nmdX2tpgbJtUJhvTd0U5cMnv2ifvknIsgI+PRDyadngiej7n0GpXqCBfgznjkgiJTaC+SuLNNBDhctl9aNJGQ25N1vPNdRA8er2gN/5Kax73XrN7YO08Va4Z+RZtwHD9ACsCkka6MfgcbuYccZgXvp8JxU1DST4fU6XpE6Gzw+Z51q3VlVFVrgXLofCFbDiD7Dsd9Zr0cnt4Z6eZ03bRMY7UrpSJ0ID/TiuzU3n+U938Pa6vdxy1jCny1F2aZ2yGTvDetzcCAc2BqZq8q2w3/peYGOxRvzpee1Bn3K6rqxRQUf/jzyOcYPjGJUaw5urijTQw5nb276WftLXrecOV1onRxWtsEbyW96B1X+2XvP6rTYIGWe2H3CN02k55SwN9OMQEWbmZvDf721mV1kNw5L8Tpek+krUAKsn/GnTrMfGWCtpila0H3T9/LfQEuhfE5feeZom6TQ9IUr1KQ30Hrg2dzA/W7yZN1cV8Z2LRzldjnKKSPtSyvGzreca66yWB60HXAuXw8a32r/HG231sGk9ESohs/3EqAFDrb8MlLKJBnoPDIqP4uzhSby5qoj7po3UVgCqnTcShkyybq2qD8DetZ3Pfi3/Er78EJrq2rcTN8RndD7zteN9hDaGUydGA72HZuam89C8tazcXcmZw7SJlDqGmIEw8uIjn29pger97SHf8X7jW3C4y0W5/SndB31ilvWaDixUFz0KdBG5HPgV4AaeN8Y8eZTtrgPmAZOMMfm2VRkEWlsBLFhVpIGuTo7LZR04jRsEw8458vW6qiODvnwH7PoHrJ0LmPZtfTGBqZzMIwM/foiuwOmnjvtfXUTcwDPAJUAhsFxEFhpjNnbZLha4D1jWG4U6LTbSy6Xj0li0tpjvXz0Wn0d7hCibRcbD4AnWraum+i69bQL3pdu6720TP6TzXP2AoZAwzDppKjpJR/dhqicf45OB7caYAgAReRWYAWzsst2PgP8GHrK1wiAyKzedRWuK+XjLAS4dl+Z0Oao/8URA8kjr1lWn3jZdAr94FRyu6Ly9198e8m1BP9QK+wFDrTbGGvghqSeBng7s6fC4EJjScQMRmQgMMca8LSJHDXQRuRO4E2Do0KEnXq3Dzh+ZTHKMjzdXFWmgq+BxrN42AHUHoWqPNcKv2GXdV+6ybnu+OPIiJL7YDiHfIehbw1/Pmg1apzzRJiIu4CngtuNta4x5DngOIC8vzxxn86Djcbu45ozBvPzFbqpqG4mP1iVnKgRExkHkUdoUg3UCVeXuDkG/uz38dyyFhi4XAY+M7xD0w7qM8odCRGzv/0yqWz0J9CJgSIfHGYHnWsUC2cDHgeV8acBCEZkebgdGAWblZvDiZzt5e91ebpoSen9lKHWEqAHWbdD4I18zxpqy6Rr0lbuh7Ev48iNorO2yv8Qj5+2TRkBqtrUCSPWangT6cmCkiGRhBfkNwE2tLxpjqoDk1sci8jHw3XAMc4Ds9DhGpPhZsKpIA12FP5H2q04Nzj3ydWOgtswK/IpdnUf6JZth2986r733p1jBnjoO0nKs++TR4NHGd3Y4bqAbY5pE5G5gMdayxReMMRtE5HEg3xizsLeLDCYiwqyJGfx88Rb2lNcyJFGvYq/6MRHwJ1u37i4zaIx1olXpVti/Hvatt+7/+fv2lTkujxXqadmdw15H8ydMjHFmKjsvL8/k54fmIL6wopbz/nsJD14yinumdbPqQCl1bM1N1tmz+9bB/g1WyO/fAAc7zObqaL5bIrLCGJPX3Wt69sFJyEiIZkpWIr//pICU2AiuzxuC26XLvJTqMben/UIkOV9tf762vEPAB0b0Rx3NjwsEfjbEpjrzcwQZHaGfpIKSah5+Yy3Ld1aQkx7PY9PH6RmkSvWGHo/mOwR8WnbYjuaPNULXQD8FxhgWrinmJ+9sYv/BemblpvPIFWMYGBfpdGlKhb/uRvMHNh05mk8d12FEH5ibD+ETpzTQe1lNfRPPLNnO85/swOsW7p02ktvPzdL2AEr1tZ6M5qOTO4zmA+vzU8ZYnTNDgAZ6H9lZWsMTb2/kg00HGJ7s5/vXjOWi0XqkXinH1ZYHwn1je8gf2ARNh63XxW1dkKQ14FvDPj4j6EbzGuh9bMmWA/xo0UYKSmuYNmYg3796LJnJeqUjpYJKS7PV86Y14FtH9JW72reJiO8Q8oGgH3i6o73qNdAd0NDUwouf7eDXH26jsdnw9fOzuPui0/BH6MIipYJa3UFr9N4p6DdAw6H2bRKyjpy2Sciy+ur0Mg10Bx04WMeT721m/soiUuMi+M8rT2f6GYP1qkdKhRJjrDNgO47k92+Asu209an3+q3Re6egH2t1r7SRBnoQWLGrgscWbmBdURV5wxJ4bPo4stO1a51SIa2h1mpx0Cno13duWRyXceS0TdJpJ30REg30INHSYnh9xR5+9t4WymsbuHHyUL576WgS/eG3VlapfssYOLSvPdxbw750K7Q0Wdtc9hM4+66T2r0GepCpOtzIrz7Yxkuf78Tvc/PgpaO5ecpQPG5d5qhU2GqqD/S02QDpeZB82kntRgM9SG3bf4jHFm3gs+1ljE6N5QfTx3LOiOTjf6NSqt86VqDrkNBBI1Nj+fPXp/DsLROpaWjipt8v466XV1JUedjp0pRSIUgD3WEiwuXZg/jggQu4/+JRfLBpP9N+8TG//nAbdY3NTpenlAohGuhBItLr5r6LR/LhgxcwbUwqT72/lYuf+jvvrd+HU9NiSqnQooEeZPXpZzIAAAtxSURBVDISonnm5om88o0p+H0evvnnFfzL//2TbfsPHf+blVL9mgZ6kDpnRDJv33seP5w+jrWFlVz+q094fNFGqg43Ol2aUipIaaAHMY/bxdfOyWTJdy9kzqQhvPiPHXzlfz7mteW7aWnRaRilVGca6CEgKSaCn8zMYdHd55GZ7OfhN9Zx7W8/Y+XuiuN/s1Kq39BADyHZ6fHM++bZ/HLOBPZV1THrt//ggbmrKSip1gOnSim9pmioERGuzU3n4rGpgYtqFLQ1/pqSlcSU4YlMyUpiRIpfG4Ap1c/omaIhrrCiliVbSlhWUMYXBeWUVluX30qOiWDK8ETOykpkyvAkRg6M0YBXKgzoqf/9hDGGgtIalhWUs2xHGcsKytl3sA6ARL+PyZmJbSP4MWmxuFwa8EqFmmMFuk65hBERYURKDCNSYrhpylCMMewur2VZQTlfBAL+vQ37AIiP8jIpM5GzAgE/dnAcbg14pUKaBnoYExGGJfkZluRn9qQhgDVF0zaC31HOB5v2AxAb4SEvM4Epw5OYkpVIdno8Xu3+qFRI0UDvZzISosk4M5rrzswAYF9VHct2WPPvy3aUsWRLCQDRPjdnDkvgrOFJnDU8kZz0Afg8GvBKBTOdQ1edHDhUxz93lLeN4rfurwYg0uvizGEJ1kqarETOGDKASK/b4WqV6n/0oKg6aWXV9VbA7yjni4Iytuw/hDHg87jIHTKAKcOTOCsrkYnDEjTgleoDGujKNpW1DW0Bv2xHGRuLD9JiwOsWBsZGMiDaa92ifMRHexkQ1d1jHwOivcRHefVDQKkTpKtclG0GRPu4dFwal45LA+BgXSP5O8tZvrOC/QfrqKptpPJwI5urDlJ1uJHK2kaajtF3JtLrYkBUe8C3hr/1wRC4j/IGPgx8bR8YUV63rqtXqgsNdHVK4iK9fGVMKl8Zk9rt68YYahqaqaxtoLK2sS3kKw93fNwQeK6RnaW1VB6upKK2kYamlqO+r8/t6vQXQHwg7BOivQxJjCYr2U9Wsp/B8VG63l71GxroqleJCDERHmIiPGQknNj3Hm5obgt+K/zbg7/T49pGiioPs7G4irKaBuo7fBD4PC4yk1oDPoas5OjAvZ/kGJ+O8lVY0UBXQSvK5ybKF8Wg+Kgef48xhgOH6ikoqWFnWQ07SmsoKKlh+4FqPtp8gMbm9umfmAhP20i+4y0z2U98lLc3fiSlepUGugorIkJqXCSpcZGcPSKp02tNzS0UV9ZRUFrNztJA2JfWsHJ3BYvWFtNxfUCS39cp4Icn+8lK8ZOZ5NcDuSpoaaCrfsPjdjE0KZqhSdEwuvNrdY3N7CmvpaC0plPY/31rCa+vKOy07eD4yLZwz0r2MzzFms7JSIjSs2uVozTQlcK6SPfI1FhGpsYe8Vp1fRM7AwHfMewXrSnmYF1T23ZulzA0cEB2SEIUkV43Po+LCI8Ln8eFz+3C57Gea33c9lrb60d/zaMfFuo4NNCVOo6YCA/Z6fFkp8d3et4YQ0VtIztKq9lRWhu4r2FHaS3Ld5ZT39RyzJU6J8oldPpgaA38iKN8IPg8Lvw+D8mxPpJjIkiOiSAlNnAfE0FclEcPCocZDXSlTpKIkOj3kehP5Mxhid1uY4yhsdnQ0GyFe9utubkt8K3HLdQ3tnTarr6b7+m0fZfvb/26ur6p09dlNQ00d3MugM/tIjnG1xby7YHvIyU2kuQYH8mx1nOxERr+oUADXaleJCL4PGI1NotwpoaWFkNFbQOl1Q2UVtdTcqjeum/7uoHiqjrWFlVRVl1Pd+eB+TwuUmIirIDv9kMgou3DIUbD3zE9CnQRuRz4FeAGnjfGPNnl9W8CdwHNQDVwpzFmo821KqVOgsslJMVEkBQTwWiOPEbQUXNb+NdTeqiBkuo6Sg+1fxCUVNdTWHGY1XuqKK/pPvwjPK4jAj/R7yUu0ktclJfYSE/b13GRHmIjvcRFeYjw6OqhU3XcQBcRN/AMcAlQCCwXkYVdAvsVY8yzge2nA08Bl/dCvUqpXuR2SVsQk3bsbZtbDOU1gfDvOPIPjPpLq+sprKhl9Z4KKmobu5326SjC4+o28Lt9LvAh0PFDQttB9GyEPhnYbowpABCRV4EZQFugG2MOdtjeD+gl6JUKc26XkBKYYz8eYwy1Dc0crGvkUF0TBw83crCukYOHmzhU18jBjs8Fvq463EhheW3b44bmYx9g9rjkiFF/XKT1l0Fs4IMhIdpLgt9HQrR1S/T7SPB7w+avg54Eejqwp8PjQmBK141E5C7gAcAHfKW7HYnIncCdAEOHDj3RWpVSIUpE8Ed48Ed4GBR//O27U9fYfNQPgaN9SBw4WN32em1D81H37fe5SfAHAj66/b71A6DT834vCdG+oDznwLaDosaYZ4BnROQm4FHga91s8xzwHFjtc+16b6VU+Iv0uon0uhl47MMAR9XY3EJlbSMVtQ2U1zRQUdNARZfH5bXWfUFpNRU1jVTXNx11f7GRniODP9p3xAdAYuADYEC0r9ev29uTQC8ChnR4nBF47mheBX53KkUppZTdvG5Xj6eIWtU3NVNZ22gFfm0DFTWNbaHf+lx5TQMl1fVs3V9NeU0Dhxu7/0tAxOpOmuj3cf8lo5h+xmC7frQ2PQn05cBIEcnCCvIbgJs6FyojjTHbAg+vArahlFIhLsLjJjXOTWpcZI+/p66xucOov/sPgITo3mn+dtxAN8Y0icjdwGKsZYsvGGM2iMjjQL4xZiFwt4hcDDQCFXQz3aKUUv1BpNfNoPgT6xJqlx7NoRtj3gHe6fLcf3X4+j6b61JKKXWCgu8wrVJKqZOiga6UUmFCA10ppcKEBrpSSoUJDXSllAoTGuhKKRUmNNCVUipMiDHOtFQRkRJglyNvbp9koNTpIoKI/j7a6e+iM/19dHYqv49hxpiU7l5wLNDDgYjkG2PynK4jWOjvo53+LjrT30dnvfX70CkXpZQKExroSikVJjTQT81zThcQZPT30U5/F53p76OzXvl96By6UkqFCR2hK6VUmNBAV0qpMKGBfhJEZIiILBGRjSKyQUT6fT94EXGLyCoR+avTtThNRAaIyDwR2Swim0TkbKdrcpKI3B/4d7JeRP4iIj2//E+IE5EXROSAiKzv8FyiiLwvItsC9wl2vZ8G+slpAh40xowFzgLuEpGxDtfktPuATU4XESR+BbxnjBkDnEE//r2ISDpwL5BnjMnGuurZDc5W1af+AFze5blHgA+NMSOBDwOPbaGBfhKMMXuNMSsDXx/C+geb7mxVzhGRDKxryT7vdC1OE5F4YCrwfwDGmAZjTKWzVTnOA0SJiAeIBoodrqfPGGOWAuVdnp4BvBT4+iXgWrveTwP9FIlIJpALLHO2Ekf9Evh3oMXpQoJAFlACvBiYgnpeRPxOF+UUY0wR8D/AbmAvUGWM+ZuzVTku1RizN/D1PiDVrh1roJ8CEYkB3gC+Y4w56HQ9ThCRq4EDxpgVTtcSJDzAROB3xphcoAYb/6QONYH54RlYH3SDAb+I3OJsVcHDWOvGbVs7roF+kkTEixXmLxtj5jtdj4POBaaLyE7gVeArIvJnZ0tyVCFQaIxp/YttHlbA91cXAzuMMSXGmEZgPnCOwzU5bb+IDAII3B+wa8ca6CdBRARrjnSTMeYpp+txkjHmP4wxGcaYTKyDXR8ZY/rtCMwYsw/YIyKjA09NAzY6WJLTdgNniUh04N/NNPrxQeKAhcDXAl9/DXjLrh1roJ+cc4F/wRqNrg7crnS6KBU07gFeFpG1wATgJw7X45jAXyrzgJXAOqzM6TdtAETkL8DnwGgRKRSRrwNPApeIyDasv2CetO399NR/pZQKDzpCV0qpMKGBrpRSYUIDXSmlwoQGulJKhQkNdKWUChMa6EopFSY00JVSKkz8f0useVj6zAB4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = nn.predict(X_val)\n",
    "\n",
    "accuracy = accuracy_score(y_pred, y_val)\n",
    "print(\"正答率:{}\".format(accuracy))\n",
    "\n",
    "x = np.arange(1, len(nn.list_train_loss)+1)\n",
    "plt.plot(x, nn.list_train_loss, label=\"loss\")\n",
    "plt.plot(x, nn.list_test_loss, label=\"val_loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題8】（アドバンス課題）有名な画像認識モデルの調査\n",
    "CNNの代表的な構造としてははAlexNet(2012)、VGG16(2014)などがあります。こういったものはフレームワークで既に用意されていることも多いです。\n",
    "\n",
    "どういったものがあるか簡単に調べてまとめてください。名前だけでも見ておくと良いでしょう。\n",
    "\n",
    "《参考》\n",
    "[Applications - Keras Documentation](https://keras.io/ja/applications/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 【AlexNet】\n",
    "問題7のLeNet再現モデルに加えて、DropoutやLRN(Local Response Normalization)を用いたモデル\n",
    "\n",
    "##### 【VGG16】\n",
    "[ImageNet](https://kotobank.jp/word/ImageNet-2119310)で事前学習した重みを利用可能なモデル。畳み込み13層、全結合層3層で計16層あるネットワーク。簡単な画像認識を試すなら良さそうなモデル。kerasライブラリのデフォルトのインプットサイズは224×224。\n",
    "\n",
    "※ImageNetのデータセット自体は1枚の画像に対して１つだけのラベルを割り当てるようなアノテーションをしており、正しく画像認識出来ない場合もあるので注意する。[(参考)](https://qiita.com/omiita/items/e1e377f30f624ad705b2)\n",
    "\n",
    "##### 【VGG19】\n",
    "[ImageNet](https://kotobank.jp/word/ImageNet-2119310)で事前学習した重みを利用可能なモデル。畳み込み16層、全結合層3層で計16層あるネットワーク。VGG16と同様、オブジェクトの画像認識において高い性能がある。kerasライブラリのデフォルトのインプットサイズは224×224。\n",
    "\n",
    "\"《参考》\"にあるモデルは全てImageNetのデータセットで事前学習したモデルになっている。\n",
    "\n",
    "#### 【EfficientNet】[(論文)](https://arxiv.org/pdf/1905.11946.pdf)\n",
    "2019年5月にGoogle Brainから発表されたモデル。MobileNetとResNetのスケールアップとNAS(Neural Architecture Search)[(参考記事)](https://qiita.com/cvusk/items/536862d57107b9c190e2)によって作られた。\n",
    "\n",
    "年々、新しいモデルが論文とともにSoTA(State of The Art)として表れている。気になる分野について新しい論文が出ているかはアンテナを張っておきたい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題9】出力サイズとパラメータ数の計算\n",
    "CNNモデルを構築する際には、全結合層に入力する段階で特徴量がいくつになっているかを事前に計算する必要があります。\n",
    "\n",
    "また、巨大なモデルを扱うようになると、メモリや計算速度の関係でパラメータ数の計算は必須になってきます。フレームワークでは各層のパラメータ数を表示させることが可能ですが、意味を理解していなくては適切な調整が行えません。\n",
    "\n",
    "以下の3つの畳み込み層の出力サイズとパラメータ数を計算してください。パラメータ数についてはバイアス項も考えてください。\n",
    "\n",
    "1.\n",
    "\n",
    "- 入力サイズ : 144×144, 3チャンネル\n",
    "- フィルタサイズ : 3×3, 6チャンネル\n",
    "- ストライド : 1\n",
    "- パディング : なし\n",
    "\n",
    "2.\n",
    "\n",
    "- 入力サイズ : 60×60, 24チャンネル\n",
    "- フィルタサイズ : 3×3, 48チャンネル\n",
    "- ストライド　: 1\n",
    "- パディング : なし\n",
    "\n",
    "3.\n",
    "\n",
    "- 入力サイズ : 20×20, 10チャンネル\n",
    "- フィルタサイズ: 3×3, 20チャンネル\n",
    "- ストライド : 2\n",
    "- パディング : なし\n",
    "\n",
    "＊最後の例は丁度良く畳み込みをすることができない場合です。フレームワークでは余ったピクセルを見ないという処理が行われることがあるので、その場合を考えて計算してください。端が欠けてしまうので、こういった設定は好ましくないという例です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 回答\n",
    "\n",
    "1.\n",
    "\n",
    "- 出力サイズ：142×142, 6チャンネル\n",
    "- パラメータ数：3×3×3×6 + 6 = 168\n",
    "\n",
    "2.\n",
    "\n",
    "- 出力サイズ：58×58, 48チャンネル\n",
    "- パラメータ数：24×3×3×48 + 48 = 10416\n",
    "\n",
    "3.\n",
    "\n",
    "- 出力サイズ：9×9, 20チャンネル\n",
    "- パラメータ数：10×3×3×20 + 20 = 1820"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題10】（アドバンス課題）フィルタサイズに関する調査\n",
    "畳み込み層にはフィルタサイズというハイパーパラメータがありますが、2次元畳み込み層において現在では3×3と1×1の使用が大半です。以下のそれぞれを調べたり、自分なりに考えて説明してください。\n",
    "\n",
    "- 7×7などの大きめのものではなく、3×3のフィルタが一般的に使われる理由\n",
    "- 高さや幅方向を持たない1×1のフィルタの効果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 回答\n",
    "- [参考記事1](https://towardsdatascience.com/deciding-optimal-filter-size-for-cnns-d6f7b56f9363)\n",
    "- [参考記事2](https://medium.com/lsc-psd/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%8B%E3%82%A2%E3%81%AA%E3%82%89%E7%AD%94%E3%81%88%E3%82%89%E3%82%8C%E3%81%A6%E5%BD%93%E7%84%B6%E3%81%AE4%E3%81%A4%E3%81%AE%E5%95%8F%E9%A1%8C-%E7%95%B3%E3%81%BF%E8%BE%BC%E3%81%BF%E5%B1%A4%E7%B7%A8-659809195d2)\n",
    "\n",
    "#### 7×7などの大きめのものではなく、3×3のフィルタが一般的に使われる理由\n",
    "畳み込み層は、画像からの特徴抽出を目的とすることを念頭に置いておく。入力する画像次第ではあるが、大きいフィルタだとストライドを1に設定したとしても、きめ細やかに特徴を抽出できない場合が想定されると考える。\n",
    "\n",
    "#### 高さや幅方向を持たない1×1のフィルタの効果\n",
    "きめ細やかに特徴抽出を行うが、隣接する情報がない。そのため、得られた特徴は限定的で汎用性がないと思われる。一方、計算量(パラメータ数)が少なくなるため、処理時間の短縮やメモリ節約に貢献する。\n",
    "\n",
    "## 記事を参考に書いたものですが、理解に間違いがあればご指摘をお願いいたします。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
