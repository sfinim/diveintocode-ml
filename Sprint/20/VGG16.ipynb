{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture tuning & score optimization\n",
    "\n",
    "\n",
    "Some ideas and code taken from ealier [kernel](https://www.kaggle.com/wrosinski/clean-workflow-in-keras) and last prepared notebook.\n",
    "\n",
    "Having dealt with data processing & engineering of channel features, next step of modeling is preparation and tuning of model architecture. Earlier notebooks provided a way to create images with three channels, which will facilitate usage of pretrained models.\n",
    "\n",
    "For segmentation tasks, a pretrained model can be used as encoder part of the final architecture. \n",
    "In order to use pretrained models, we will have to extract features from a few intermediate layers, which will then serve as a basis for layers coming afterwards and for skip connections between encoder and decoder part.\n",
    "\n",
    "ResNet50 is a good starting point, because it consists of 4 blocks, where each one of them can serve as feature extractor with first layer serving as the 5th extractor to achieve consistency with standard UNet architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:39:39.259864Z",
     "start_time": "2020-03-25T14:39:39.039884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.callbacks import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import *\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.backend import clear_session\n",
    "from keras import backend as K\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:39:43.879310Z",
     "start_time": "2020-03-25T14:39:43.876304Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "# plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:39:44.446808Z",
     "start_time": "2020-03-25T14:39:44.431975Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_coverage(df, masks):\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    def cov_to_class(val):\n",
    "        for i in range(0, 11):\n",
    "            if val * 10 <= i:\n",
    "                return i\n",
    "\n",
    "    # Output percentage of area covered by class\n",
    "    df['coverage'] = np.mean(masks, axis=(1, 2))\n",
    "    # Coverage must be split into bins, otherwise stratified split will not be possible,\n",
    "    # because each coverage will occur only once.\n",
    "    df['coverage_class'] = df.coverage.map(\n",
    "        cov_to_class)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_depth_abs_channels(image_tensor):\n",
    "    image_tensor = image_tensor.astype(np.float32)\n",
    "    h, w, c = image_tensor.shape\n",
    "    for row, const in enumerate(np.linspace(0, 1, h)):\n",
    "        image_tensor[row, :, 1] = const\n",
    "    image_tensor[:, :, 2] = (\n",
    "        image_tensor[:, :, 0] * image_tensor[:, :, 1])\n",
    "\n",
    "    x_dx = np.diff(image_tensor[:, :, 0], axis=0)\n",
    "    x_dy = np.diff(image_tensor[:, :, 0], axis=1)\n",
    "    x_dx = cv2.copyMakeBorder(x_dx, 1, 0, 0, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    x_dy = cv2.copyMakeBorder(x_dy, 0, 0, 1, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    image_tensor[:, :, 1] = np.abs(x_dx + x_dy)\n",
    "\n",
    "    return image_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading & depth merge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:39:47.676622Z",
     "start_time": "2020-03-25T14:39:47.485724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "           id                                           rle_mask\n",
      "0  2c45b152f1  99 3 197 6 295 9 395 10 494 12 594 13 694 14 7...\n",
      "1  3cb59a4fdc                                             1 5656\n",
      "2  e185ab5dc1  4647 2 4748 10 4849 18 4950 25 5051 29 5152 34...\n",
      "3  c78c89577c                                              101 1\n",
      "4  6306dd3a8e  1 30 102 29 203 29 304 28 405 27 506 27 607 26...\n",
      "\n",
      "test:\n",
      "           id rle_mask\n",
      "0  3e06571ef3      1 1\n",
      "1  a51b08d882      1 1\n",
      "2  c32590b06f      1 1\n",
      "3  15f7a047c7      1 1\n",
      "4  e8827bc832      1 1\n",
      "\n",
      "           id                                           rle_mask    z\n",
      "0  2c45b152f1  99 3 197 6 295 9 395 10 494 12 594 13 694 14 7...  312\n",
      "1  3cb59a4fdc                                             1 5656  603\n",
      "2  e185ab5dc1  4647 2 4748 10 4849 18 4950 25 5051 29 5152 34...  687\n",
      "3  c78c89577c                                              101 1  236\n",
      "4  6306dd3a8e  1 30 102 29 203 29 304 28 405 27 506 27 607 26...  805\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('input/train.csv')\n",
    "test = pd.read_csv('input/sample_submission.csv')\n",
    "depth = pd.read_csv('input/depths.csv')\n",
    "\n",
    "train_src = 'input/train/'\n",
    "\n",
    "print('train:\\n{}'.format(train.head()))\n",
    "print('\\ntest:\\n{}'.format(test.head()))\n",
    "\n",
    "\n",
    "train = train.merge(depth, how='left', on='id')\n",
    "test = test.merge(depth, how='left', on='id')\n",
    "\n",
    "print('\\n{}'.format(train.head()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load images and masks, examine random sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:39:58.581787Z",
     "start_time": "2020-03-25T14:39:50.781893Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 101, 101) (4000, 101, 101)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.asarray(\n",
    "    [cv2.imread('input/train/images/{}.png'.format(x), 0) for x in train.id.tolist()], \n",
    "    dtype=np.uint8) / 255.\n",
    "y_train = np.asarray(\n",
    "    [cv2.imread('input/train/masks/{}.png'.format(x), 0) for x in train.id.tolist()],\n",
    "    dtype=np.uint8) / 255.\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:39:59.083122Z",
     "start_time": "2020-03-25T14:39:58.584544Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1bd82113c8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_index = np.random.randint(0, X_train.shape[0])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "ax[0].imshow(X_train[random_index], cmap='gray')\n",
    "ax[1].imshow(y_train[random_index], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute salt coverage (this will serve as a basis for stratified split):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:40:08.034054Z",
     "start_time": "2020-03-25T14:40:07.987000Z"
    }
   },
   "outputs": [],
   "source": [
    "train = compute_coverage(train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:40:35.924796Z",
     "start_time": "2020-03-25T14:40:09.595933Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3200, 224, 224, 3) (3200, 224, 224, 1)\n",
      "(800, 224, 224, 3) (800, 224, 224, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, random_state=1337)\n",
    "\n",
    "# Add channel features\n",
    "X_train_ch = np.repeat(np.expand_dims(X_train, axis=-1), 3, -1)\n",
    "X_train_ch = np.asarray(list(map(lambda x: create_depth_abs_channels(x), X_train_ch)))\n",
    "\n",
    "# Resize to 224x224, default ResNet50 image size\n",
    "X_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), X_train_ch)))\n",
    "y_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), y_train)))\n",
    "\n",
    "\n",
    "for train_index, valid_index in kfold.split(train.id.values, train.coverage_class.values):\n",
    "    \n",
    "    X_tr, X_val = X_resized[train_index], X_resized[valid_index]\n",
    "    y_tr, y_val = y_resized[train_index], y_resized[valid_index]\n",
    "    \n",
    "    break\n",
    "    \n",
    "\n",
    "y_tr = np.expand_dims(y_tr, axis=-1)\n",
    "y_val = np.expand_dims(y_val, axis=-1)\n",
    "\n",
    "print(X_tr.shape, y_tr.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "\n",
    "\n",
    "del X_train_ch, y_resized\n",
    "del X_resized\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss functions & metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:40:35.952868Z",
     "start_time": "2020-03-25T14:40:35.927679Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "\n",
    "# Dice & combined\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
    "    return score\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "\n",
    "def bce_logdice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Lovash loss: https://github.com/bermanmaxim/LovaszSoftmax\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    gts = tf.reduce_sum(gt_sorted)\n",
    "    intersection = gts - tf.cumsum(gt_sorted)\n",
    "    union = gts + tf.cumsum(1. - gt_sorted)\n",
    "    jaccard = 1. - intersection / union\n",
    "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        def treat_image(log_lab):\n",
    "            log, lab = log_lab\n",
    "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
    "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
    "            return lovasz_hinge_flat(log, lab)\n",
    "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
    "        loss = tf.reduce_mean(losses)\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_loss():\n",
    "        labelsf = tf.cast(labels, logits.dtype)\n",
    "        signs = 2. * labelsf - 1.\n",
    "        errors = 1. - logits * tf.stop_gradient(signs)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
    "        gt_sorted = tf.gather(labelsf, perm)\n",
    "        grad = lovasz_grad(gt_sorted)\n",
    "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
    "        return loss\n",
    "\n",
    "    # deal with the void prediction case (only void pixels)\n",
    "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
    "                   lambda: tf.reduce_sum(logits) * 0.,\n",
    "                   compute_loss,\n",
    "                   strict=True,\n",
    "                   name=\"loss\"\n",
    "                   )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = tf.reshape(scores, (-1,))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = tf.not_equal(labels, ignore)\n",
    "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
    "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
    "    return vscores, vlabels\n",
    "\n",
    "\n",
    "def lovasz_loss(y_true, y_pred):\n",
    "    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
    "    #logits = K.log(y_pred / (1. - y_pred))\n",
    "    logits = y_pred #Jiaxin\n",
    "    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
    "    return loss\n",
    "\n",
    "\n",
    "# IoU metric for observation during training\n",
    "# https://www.kaggle.com/cpmpml/fast-iou-metric-in-numpy-and-tensorflow\n",
    "def get_iou_vector(A, B):\n",
    "    # Numpy version    \n",
    "    batch_size = A.shape[0]\n",
    "    metric = 0.0\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch], B[batch]\n",
    "        true = np.sum(t)\n",
    "        pred = np.sum(p)\n",
    "        \n",
    "        # deal with empty mask first\n",
    "        if true == 0:\n",
    "            metric += (pred == 0)\n",
    "            continue\n",
    "        \n",
    "        # non empty mask case.  Union is never empty \n",
    "        # hence it is safe to divide by its number of pixels\n",
    "        intersection = np.sum(t * p)\n",
    "        union = true + pred - intersection\n",
    "        iou = intersection / union\n",
    "        \n",
    "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
    "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
    "        \n",
    "        metric += iou\n",
    "        \n",
    "    # teake the average over all images in batch\n",
    "    metric /= batch_size\n",
    "    return metric\n",
    "\n",
    "\n",
    "def my_iou_metric(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n",
    "\n",
    "\n",
    "# For Lovash loss\n",
    "def my_iou_metric_2(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder features - ResNet50:\n",
    "\n",
    "In ResNet50, each block finishes with a pooling layer, so we can extract features from intermediate layers just before the pooling. This way, when first layer is added as additional extractor, we will have features extracted from 5 layers.\n",
    "Default input size will be assumed, which is (224, 224, 3).\n",
    "Layers will be as follows:\n",
    "\n",
    "- 'activation_1', shape: (None, 112, 112, 64)\n",
    "- 'activation_10', shape: (None, 56, 56, 256)\n",
    "- 'activation_22', shape: (None, 28, 28, 512)\n",
    "- 'activation_40', shape: (None, 14, 14, 1024)\n",
    "- 'activation_49', shape: (None, 7, 7, 2048)\n",
    "\n",
    "One thing to keep in mind is that every time a model will be created in the same TF session in the notebook, layer names will change, so above layer names correspond to first creation of the model. In order to reset session, call `K.clear_session()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:102: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = (224, 224, 3)\n",
    "clear_session()\n",
    "base_model = VGG16(input_shape=input_size, include_top=False)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder blocks:\n",
    "\n",
    "Features from ResNet50 will serve as a basis for encoder part of the segmentation model, now a decoder part is needed.\n",
    "For this part, we will have to create our own blocks. Let's create a very basic block and a second one, which structure will have a more complicated structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:40:46.197121Z",
     "start_time": "2020-03-25T14:40:46.188335Z"
    }
   },
   "outputs": [],
   "source": [
    "# Basic decoder block with Conv, BN and PReLU activation.\n",
    "def decoder_block_simple(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3)):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation'.format(block_name))(x_dec)\n",
    "\n",
    "    return x_dec\n",
    "\n",
    "# Decoder block with bottleneck architecture, where middle conv layer\n",
    "# is half the size of first and last, in order to compress representation.\n",
    "# This type of architecture is supposed to retain most useful information.\n",
    "def decoder_block_bottleneck(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3),\n",
    "        dropout_frac=0.2):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv1'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn1'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation1'.format(block_name))(x_dec)\n",
    "    x_dec = Dropout(dropout_frac)(x_dec)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters // 2, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv2'.format(block_name))(x_dec)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Add()([x_dec, x_dec2])\n",
    "\n",
    "    return x_dec2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition:\n",
    "\n",
    "Combine encoder and decoder blocks to create final segmentation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
    "# as this is an argument that can be given a function, like decoder_block_simple.\n",
    "def unet_resnet(input_size, decoder_block,\n",
    "                weights='imagenet',\n",
    "                loss_func='binary_crossentropy',\n",
    "                metrics_list=[my_iou_metric],\n",
    "                use_lovash=False):\n",
    "\n",
    "    # Base model - encoder\n",
    "    base_model = VGG16(\n",
    "        input_shape=input_size, \n",
    "        include_top=False,\n",
    "        weights=weights)\n",
    "    \n",
    "    # Layers for feature extraction in the encoder part\n",
    "    encoder1 = base_model.get_layer('block1_conv2').output # activation_1\n",
    "    encoder2 = base_model.get_layer('block2_conv2').output # activation_10\n",
    "    encoder3 = base_model.get_layer('block3_conv3').output # activation_22\n",
    "    encoder4 = base_model.get_layer('block4_conv3').output # activation_40\n",
    "    encoder5 = base_model.get_layer('block5_conv3').output # activation_40\n",
    "\n",
    "    # Center block\n",
    "    center = decoder_block(\n",
    "        encoder5, 'center', num_filters=128)\n",
    "    concat5 = concatenate([center, encoder5], axis=-1)\n",
    "\n",
    "    # Decoder part.\n",
    "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
    "    # This creates skip connections.\n",
    "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
    "    decoder4 = decoder_block(\n",
    "        concat5, 'decoder4', num_filters=128)\n",
    "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
    "\n",
    "    decoder3 = decoder_block(\n",
    "        concat4, 'decoder3', num_filters=64)\n",
    "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
    "\n",
    "    decoder2 = decoder_block(\n",
    "        concat3, 'decoder2', num_filters=32)\n",
    "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
    "\n",
    "#     decoder1 = decoder_block(\n",
    "#         concat2, 'decoder1', num_filters=32)\n",
    "#     concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
    "\n",
    "    # Final upsampling and decoder block for segmentation.\n",
    "    output = UpSampling2D()(concat2)\n",
    "    output = decoder_block(\n",
    "        output, 'decoder_output', num_filters=32)\n",
    "    output = Conv2D(\n",
    "        1, (1, 1), activation=None, name='prediction')(output)\n",
    "    if not use_lovash:\n",
    "        output = Activation('sigmoid')(output)\n",
    "        \n",
    "    model = Model(base_model.input, output)\n",
    "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect created model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:55:00.601042Z",
     "start_time": "2020-03-25T14:54:53.772115Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_conv (Conv2D)            (None, 14, 14, 128)  589952      block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_bn (BatchNormalization)  (None, 14, 14, 128)  512         center_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_activation (PReLU)       (None, 14, 14, 128)  25088       center_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 14, 14, 640)  0           center_activation[0][0]          \n",
      "                                                                 block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv (Conv2D)          (None, 14, 14, 128)  737408      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn (BatchNormalization (None, 14, 14, 128)  512         decoder4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation (PReLU)     (None, 14, 14, 128)  25088       decoder4_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 28, 28, 128)  0           decoder4_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv (Conv2D)          (None, 28, 28, 64)   368704      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn (BatchNormalization (None, 28, 28, 64)   256         decoder3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation (PReLU)     (None, 28, 28, 64)   50176       decoder3_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 56, 56, 64)   0           decoder3_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv (Conv2D)          (None, 56, 56, 32)   92192       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn (BatchNormalization (None, 56, 56, 32)   128         decoder2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation (PReLU)     (None, 56, 56, 32)   100352      decoder2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 112, 112, 32) 0           decoder2_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 112, 112, 160 0           up_sampling2d_3[0][0]            \n",
      "                                                                 block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 224, 224, 160 0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv (Conv2D)    (None, 224, 224, 32) 46112       up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn (BatchNormali (None, 224, 224, 32) 128         decoder_output_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation (PReL (None, 224, 224, 32) 1605632     decoder_output_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          decoder_output_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 18,356,961\n",
      "Trainable params: 18,356,193\n",
      "Non-trainable params: 768\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = (224, 224, 3)\n",
    "\n",
    "\n",
    "clear_session()\n",
    "model = unet_resnet(\n",
    "    input_size, decoder_block_simple, weights='imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T17:37:03.773696Z",
     "start_time": "2020-03-25T14:58:43.483800Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_conv1 (Conv2D)           (None, 14, 14, 128)  589952      block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_bn1 (BatchNormalization) (None, 14, 14, 128)  512         center_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation1 (PReLU)      (None, 14, 14, 128)  25088       center_bn1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 14, 14, 128)  0           center_activation1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv2 (Conv2D)           (None, 14, 14, 64)   73792       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn2 (BatchNormalization) (None, 14, 14, 64)   256         center_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation2 (PReLU)      (None, 14, 14, 64)   12544       center_bn2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 14, 14, 64)   0           center_activation2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv3 (Conv2D)           (None, 14, 14, 128)  73856       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn3 (BatchNormalization) (None, 14, 14, 128)  512         center_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation3 (PReLU)      (None, 14, 14, 128)  25088       center_bn3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 14, 14, 128)  0           center_activation3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 14, 14, 128)  0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 14, 14, 640)  0           add_1[0][0]                      \n",
      "                                                                 block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv1 (Conv2D)         (None, 14, 14, 128)  737408      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn1 (BatchNormalizatio (None, 14, 14, 128)  512         decoder4_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation1 (PReLU)    (None, 14, 14, 128)  25088       decoder4_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 14, 14, 128)  0           decoder4_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv2 (Conv2D)         (None, 14, 14, 64)   73792       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn2 (BatchNormalizatio (None, 14, 14, 64)   256         decoder4_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation2 (PReLU)    (None, 14, 14, 64)   12544       decoder4_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 14, 14, 64)   0           decoder4_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv3 (Conv2D)         (None, 14, 14, 128)  73856       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn3 (BatchNormalizatio (None, 14, 14, 128)  512         decoder4_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation3 (PReLU)    (None, 14, 14, 128)  25088       decoder4_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 14, 14, 128)  0           decoder4_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 14, 14, 128)  0           dropout_4[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 28, 28, 128)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv1 (Conv2D)         (None, 28, 28, 64)   368704      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn1 (BatchNormalizatio (None, 28, 28, 64)   256         decoder3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation1 (PReLU)    (None, 28, 28, 64)   50176       decoder3_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 28, 28, 64)   0           decoder3_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv2 (Conv2D)         (None, 28, 28, 32)   18464       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn2 (BatchNormalizatio (None, 28, 28, 32)   128         decoder3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation2 (PReLU)    (None, 28, 28, 32)   25088       decoder3_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 28, 28, 32)   0           decoder3_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv3 (Conv2D)         (None, 28, 28, 64)   18496       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn3 (BatchNormalizatio (None, 28, 28, 64)   256         decoder3_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation3 (PReLU)    (None, 28, 28, 64)   50176       decoder3_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 28, 28, 64)   0           decoder3_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 28, 28, 64)   0           dropout_7[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 56, 56, 64)   0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv1 (Conv2D)         (None, 56, 56, 32)   92192       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn1 (BatchNormalizatio (None, 56, 56, 32)   128         decoder2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation1 (PReLU)    (None, 56, 56, 32)   100352      decoder2_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 56, 56, 32)   0           decoder2_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv2 (Conv2D)         (None, 56, 56, 16)   4624        dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn2 (BatchNormalizatio (None, 56, 56, 16)   64          decoder2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation2 (PReLU)    (None, 56, 56, 16)   50176       decoder2_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 56, 56, 16)   0           decoder2_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv3 (Conv2D)         (None, 56, 56, 32)   4640        dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn3 (BatchNormalizatio (None, 56, 56, 32)   128         decoder2_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation3 (PReLU)    (None, 56, 56, 32)   100352      decoder2_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 56, 56, 32)   0           decoder2_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 56, 56, 32)   0           dropout_10[0][0]                 \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 112, 112, 32) 0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 112, 112, 160 0           up_sampling2d_3[0][0]            \n",
      "                                                                 block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 224, 224, 160 0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 46112       up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 224, 224, 32) 0           dropout_13[0][0]                 \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 21,419,553\n",
      "Trainable params: 21,417,633\n",
      "Non-trainable params: 1,920\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 3200 samples, validate on 800 samples\n",
      "Epoch 1/25\n",
      "3200/3200 [==============================] - 43s 13ms/step - loss: 0.9391 - my_iou_metric: 0.1247 - val_loss: 2.1731 - val_my_iou_metric: 0.1528\n",
      "\n",
      "Epoch 00001: val_my_iou_metric improved from -inf to 0.15275, saving model to unet_resnet.h5\n",
      "Epoch 2/25\n",
      "3200/3200 [==============================] - 34s 11ms/step - loss: 0.7874 - my_iou_metric: 0.1857 - val_loss: 2.1979 - val_my_iou_metric: 0.1622\n",
      "\n",
      "Epoch 00002: val_my_iou_metric improved from 0.15275 to 0.16225, saving model to unet_resnet.h5\n",
      "Epoch 3/25\n",
      "3200/3200 [==============================] - 34s 11ms/step - loss: 0.6961 - my_iou_metric: 0.2552 - val_loss: 1.1658 - val_my_iou_metric: 0.2105\n",
      "\n",
      "Epoch 00003: val_my_iou_metric improved from 0.16225 to 0.21050, saving model to unet_resnet.h5\n",
      "Epoch 4/25\n",
      "3200/3200 [==============================] - 34s 11ms/step - loss: 0.6492 - my_iou_metric: 0.3083 - val_loss: 0.6291 - val_my_iou_metric: 0.4481\n",
      "\n",
      "Epoch 00004: val_my_iou_metric improved from 0.21050 to 0.44812, saving model to unet_resnet.h5\n",
      "Epoch 5/25\n",
      "3200/3200 [==============================] - 34s 11ms/step - loss: 0.5969 - my_iou_metric: 0.3711 - val_loss: 0.8000 - val_my_iou_metric: 0.2784\n",
      "\n",
      "Epoch 00005: val_my_iou_metric did not improve from 0.44812\n",
      "Epoch 6/25\n",
      "3200/3200 [==============================] - 34s 11ms/step - loss: 0.6082 - my_iou_metric: 0.3706 - val_loss: 0.5489 - val_my_iou_metric: 0.4199\n",
      "\n",
      "Epoch 00006: val_my_iou_metric did not improve from 0.44812\n",
      "Epoch 7/25\n",
      "3200/3200 [==============================] - 34s 11ms/step - loss: 0.5376 - my_iou_metric: 0.4270 - val_loss: 0.6183 - val_my_iou_metric: 0.3900\n",
      "\n",
      "Epoch 00007: val_my_iou_metric did not improve from 0.44812\n",
      "Epoch 8/25\n",
      "3200/3200 [==============================] - 34s 11ms/step - loss: 0.5277 - my_iou_metric: 0.4515 - val_loss: 0.4882 - val_my_iou_metric: 0.5339\n",
      "\n",
      "Epoch 00008: val_my_iou_metric improved from 0.44812 to 0.53387, saving model to unet_resnet.h5\n",
      "Epoch 9/25\n",
      "3200/3200 [==============================] - 34s 11ms/step - loss: 0.5067 - my_iou_metric: 0.4700 - val_loss: 0.4814 - val_my_iou_metric: 0.5769\n",
      "\n",
      "Epoch 00009: val_my_iou_metric improved from 0.53387 to 0.57688, saving model to unet_resnet.h5\n",
      "Epoch 10/25\n",
      "3200/3200 [==============================] - 34s 11ms/step - loss: 0.5033 - my_iou_metric: 0.4808 - val_loss: 0.4693 - val_my_iou_metric: 0.5591\n",
      "\n",
      "Epoch 00010: val_my_iou_metric did not improve from 0.57688\n",
      "Epoch 11/25\n",
      "3200/3200 [==============================] - 34s 11ms/step - loss: 0.4732 - my_iou_metric: 0.5055 - val_loss: 0.4651 - val_my_iou_metric: 0.5979\n",
      "\n",
      "Epoch 00011: val_my_iou_metric improved from 0.57688 to 0.59787, saving model to unet_resnet.h5\n",
      "Epoch 12/25\n",
      "3200/3200 [==============================] - 34s 11ms/step - loss: 0.4765 - my_iou_metric: 0.4906 - val_loss: 0.4597 - val_my_iou_metric: 0.5744\n",
      "\n",
      "Epoch 00012: val_my_iou_metric did not improve from 0.59787\n",
      "Epoch 13/25\n",
      "3200/3200 [==============================] - 34s 11ms/step - loss: 0.4529 - my_iou_metric: 0.5183 - val_loss: 0.4702 - val_my_iou_metric: 0.6358\n",
      "\n",
      "Epoch 00013: val_my_iou_metric improved from 0.59787 to 0.63575, saving model to unet_resnet.h5\n",
      "Epoch 14/25\n",
      "3200/3200 [==============================] - 34s 11ms/step - loss: 0.4517 - my_iou_metric: 0.5203 - val_loss: 0.4531 - val_my_iou_metric: 0.5751\n",
      "\n",
      "Epoch 00014: val_my_iou_metric did not improve from 0.63575\n",
      "Epoch 15/25\n",
      "3200/3200 [==============================] - 34s 11ms/step - loss: 0.4398 - my_iou_metric: 0.5286 - val_loss: 0.4336 - val_my_iou_metric: 0.6078\n",
      "\n",
      "Epoch 00015: val_my_iou_metric did not improve from 0.63575\n",
      "Epoch 16/25\n",
      "3200/3200 [==============================] - 34s 11ms/step - loss: 0.4378 - my_iou_metric: 0.5356 - val_loss: 0.4092 - val_my_iou_metric: 0.5519\n",
      "\n",
      "Epoch 00016: val_my_iou_metric did not improve from 0.63575\n",
      "Epoch 17/25\n",
      "3200/3200 [==============================] - 34s 11ms/step - loss: 0.4334 - my_iou_metric: 0.5345 - val_loss: 0.4375 - val_my_iou_metric: 0.6165\n",
      "\n",
      "Epoch 00017: val_my_iou_metric did not improve from 0.63575\n",
      "Epoch 18/25\n",
      "3200/3200 [==============================] - 34s 11ms/step - loss: 0.3972 - my_iou_metric: 0.5706 - val_loss: 0.3815 - val_my_iou_metric: 0.6098\n",
      "\n",
      "Epoch 00018: val_my_iou_metric did not improve from 0.63575\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 19/25\n",
      "3200/3200 [==============================] - 34s 11ms/step - loss: 0.3658 - my_iou_metric: 0.5872 - val_loss: 0.3755 - val_my_iou_metric: 0.6366\n",
      "\n",
      "Epoch 00019: val_my_iou_metric improved from 0.63575 to 0.63662, saving model to unet_resnet.h5\n",
      "Epoch 20/25\n",
      "3200/3200 [==============================] - 34s 11ms/step - loss: 0.3402 - my_iou_metric: 0.5901 - val_loss: 0.3681 - val_my_iou_metric: 0.6415\n",
      "\n",
      "Epoch 00020: val_my_iou_metric improved from 0.63662 to 0.64150, saving model to unet_resnet.h5\n",
      "Epoch 21/25\n",
      "3200/3200 [==============================] - 34s 11ms/step - loss: 0.3356 - my_iou_metric: 0.5995 - val_loss: 0.3797 - val_my_iou_metric: 0.6874\n",
      "\n",
      "Epoch 00021: val_my_iou_metric improved from 0.64150 to 0.68738, saving model to unet_resnet.h5\n",
      "Epoch 22/25\n",
      "3200/3200 [==============================] - 34s 11ms/step - loss: 0.3414 - my_iou_metric: 0.5927 - val_loss: 0.3643 - val_my_iou_metric: 0.6459\n",
      "\n",
      "Epoch 00022: val_my_iou_metric did not improve from 0.68738\n",
      "Epoch 23/25\n",
      "3200/3200 [==============================] - 34s 11ms/step - loss: 0.3351 - my_iou_metric: 0.5973 - val_loss: 0.3809 - val_my_iou_metric: 0.6162\n",
      "\n",
      "Epoch 00023: val_my_iou_metric did not improve from 0.68738\n",
      "Epoch 24/25\n",
      "3200/3200 [==============================] - 34s 11ms/step - loss: 0.3162 - my_iou_metric: 0.6068 - val_loss: 0.3880 - val_my_iou_metric: 0.6062\n",
      "\n",
      "Epoch 00024: val_my_iou_metric did not improve from 0.68738\n",
      "Epoch 25/25\n",
      "3200/3200 [==============================] - 34s 11ms/step - loss: 0.3094 - my_iou_metric: 0.6119 - val_loss: 0.3840 - val_my_iou_metric: 0.6339\n",
      "\n",
      "Epoch 00025: val_my_iou_metric did not improve from 0.68738\n"
     ]
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "# Build model:\n",
    "# Here, you can experiment with various losses.\n",
    "# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n",
    "# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n",
    "# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n",
    "# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n",
    "# This is controlled by use_lovash parameter.\n",
    "model_depth = unet_resnet(\n",
    "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
    "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
    "    use_lovash=False)\n",
    "print(model_depth.summary())\n",
    "\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'unet_resnet.h5' ,\n",
    "    monitor='val_my_iou_metric', \n",
    "    mode='max',\n",
    "    save_best_only=True, \n",
    "    save_weights_only=True, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_my_iou_metric',\n",
    "    mode='max',\n",
    "    factor=0.5, \n",
    "    patience=5, \n",
    "    min_lr=0.0001, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "epochs = 25  # 25\n",
    "batch_size = 16\n",
    "\n",
    "# エラー回避\n",
    "# y_tr = y_tr.astype('float32')\n",
    "# y_val = y_val.astype('float32')\n",
    "\n",
    "history = model_depth.fit(X_tr, y_tr,\n",
    "                    validation_data=[X_val, y_val], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[model_checkpoint,reduce_lr], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation set prediction and resizing to original size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = model_depth.predict(X_val, batch_size=16)\n",
    "\n",
    "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
    "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold optimization: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "    \n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:46<00:00,  1.34s/it]\n"
     ]
    }
   ],
   "source": [
    "# Threshold range, over which optimization is performed\n",
    "thresholds = np.arange(0.2, 0.9, 0.02)\n",
    "\n",
    "# For every threshold, set predictions to binary arrays, \n",
    "# where values above threshold are treated as 1 and the rest as 0.\n",
    "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
    "ious = np.array(\n",
    "    [iou_metric_batch(y_val_true,\n",
    "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best IoU: 0.6906 at threshold: 0.880\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>iou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.652725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.204939</td>\n",
       "      <td>0.030040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.582000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.633750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.657250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.676687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.690625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       threshold        iou\n",
       "count  35.000000  35.000000\n",
       "mean    0.540000   0.652725\n",
       "std     0.204939   0.030040\n",
       "min     0.200000   0.582000\n",
       "25%     0.370000   0.633750\n",
       "50%     0.540000   0.657250\n",
       "75%     0.710000   0.676687\n",
       "max     0.880000   0.690625"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
    "df_iou['iou'] = ious\n",
    "\n",
    "# Get index of best IoU\n",
    "best_index = df_iou['iou'].idxmax()\n",
    "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
    "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
    "\n",
    "# Describe IoU DF\n",
    "df_iou.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f93a50e7f28>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot IoU values over threshold range.\n",
    "df_iou.plot(x='threshold', y='iou')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions:\n",
    "\n",
    "- Pretrained models can be used for segmentation problems:\n",
    "    - Some of architectures can be easily adapted to the problem (ie ResNet)\n",
    "    - Other architectures may require more experimentation with selection of proper layers for feature extraction and padding (example of using [Xception](https://www.kaggle.com/meaninglesslives/getting-0-87-on-private-lb-using-kaggle-kernel). )\n",
    "    - You can experiment with selection of layers for feature extraction\n",
    "    - For some models, you can also try to experiment with number of encoder/decoder blocks\n",
    "- Threshold optimization is important in problems, where direct metric optimization during training is difficult.\n",
    "    - It it possible to use more involved optimization methods (from [scipy optimize](https://docs.scipy.org/doc/scipy/reference/optimize.html)), although this may not be optimal unless distribution of train and test set are very similar. Overoptimization of threshold or any other parameter on validation set may result in worse test set results.\n",
    "- Experiment with various losses - BCE, Dice, combined BCE with Dice, Lovash loss.\n",
    "    - Models trained with various losses may give different results, which may be advantageous when ensembling.\n",
    "\n",
    "\n",
    "### Possible experiments:\n",
    "\n",
    "- Change type of decoder block in created segmentation model\n",
    "- Create your own decoder blocks\n",
    "- Train with other losses\n",
    "- Train longer\n",
    "- Train with BCE/Dice, save the model, then load weights and finetune with Lovash loss\n",
    "- Try different ranges and intervals for threshold optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T08:26:39.786782Z",
     "start_time": "2019-09-25T08:26:39.781446Z"
    }
   },
   "outputs": [],
   "source": [
    "np.int32(0.7 > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iou_vector(A, B):\n",
    "    # Numpy version\n",
    "    \n",
    "    batch_size = A.shape[0]\n",
    "    metric = 0.0\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch], B[batch]\n",
    "        true = np.sum(t)\n",
    "        pred = np.sum(p)\n",
    "        \n",
    "        # deal with empty mask first\n",
    "        if true == 0:\n",
    "            metric += (pred == 0)\n",
    "            continue\n",
    "        \n",
    "        # non empty mask case.  Union is never empty \n",
    "        # hence it is safe to divide by its number of pixels\n",
    "        intersection = np.sum(t * p)\n",
    "        union = true + pred - intersection\n",
    "        iou = intersection / union\n",
    "        \n",
    "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
    "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
    "        \n",
    "        metric += iou\n",
    "        \n",
    "    # teake the average over all images in batch\n",
    "    metric /= batch_size\n",
    "    return metric"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
