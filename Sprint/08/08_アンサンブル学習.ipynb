{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## アンサンブル学習\n",
    "3種類のアンサンブル学習をスクラッチ実装していきます。そして、それぞれの効果を小さめのデータセットで確認します。\n",
    "\n",
    "- ブレンディング\n",
    "- バギング\n",
    "- スタッキング\n",
    "\n",
    "#### 小さなデータセットの用意\n",
    "以前も利用した回帰のデータセットを用意します。\n",
    "\n",
    "[House Prices: Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)\n",
    "\n",
    "この中のtrain.csvをダウンロードし、目的変数としてSalePrice、説明変数として、GrLivAreaとYearBuiltを使います。\n",
    "\n",
    "train.csvを学習用（train）8割、検証用（val）2割に分割してください。\n",
    "\n",
    "#### scikit-learn\n",
    "単一のモデルはスクラッチ実装ではなく、scikit-learnなどのライブラリの使用を推奨します。\n",
    "\n",
    "[sklearn.linear_model.LinearRegression — scikit-learn 0.21.3 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)\n",
    "\n",
    "[sklearn.svm.SVR — scikit-learn 0.21.3 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html)\n",
    "\n",
    "[sklearn.tree.DecisionTreeRegressor — scikit-learn 0.21.3 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1515.463699</td>\n",
       "      <td>1971.267808</td>\n",
       "      <td>180921.195890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>525.480383</td>\n",
       "      <td>30.202904</td>\n",
       "      <td>79442.502883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>334.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>34900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1129.500000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>129975.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1464.000000</td>\n",
       "      <td>1973.000000</td>\n",
       "      <td>163000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1776.750000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>214000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5642.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>755000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         GrLivArea    YearBuilt      SalePrice\n",
       "count  1460.000000  1460.000000    1460.000000\n",
       "mean   1515.463699  1971.267808  180921.195890\n",
       "std     525.480383    30.202904   79442.502883\n",
       "min     334.000000  1872.000000   34900.000000\n",
       "25%    1129.500000  1954.000000  129975.000000\n",
       "50%    1464.000000  1973.000000  163000.000000\n",
       "75%    1776.750000  2000.000000  214000.000000\n",
       "max    5642.000000  2010.000000  755000.000000"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('train.csv')\n",
    "df_select = df[['GrLivArea', 'YearBuilt', 'SalePrice']]\n",
    "df_select.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1168, 3)\n",
      "(292, 3)\n"
     ]
    }
   ],
   "source": [
    "df_train = df_select.iloc[:int(len(df_select)*0.8), :]\n",
    "df_val = df_select.iloc[int(len(df_select)*0.8):, :]\n",
    "print(df_train.shape)\n",
    "print(df_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[['GrLivArea', 'YearBuilt']]\n",
    "y_train = df_train[\"SalePrice\"]\n",
    "X_test = df_val[['GrLivArea', 'YearBuilt']]\n",
    "y_test = df_val[\"SalePrice\"]\n",
    "X = df_select[['GrLivArea', 'YearBuilt']]\n",
    "y = df_select[\"SalePrice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, LogisticRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題1】ブレンディングのスクラッチ実装\n",
    "ブレンディング をスクラッチ実装し、単一モデルより精度があがる例を 最低3つ 示してください。精度があがるとは、検証用データに対する平均二乗誤差（MSE）が小さくなることを指します。\n",
    "\n",
    "#### ブレンディングとは\n",
    "ブレンディングとは、N個の多様なモデルを独立して学習させ、推定結果を重み付けした上で足し合わせる方法です。最も単純には平均をとります。多様なモデルとは、以下のような条件を変化させることで作り出すものです。\n",
    "\n",
    "- 手法（例：線形回帰、SVM、決定木、ニューラルネットワークなど）\n",
    "- ハイパーパラメータ（例：SVMのカーネルの種類、重みの初期値など）\n",
    "- 入力データの前処理の仕方（例：標準化、対数変換、PCAなど）\n",
    "\n",
    "重要なのはそれぞれのモデルが大きく異なることです。\n",
    "\n",
    "回帰問題でのブレンディングは非常に単純であるため、scikit-learnには用意されていません。\n",
    "\n",
    "《補足》\n",
    "\n",
    "分類問題の場合は、多数決を行います。回帰問題に比べると複雑なため、scikit-learnにはVotingClassifierが用意されています。\n",
    "\n",
    "[sklearn.ensemble.VotingClassifier — scikit-learn 0.21.3 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchBlending():\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "\n",
    "# 不要だった\n",
    "#     def fit(self, X, y):\n",
    "#         for model in self.models:\n",
    "#             model.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        list_y_pred = []\n",
    "        for model in self.models:\n",
    "            list_y_pred.append(model.predict(X))\n",
    "            \n",
    "        y_pred = sum(list_y_pred)/len(list_y_pred)\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "結果\n",
      "single:2.967268e+09, ensemble:2.742822e+09\n"
     ]
    }
   ],
   "source": [
    "# パターン1\n",
    "mse_single = []\n",
    "lr_1 = LinearRegression()\n",
    "lr_1.fit(X_train, y_train)\n",
    "y_pred = lr_1.predict(X_test)\n",
    "mse_single.append(mean_squared_error(y_pred, y_test))\n",
    "\n",
    "svr_1 = SVR()\n",
    "svr_1.fit(X_train, y_train)\n",
    "y_pred = svr_1.predict(X_test)\n",
    "mse_single.append(mean_squared_error(y_pred, y_test))\n",
    "\n",
    "dt_1 = DecisionTreeRegressor()\n",
    "dt_1.fit(X_train, y_train)\n",
    "y_pred = dt_1.predict(X_test)\n",
    "mse_single.append(mean_squared_error(y_pred, y_test))\n",
    "\n",
    "\n",
    "models_1 = [lr_1, svr_1, dt_1]\n",
    "\n",
    "blend_model = ScratchBlending(models_1)\n",
    "y_pred = blend_model.predict(X_test)\n",
    "mse = mean_squared_error(y_pred, y_test)\n",
    "\n",
    "print(\"結果\")\n",
    "print(\"single:{:e}, ensemble:{:e}\".format(min(mse_single), mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "結果\n",
      "single:2.879109e+09, ensemble:2.810552e+09\n"
     ]
    }
   ],
   "source": [
    "# パターン2\n",
    "mse_single = []\n",
    "lr_2 = LinearRegression()\n",
    "lr_2.fit(X_train, y_train)\n",
    "y_pred = lr_2.predict(X_test)\n",
    "mse_single.append(mean_squared_error(y_pred, y_test))\n",
    "\n",
    "lr_3 = LinearRegression()\n",
    "lr_3.fit(X_train, y_train)\n",
    "y_pred = lr_3.predict(X_test)\n",
    "mse_single.append(mean_squared_error(y_pred, y_test))\n",
    "\n",
    "dt_2 = DecisionTreeRegressor(max_depth=3)\n",
    "dt_2.fit(X_train, y_train)\n",
    "y_pred = dt_2.predict(X_test)\n",
    "mse_single.append(mean_squared_error(y_pred, y_test))\n",
    "\n",
    "svr_2 = SVR(C=0.1)\n",
    "svr_2.fit(X_train, y_train)\n",
    "y_pred = svr_2.predict(X_test)\n",
    "mse_single.append(mean_squared_error(y_pred, y_test))\n",
    "\n",
    "\n",
    "models_2 = [lr_2, lr_3, dt_2, svr_2]\n",
    "\n",
    "blend_model = ScratchBlending(models_2)\n",
    "y_pred = blend_model.predict(X_test)\n",
    "mse = mean_squared_error(y_pred, y_test)\n",
    "\n",
    "print(\"結果\")\n",
    "print(\"single:{:e}, ensemble:{:e}\".format(min(mse_single), mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "結果\n",
      "single:2.967268e+09, ensemble:2.600892e+09\n"
     ]
    }
   ],
   "source": [
    "# パターン3\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scale = scaler.fit_transform(X_train)\n",
    "X_test_scale = scaler.transform(X_test)\n",
    "\n",
    "mse_single = []\n",
    "lr_4 = LinearRegression()\n",
    "lr_4.fit(X_train_scale, y_train)\n",
    "y_pred = lr_4.predict(X_test_scale)\n",
    "mse_single.append(mean_squared_error(y_pred, y_test))\n",
    "\n",
    "svr_3 = SVR()\n",
    "svr_3.fit(X_train_scale, y_train)\n",
    "y_pred = svr_3.predict(X_test_scale)\n",
    "mse_single.append(mean_squared_error(y_pred, y_test))\n",
    "\n",
    "dt_3 = DecisionTreeRegressor()\n",
    "dt_3.fit(X_train_scale, y_train)\n",
    "y_pred = dt_3.predict(X_test_scale)\n",
    "mse_single.append(mean_squared_error(y_pred, y_test))\n",
    "\n",
    "\n",
    "models_3 = [lr_4, dt_3, svr_3]\n",
    "\n",
    "blend_model = ScratchBlending(models_3)\n",
    "y_pred = blend_model.predict(X_test_scale)\n",
    "mse = mean_squared_error(y_pred, y_test)\n",
    "\n",
    "print(\"結果\")\n",
    "print(\"single:{:e}, ensemble:{:e}\".format(min(mse_single), mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題2】バギングのスクラッチ実装\n",
    "バギング をスクラッチ実装し、単一モデルより精度があがる例を 最低1つ 示してください。\n",
    "\n",
    "\n",
    "#### バギングとは\n",
    "バギングは入力データの選び方を多様化する方法です。学習データから重複を許した上でランダムに抜き出すことで、N種類のサブセット（ ブートストラップサンプル ）を作り出します。それらによってモデルをN個学習し、推定結果の平均をとります。ブレンディングと異なり、それぞれの重み付けを変えることはありません。\n",
    "\n",
    "[sklearn.model_selection.train_test_split — scikit-learn 0.21.3 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
    "\n",
    "scikit-learnのtrain_test_splitを、shuffleパラメータをTrueにして使うことで、ランダムにデータを分割することができます。これによりブートストラップサンプルが手に入ります。\n",
    "\n",
    "推定結果の平均をとる部分はブースティングと同様の実装になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "結果\n",
      "single:2.036735e+09, ensemble:2.077508e+09\n"
     ]
    }
   ],
   "source": [
    "models_4 = []\n",
    "mse_single = []\n",
    "\n",
    "num_tree = 10\n",
    "depth_tree = 10\n",
    "\n",
    "for i in range(num_tree):\n",
    "    X_train_bag, X_test_bag, y_train_bag, y_test_bag = train_test_split(X_train, y_train, \n",
    "                                                                        shuffle=True,\n",
    "                                                                        test_size=0.2)\n",
    "    dt_tmp = DecisionTreeRegressor(max_depth=depth_tree)\n",
    "    dt_tmp.fit(X_train_bag, y_train_bag)\n",
    "    y_pred = dt_tmp.predict(X_test)\n",
    "    mse_single.append(mean_squared_error(y_pred, y_test))\n",
    "    models_4.append(dt_tmp)\n",
    "    \n",
    "bagging_model = ScratchBlending(models_4)\n",
    "y_pred = bagging_model.predict(X_test)\n",
    "mse = mean_squared_error(y_pred, y_test)\n",
    "\n",
    "print(\"結果\")\n",
    "print(\"single:{:e}, ensemble:{:e}\".format(min(mse_single), mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題3】スタッキングのスクラッチ実装\n",
    "スタッキング をスクラッチ実装し、単一モデルより精度があがる例を 最低1つ 示してください。\n",
    "\n",
    "#### スタッキングとは\n",
    "スタッキングの手順は以下の通りです。最低限ステージ0とステージ1があればスタッキングは成立するため、それを実装してください。まずは $K_0=3, M_0=2$ 程度にします。\n",
    "\n",
    "《学習時》\n",
    "\n",
    "（ステージ $0$ ）\n",
    "\n",
    "- 学習データを $K_0$ 個に分割する。\n",
    "- 分割した内の $(K_0 - 1)$ 個をまとめて学習用データ、残り $1$ 個を推定用データとする組み合わせが $K_0$ 個作れる。\n",
    "- あるモデルのインスタンスを $K_0$ 個用意し、異なる学習用データを使い学習する。\n",
    "- それぞれの学習済みモデルに対して、使っていない残り $1$ 個の推定用データを入力し、推定値を得る。（これをブレンドデータと呼ぶ）\n",
    "- さらに、異なるモデルのインスタンスも $K_0$ 個用意し、同様のことを行う。モデルが $M_0$ 個あれば、 $M_0$ 個のブレンドデータが得られる。\n",
    "\n",
    "（ステージ $n$ ）\n",
    "\n",
    "ステージ $n-1$ のブレンドデータを$M_{n-1}$ 次元の特徴量を持つ学習用データと考え、 $K_n$ 個に分割する。以下同様である。\n",
    "\n",
    "（ステージ $N$ ）＊最後のステージ\n",
    "\n",
    "ステージ $N-1$ の $M_{N-1}$ 個のブレンドデータを$M_{N-1}$ 次元の特徴量の入力として、1種類のモデルの学習を行う。これが最終的な推定を行うモデルとなる。\n",
    "\n",
    "《推定時》\n",
    "\n",
    "（ステージ $0$ ）\n",
    "\n",
    "テストデータを $K_0×M_0$ 個の学習済みモデルに入力し、$K_0×M_0$ 個の推定値を得る。これを $K_0$ の軸で平均値を求め $M_0$ 次元の特徴量を持つデータを得る。（ブレンドテストと呼ぶ）\n",
    "\n",
    "（ステージ $n$ ）\n",
    "\n",
    "ステージ $n-1$ で得たブレンドテストを $K_n×M_n$ 個の学習済みモデルに入力し、$K_n×M_n$ 個の推定値を得る。これを $K_n$ の軸で平均値を求め $M_0$ 次元の特徴量を持つデータを得る。（ブレンドテストと呼ぶ）\n",
    "\n",
    "（ステージ $N$ ）＊最後のステージ\n",
    "\n",
    "ステージ $N-1$ で得たブレンドテストを学習済みモデルに入力し、推定値を得る。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import copy\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([3, 4, 5, 6, 7, 8]), array([0, 1, 2])),\n",
       " (array([0, 1, 2, 6, 7, 8]), array([3, 4, 5])),\n",
       " (array([0, 1, 2, 3, 4, 5]), array([6, 7, 8]))]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits=3, shuffle=False)\n",
    "a = np.array([[1,2,3,4,5,6], [2,3,4,5,6,7], [3,4,5,6,7,8], [1,2,3,4,5,6], [2,3,4,5,6,7], [3,4,5,6,7,8], [1,2,3,4,5,6], [2,3,4,5,6,7], [3,4,5,6,7,8]])\n",
    "index = list(kf.split(a))\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchStacking():\n",
    "    def __init__(self, models, K):\n",
    "        self.K = K\n",
    "        self.models = models\n",
    "        self.M = len(models)\n",
    "        self.last_model = None\n",
    "        self.stack_models = []\n",
    "        self.single_mse = {}\n",
    "        self.flg_reshape = 0\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        kf = KFold(n_splits=self.K, shuffle=False)\n",
    "        \n",
    "        # ステージ0\n",
    "        for m in range(self.M):\n",
    "            tmp_stack_models = []\n",
    "            self.single_mse[\"model_\"+str(m)] = []\n",
    "            for k, (train_index, val_index) in enumerate(kf.split(X)):\n",
    "                # 学習・推定\n",
    "                self.models[m].fit(X[train_index], y[train_index])\n",
    "                pred_tmp = self.models[m].predict(X[val_index])\n",
    "                if k == 0:\n",
    "                    tmp_blend_data = pred_tmp\n",
    "                    y_test = y[val_index]\n",
    "                else:\n",
    "                    tmp_blend_data = np.hstack([tmp_blend_data, pred_tmp])\n",
    "                    y_test = np.hstack([y_test, y[val_index]])\n",
    "\n",
    "                self.single_mse[\"model_\"+str(m)].append(mean_squared_error(pred_tmp, y[val_index]))\n",
    "                    \n",
    "                tmp_stack_models.append(copy.deepcopy(self.models[m]))\n",
    "\n",
    "            self.stack_models.append(tmp_stack_models)\n",
    "\n",
    "            if m == 0:\n",
    "                blend_data = tmp_blend_data\n",
    "            else:\n",
    "                blend_data = np.vstack([blend_data, tmp_blend_data])\n",
    "\n",
    "        # 最終ステージ\n",
    "        blend_data = blend_data.T\n",
    "        self.last_model = RandomForestRegressor(max_depth=5)\n",
    "        if blend_data.shape == y_test.shape:\n",
    "            self.flg_reshape = 1\n",
    "            blend_data = blend_data.reshape(-1, 1)\n",
    "        self.last_model.fit(blend_data, y_test)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # ステージ0\n",
    "        for m in range(self.M):\n",
    "            for k in range(self.K):\n",
    "                if k == 0:\n",
    "                    y_pred = self.stack_models[m][k].predict(X)\n",
    "                else:\n",
    "                    y_pred = np.vstack([y_pred, self.stack_models[m][k].predict(X)])\n",
    "            \n",
    "            y_pred_mean = y_pred.T.mean(axis=1)\n",
    "            \n",
    "            if m == 0:\n",
    "                y_pred_mean_all = y_pred_mean\n",
    "            else:\n",
    "                y_pred_mean_all = np.vstack([y_pred_mean_all, y_pred_mean])\n",
    "        \n",
    "        y_pred_mean_all = y_pred_mean_all.T\n",
    "\n",
    "        # 最終ステージ\n",
    "        if self.flg_reshape == 1:\n",
    "            y_pred_mean_all = y_pred_mean_all.reshape(-1, 1)\n",
    "        result = self.last_model.predict(y_pred_mean_all)\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_0': [2320375826.2049193, 2623001474.1875887, 2134598984.620627], 'model_1': [1774895498.8549366, 2481788907.223859, 1773550877.2380145], 'model_2': [1774895303.6456006, 2481789050.5483913, 1773550927.4333797], 'model_3': [1774895354.2016983, 2481789018.9762273, 1773550907.4525685]}\n",
      "結果\n",
      "single:1.773551e+09, ensemble:3.270910e+09\n"
     ]
    }
   ],
   "source": [
    "lr_5 = LinearRegression()\n",
    "svr_4 = SVR()\n",
    "dt_4 = DecisionTreeRegressor(max_depth=10)\n",
    "rdg = Ridge()\n",
    "lasso = Lasso()\n",
    "# last_model = DecisionTreeRegressor()\n",
    "models_4 = [dt_4, lr_5, rdg, lasso]\n",
    "\n",
    "stacking = ScratchStacking(models_4, 3)\n",
    "stacking.fit(X_train, y_train)\n",
    "pred = stacking.predict(X_test)\n",
    "mse = mean_squared_error(pred, y_test)\n",
    "\n",
    "print(stacking.single_mse)\n",
    "print(\"結果\")\n",
    "print(\"single:{:e}, ensemble:{:e}\".format(min(min(stacking.single_mse.values())), mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_0': [3389068602.928205, 4155719280.359897, 3833670714.9717226], 'model_1': [1774895303.6456006, 2481789050.5483913, 1773550927.4333797], 'model_2': [1774895354.2016983, 2481789018.9762273, 1773550907.4525685], 'model_3': [1774819832.3176727, 2481845086.442278, 1773570715.4008763], 'model_4': [1774895498.8549366, 2481788907.223859, 1773550877.2380145]}\n",
      "結果\n",
      "single:1.773571e+09, ensemble:1.002327e+10\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(max_iter=5000)\n",
    "rdg = Ridge()\n",
    "lasso = Lasso()\n",
    "eln = ElasticNet()\n",
    "lr = LinearRegression()\n",
    "# last_model = LogisticRegression(max_iter=5000)\n",
    "models_5 = [logreg, rdg, lasso, eln, lr]\n",
    "\n",
    "stacking = ScratchStacking(models_5, 3)\n",
    "stacking.fit(X_train, y_train)\n",
    "pred = stacking.predict(X_test)\n",
    "mse = mean_squared_error(pred, y_test)\n",
    "\n",
    "print(stacking.single_mse)\n",
    "print(\"結果\")\n",
    "print(\"single:{:e}, ensemble:{:e}\".format(min(min(stacking.single_mse.values())), mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_0': [1774819832.3176727, 2481845086.442278, 1773570715.4008763], 'model_1': [2317359570.841956, 2639037838.717794, 2176177872.795434], 'model_2': [2483578611.9407163, 3768169884.61499, 2394386522.9104295], 'model_3': [1774895498.8549366, 2481788907.223859, 1773550877.2380145], 'model_4': [1774895303.6456006, 2481789050.5483913, 1773550927.4333797], 'model_5': [1774895354.2016983, 2481789018.9762273, 1773550907.4525685], 'model_6': [3389068602.928205, 4155719280.359897, 3833670714.9717226]}\n",
      "結果\n",
      "single:1.773571e+09, ensemble:1.991638e+09\n"
     ]
    }
   ],
   "source": [
    "eln = ElasticNet()\n",
    "dt = DecisionTreeRegressor(max_depth=10)\n",
    "svr = SVR(kernel='poly')\n",
    "lr = LinearRegression()\n",
    "rdg = Ridge()\n",
    "lasso = Lasso()\n",
    "logreg = LogisticRegression(max_iter=5000)\n",
    "# last_model = RandomForestRegressor(max_depth=5)\n",
    "\n",
    "models_6 = [eln, dt, svr, lr, rdg, lasso, logreg]\n",
    "\n",
    "stacking = ScratchStacking(models_6, 3)\n",
    "stacking.fit(X_train, y_train)\n",
    "pred = stacking.predict(X_test)\n",
    "mse = mean_squared_error(pred, y_test)\n",
    "\n",
    "print(stacking.single_mse)\n",
    "print(\"結果\")\n",
    "print(\"single:{:e}, ensemble:{:e}\".format(min(min(stacking.single_mse.values())), mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_0': [1774865150.7670772, 2481811309.1378307, 1773558748.061693], 'model_1': [1923577328.2195165, 2326062530.667825, 1566711232.7192554], 'model_2': [2839004356.282099, 4140245011.845541, 2606565876.599297], 'model_3': [1774895498.8549366, 2481788907.223859, 1773550877.2380145], 'model_4': [1774895362.207922, 2481789007.5506124, 1773550912.3743963], 'model_5': [1774895456.3711839, 2481788942.930067, 1773550887.241639]}\n",
      "結果\n",
      "single:1.773559e+09, ensemble:1.761802e+09\n"
     ]
    }
   ],
   "source": [
    "eln = ElasticNet(alpha=0.4)\n",
    "dt = DecisionTreeRegressor(max_depth=7)\n",
    "svr = SVR(kernel='poly', C=0.2)\n",
    "lr = LinearRegression()\n",
    "rdg = Ridge(alpha=0.7)\n",
    "lasso = Lasso(alpha=0.3)\n",
    "# last_model = RandomForestRegressor(max_depth=5)\n",
    "\n",
    "models_7 = [eln, dt, svr, lr, rdg, lasso]\n",
    "\n",
    "stacking = ScratchStacking(models_7, 3)\n",
    "stacking.fit(X_train, y_train)\n",
    "pred = stacking.predict(X_test)\n",
    "mse = mean_squared_error(pred, y_test)\n",
    "\n",
    "print(stacking.single_mse)\n",
    "print(\"結果\")\n",
    "print(\"single:{:e}, ensemble:{:e}\".format(min(min(stacking.single_mse.values())), mse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
